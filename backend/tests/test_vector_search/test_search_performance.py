#!/usr/bin/env python
"""
å‘é‡æœå°‹æ•ˆèƒ½å°ˆé …æ¸¬è©¦

åŠŸèƒ½ï¼š
1. æ¸¬è©¦å–®æ¬¡æœå°‹è€—æ™‚
2. æ¸¬è©¦æ‰¹é‡æœå°‹è€—æ™‚
3. æ¸¬è©¦ä¸åŒåƒæ•¸å°æ•ˆèƒ½çš„å½±éŸ¿
4. å£“åŠ›æ¸¬è©¦ï¼ˆé€£çºŒ/ä¸¦ç™¼æœå°‹ï¼‰
5. ç”Ÿæˆæ•ˆèƒ½å ±å‘Š

ä½¿ç”¨æ–¹å¼ï¼š
    python tests/test_vector_search/test_search_performance.py

è¼¸å‡ºï¼š
    - reports/performance_YYYYMMDD.json (è©³ç´°æ•¸æ“š)
    - reports/performance_YYYYMMDD.md (ç¸½çµå ±å‘Š)
"""

import os
import sys
import json
import time
import statistics
from datetime import datetime
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor, as_completed

# æ·»åŠ å°ˆæ¡ˆæ ¹ç›®éŒ„åˆ° Python è·¯å¾‘
sys.path.insert(0, str(Path(__file__).resolve().parent.parent.parent))

# Django ç’°å¢ƒè¨­å®š
os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'ai_platform.settings')
import django
django.setup()

from library.common.knowledge_base.section_search_service import SectionSearchService


class SearchPerformanceTest:
    """æœå°‹æ•ˆèƒ½æ¸¬è©¦é¡åˆ¥"""
    
    def __init__(self):
        self.service = SectionSearchService()
        self.test_queries = []
        self.results = {
            'single_search': [],
            'batch_search': [],
            'parameter_impact': {},
            'stress_test': {},
        }
    
    def load_test_queries(self):
        """è¼‰å…¥æ¸¬è©¦æŸ¥è©¢"""
        test_data_file = Path(__file__).parent / 'test_data' / 'test_queries.json'
        
        if test_data_file.exists():
            with open(test_data_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
                for category in ['basic_queries', 'technical_queries', 'semantic_queries']:
                    if category in data:
                        self.test_queries.extend(data[category][:5])  # æ¯é¡å– 5 å€‹
        else:
            self.test_queries = [
                "ULINK é€£æ¥å¤±æ•—",
                "æ¸¬è©¦ç’°å¢ƒæº–å‚™",
                "OpenCV ç‰ˆæœ¬ç›¸å®¹æ€§",
                "pytest fixture ä½¿ç”¨",
                "å¦‚ä½•é™¤éŒ¯ç¨‹å¼",
            ]
        
        print(f"âœ… è¼‰å…¥ {len(self.test_queries)} å€‹æ¸¬è©¦æŸ¥è©¢")
        return self.test_queries
    
    def test_single_search(self, query, top_k=3, threshold=0.7, iterations=10):
        """æ¸¬è©¦å–®æ¬¡æœå°‹æ•ˆèƒ½ï¼ˆå¤šæ¬¡æ¸¬é‡å–å¹³å‡ï¼‰"""
        times = []
        
        for i in range(iterations):
            start_time = time.time()
            results = self.service.search_sections(
                query=query,
                source_table='protocol_guide',
                limit=top_k,
                threshold=threshold
            )
            elapsed = (time.time() - start_time) * 1000  # æ¯«ç§’
            times.append(elapsed)
        
        # è¨ˆç®—çµ±è¨ˆæŒ‡æ¨™
        result = {
            'query': query,
            'iterations': iterations,
            'times_ms': times,
            'avg_ms': round(statistics.mean(times), 2),
            'median_ms': round(statistics.median(times), 2),
            'min_ms': round(min(times), 2),
            'max_ms': round(max(times), 2),
            'std_ms': round(statistics.stdev(times), 2) if len(times) > 1 else 0,
            'found_count': len(results),
        }
        
        self.results['single_search'].append(result)
        
        print(f"  âœ“ {query}: å¹³å‡ {result['avg_ms']:.2f}ms (ä¸­ä½æ•¸ {result['median_ms']:.2f}ms)")
        
        return result
    
    def test_batch_search(self, queries, top_k=3, threshold=0.7):
        """æ¸¬è©¦æ‰¹é‡æœå°‹æ•ˆèƒ½"""
        print(f"\nğŸ“¦ æ¸¬è©¦æ‰¹é‡æœå°‹ ({len(queries)} å€‹æŸ¥è©¢)")
        
        start_time = time.time()
        results_list = []
        
        for query in queries:
            results = self.service.search_sections(
                query=query,
                source_table='protocol_guide',
                limit=top_k,
                threshold=threshold
            )
            results_list.append(results)
        
        total_time = (time.time() - start_time) * 1000
        avg_time = total_time / len(queries)
        
        result = {
            'total_queries': len(queries),
            'total_time_ms': round(total_time, 2),
            'avg_time_per_query_ms': round(avg_time, 2),
            'queries_per_second': round(1000 / avg_time, 2),
        }
        
        self.results['batch_search'] = result
        
        print(f"  âœ“ ç¸½è€—æ™‚: {total_time:.2f}ms")
        print(f"  âœ“ å¹³å‡æ¯å€‹æŸ¥è©¢: {avg_time:.2f}ms")
        print(f"  âœ“ ååé‡: {result['queries_per_second']:.2f} queries/sec")
        
        return result
    
    def test_parameter_impact(self, query="ULINK é€£æ¥å¤±æ•—"):
        """æ¸¬è©¦ä¸åŒåƒæ•¸å°æ•ˆèƒ½çš„å½±éŸ¿"""
        print(f"\nâš™ï¸ æ¸¬è©¦åƒæ•¸å½±éŸ¿")
        
        # æ¸¬è©¦ä¸åŒ top_k
        print(f"  æ¸¬è©¦ä¸åŒ top_k å€¼...")
        top_k_results = {}
        for k in [1, 3, 5, 10]:
            times = []
            for _ in range(5):
                start_time = time.time()
                results = self.service.search_sections(query=query, source_table='protocol_guide', limit=k, threshold=0.7)
                times.append((time.time() - start_time) * 1000)
            
            avg_time = statistics.mean(times)
            top_k_results[k] = {
                'avg_time_ms': round(avg_time, 2),
                'found_count': len(results),
            }
            print(f"    top_k={k}: {avg_time:.2f}ms ({len(results)} å€‹çµæœ)")
        
        self.results['parameter_impact']['top_k'] = top_k_results
        
        # æ¸¬è©¦ä¸åŒ threshold
        print(f"  æ¸¬è©¦ä¸åŒ threshold å€¼...")
        threshold_results = {}
        for t in [0.5, 0.6, 0.7, 0.8, 0.9]:
            times = []
            for _ in range(5):
                start_time = time.time()
                results = self.service.search_sections(query=query, source_table='protocol_guide', limit=3, threshold=t)
                times.append((time.time() - start_time) * 1000)
            
            avg_time = statistics.mean(times)
            threshold_results[t] = {
                'avg_time_ms': round(avg_time, 2),
                'found_count': len(results),
            }
            print(f"    threshold={t}: {avg_time:.2f}ms ({len(results)} å€‹çµæœ)")
        
        self.results['parameter_impact']['threshold'] = threshold_results
        
        return self.results['parameter_impact']
    
    def test_stress_continuous(self, query="ULINK é€£æ¥å¤±æ•—", iterations=100):
        """å£“åŠ›æ¸¬è©¦ï¼šé€£çºŒæœå°‹"""
        print(f"\nğŸ”¥ å£“åŠ›æ¸¬è©¦ï¼šé€£çºŒåŸ·è¡Œ {iterations} æ¬¡")
        
        times = []
        errors = 0
        
        start_time = time.time()
        
        for i in range(iterations):
            try:
                search_start = time.time()
                results = self.service.search_sections(query=query, source_table='protocol_guide', limit=3, threshold=0.7)
                search_time = (time.time() - search_start) * 1000
                times.append(search_time)
                
                if (i + 1) % 20 == 0:
                    print(f"  é€²åº¦: {i+1}/{iterations}")
                    
            except Exception as e:
                errors += 1
                print(f"  âœ— éŒ¯èª¤: {str(e)}")
        
        total_time = (time.time() - start_time) * 1000
        
        result = {
            'iterations': iterations,
            'successful': len(times),
            'errors': errors,
            'total_time_ms': round(total_time, 2),
            'avg_time_ms': round(statistics.mean(times), 2) if times else 0,
            'median_time_ms': round(statistics.median(times), 2) if times else 0,
            'p95_time_ms': round(statistics.quantiles(times, n=20)[18], 2) if len(times) >= 20 else 0,
            'p99_time_ms': round(statistics.quantiles(times, n=100)[98], 2) if len(times) >= 100 else 0,
            'min_time_ms': round(min(times), 2) if times else 0,
            'max_time_ms': round(max(times), 2) if times else 0,
            'std_time_ms': round(statistics.stdev(times), 2) if len(times) > 1 else 0,
            'throughput_qps': round(len(times) / (total_time / 1000), 2) if total_time > 0 else 0,
        }
        
        self.results['stress_test']['continuous'] = result
        
        print(f"  âœ“ æˆåŠŸ: {result['successful']}/{iterations}")
        print(f"  âœ“ å¹³å‡è€—æ™‚: {result['avg_time_ms']:.2f}ms")
        print(f"  âœ“ P95 è€—æ™‚: {result['p95_time_ms']:.2f}ms")
        print(f"  âœ“ P99 è€—æ™‚: {result['p99_time_ms']:.2f}ms")
        print(f"  âœ“ ååé‡: {result['throughput_qps']:.2f} QPS")
        
        return result
    
    def test_stress_concurrent(self, query="ULINK é€£æ¥å¤±æ•—", workers=10, iterations_per_worker=10):
        """å£“åŠ›æ¸¬è©¦ï¼šä¸¦ç™¼æœå°‹"""
        print(f"\nğŸ”¥ å£“åŠ›æ¸¬è©¦ï¼š{workers} å€‹ä¸¦ç™¼ workerï¼Œæ¯å€‹åŸ·è¡Œ {iterations_per_worker} æ¬¡")
        
        def worker_task(worker_id):
            times = []
            for i in range(iterations_per_worker):
                try:
                    start = time.time()
                    results = self.service.search_sections(query=query, source_table='protocol_guide', limit=3, threshold=0.7)
                    elapsed = (time.time() - start) * 1000
                    times.append(elapsed)
                except Exception as e:
                    pass
            return times
        
        start_time = time.time()
        all_times = []
        
        with ThreadPoolExecutor(max_workers=workers) as executor:
            futures = [executor.submit(worker_task, i) for i in range(workers)]
            
            for future in as_completed(futures):
                try:
                    times = future.result()
                    all_times.extend(times)
                except Exception as e:
                    print(f"  âœ— Worker éŒ¯èª¤: {str(e)}")
        
        total_time = (time.time() - start_time) * 1000
        
        result = {
            'workers': workers,
            'iterations_per_worker': iterations_per_worker,
            'total_requests': workers * iterations_per_worker,
            'successful': len(all_times),
            'total_time_ms': round(total_time, 2),
            'avg_time_ms': round(statistics.mean(all_times), 2) if all_times else 0,
            'median_time_ms': round(statistics.median(all_times), 2) if all_times else 0,
            'p95_time_ms': round(statistics.quantiles(all_times, n=20)[18], 2) if len(all_times) >= 20 else 0,
            'min_time_ms': round(min(all_times), 2) if all_times else 0,
            'max_time_ms': round(max(all_times), 2) if all_times else 0,
            'throughput_qps': round(len(all_times) / (total_time / 1000), 2) if total_time > 0 else 0,
        }
        
        self.results['stress_test']['concurrent'] = result
        
        print(f"  âœ“ æˆåŠŸ: {result['successful']}/{result['total_requests']}")
        print(f"  âœ“ ç¸½è€—æ™‚: {result['total_time_ms']:.2f}ms")
        print(f"  âœ“ å¹³å‡è€—æ™‚: {result['avg_time_ms']:.2f}ms")
        print(f"  âœ“ P95 è€—æ™‚: {result['p95_time_ms']:.2f}ms")
        print(f"  âœ“ ååé‡: {result['throughput_qps']:.2f} QPS")
        
        return result
    
    def run_all_tests(self):
        """åŸ·è¡Œæ‰€æœ‰æ•ˆèƒ½æ¸¬è©¦"""
        print(f"\n{'='*70}")
        print(f"âš¡ é–‹å§‹åŸ·è¡Œæœå°‹æ•ˆèƒ½æ¸¬è©¦")
        print(f"{'='*70}\n")
        
        # 1. å–®æ¬¡æœå°‹æ¸¬è©¦
        print(f"ğŸ” æ¸¬è©¦ 1: å–®æ¬¡æœå°‹æ•ˆèƒ½")
        print(f"-" * 70)
        for query in self.test_queries[:3]:  # æ¸¬è©¦å‰ 3 å€‹
            self.test_single_search(query, iterations=10)
        
        # 2. æ‰¹é‡æœå°‹æ¸¬è©¦
        print(f"\n")
        self.test_batch_search(self.test_queries)
        
        # 3. åƒæ•¸å½±éŸ¿æ¸¬è©¦
        print(f"\n")
        self.test_parameter_impact()
        
        # 4. å£“åŠ›æ¸¬è©¦ï¼šé€£çºŒ
        print(f"\n")
        self.test_stress_continuous(iterations=100)
        
        # 5. å£“åŠ›æ¸¬è©¦ï¼šä¸¦ç™¼
        print(f"\n")
        self.test_stress_concurrent(workers=5, iterations_per_worker=10)
        
        print(f"\n{'='*70}")
        print(f"âœ… æ‰€æœ‰æ•ˆèƒ½æ¸¬è©¦å®Œæˆ")
        print(f"{'='*70}")
    
    def save_json_report(self):
        """å„²å­˜ JSON è©³ç´°æ•¸æ“š"""
        timestamp = datetime.now().strftime('%Y%m%d')
        report_file = Path(__file__).parent / 'reports' / f'performance_{timestamp}.json'
        
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(self.results, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… JSON å ±å‘Šå·²ç”Ÿæˆ: {report_file}")
        return report_file
    
    def generate_markdown_report(self):
        """ç”Ÿæˆ Markdown å ±å‘Š"""
        timestamp = datetime.now().strftime('%Y%m%d')
        report_file = Path(__file__).parent / 'reports' / f'performance_{timestamp}.md'
        
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(f"# å‘é‡æœå°‹æ•ˆèƒ½æ¸¬è©¦å ±å‘Š\n\n")
            f.write(f"**æ¸¬è©¦æ™‚é–“**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            f.write(f"**æ¸¬è©¦ç‰ˆæœ¬**: Protocol Guide Section Search System\n\n")
            f.write(f"---\n\n")
            
            # 1. å–®æ¬¡æœå°‹æ•ˆèƒ½
            f.write(f"## ğŸ” å–®æ¬¡æœå°‹æ•ˆèƒ½\n\n")
            f.write(f"| æŸ¥è©¢ | å¹³å‡è€—æ™‚ | ä¸­ä½æ•¸ | æœ€å°å€¼ | æœ€å¤§å€¼ | æ¨™æº–å·® |\n")
            f.write(f"|------|----------|--------|--------|--------|--------|\n")
            
            for result in self.results['single_search']:
                f.write(f"| {result['query']} | {result['avg_ms']:.2f}ms | {result['median_ms']:.2f}ms | {result['min_ms']:.2f}ms | {result['max_ms']:.2f}ms | {result['std_ms']:.2f}ms |\n")
            
            f.write(f"\n")
            
            # 2. æ‰¹é‡æœå°‹æ•ˆèƒ½
            batch = self.results['batch_search']
            f.write(f"## ğŸ“¦ æ‰¹é‡æœå°‹æ•ˆèƒ½\n\n")
            f.write(f"- ç¸½æŸ¥è©¢æ•¸: {batch['total_queries']}\n")
            f.write(f"- ç¸½è€—æ™‚: {batch['total_time_ms']:.2f}ms\n")
            f.write(f"- å¹³å‡æ¯å€‹æŸ¥è©¢: {batch['avg_time_per_query_ms']:.2f}ms\n")
            f.write(f"- ååé‡: **{batch['queries_per_second']:.2f} queries/sec**\n\n")
            
            # 3. åƒæ•¸å½±éŸ¿
            f.write(f"## âš™ï¸ åƒæ•¸å½±éŸ¿åˆ†æ\n\n")
            
            f.write(f"### top_k åƒæ•¸å½±éŸ¿\n\n")
            f.write(f"| top_k | å¹³å‡è€—æ™‚ | çµæœæ•¸é‡ |\n")
            f.write(f"|-------|----------|----------|\n")
            for k, data in self.results['parameter_impact']['top_k'].items():
                f.write(f"| {k} | {data['avg_time_ms']:.2f}ms | {data['found_count']} |\n")
            f.write(f"\n")
            
            f.write(f"### threshold åƒæ•¸å½±éŸ¿\n\n")
            f.write(f"| threshold | å¹³å‡è€—æ™‚ | çµæœæ•¸é‡ |\n")
            f.write(f"|-----------|----------|----------|\n")
            for t, data in self.results['parameter_impact']['threshold'].items():
                f.write(f"| {t} | {data['avg_time_ms']:.2f}ms | {data['found_count']} |\n")
            f.write(f"\n")
            
            # 4. å£“åŠ›æ¸¬è©¦
            f.write(f"## ğŸ”¥ å£“åŠ›æ¸¬è©¦çµæœ\n\n")
            
            continuous = self.results['stress_test']['continuous']
            f.write(f"### é€£çºŒæœå°‹æ¸¬è©¦\n\n")
            f.write(f"- åŸ·è¡Œæ¬¡æ•¸: {continuous['iterations']}\n")
            f.write(f"- æˆåŠŸæ¬¡æ•¸: {continuous['successful']}\n")
            f.write(f"- å¹³å‡è€—æ™‚: {continuous['avg_time_ms']:.2f}ms\n")
            f.write(f"- ä¸­ä½æ•¸è€—æ™‚: {continuous['median_time_ms']:.2f}ms\n")
            f.write(f"- P95 è€—æ™‚: {continuous['p95_time_ms']:.2f}ms\n")
            f.write(f"- P99 è€—æ™‚: {continuous['p99_time_ms']:.2f}ms\n")
            f.write(f"- ååé‡: **{continuous['throughput_qps']:.2f} QPS**\n\n")
            
            concurrent = self.results['stress_test']['concurrent']
            f.write(f"### ä¸¦ç™¼æœå°‹æ¸¬è©¦\n\n")
            f.write(f"- ä¸¦ç™¼æ•¸: {concurrent['workers']}\n")
            f.write(f"- æ¯å€‹ worker åŸ·è¡Œ: {concurrent['iterations_per_worker']} æ¬¡\n")
            f.write(f"- ç¸½è«‹æ±‚æ•¸: {concurrent['total_requests']}\n")
            f.write(f"- æˆåŠŸæ¬¡æ•¸: {concurrent['successful']}\n")
            f.write(f"- å¹³å‡è€—æ™‚: {concurrent['avg_time_ms']:.2f}ms\n")
            f.write(f"- P95 è€—æ™‚: {concurrent['p95_time_ms']:.2f}ms\n")
            f.write(f"- ååé‡: **{concurrent['throughput_qps']:.2f} QPS**\n\n")
            
            # 5. çµè«–
            f.write(f"---\n\n")
            f.write(f"## ğŸ¯ çµè«–èˆ‡å»ºè­°\n\n")
            
            avg_single = statistics.mean([r['avg_ms'] for r in self.results['single_search']])
            
            if avg_single < 100:
                f.write(f"âœ… **æœå°‹æ•ˆèƒ½å„ªç§€**ï¼ˆå¹³å‡ {avg_single:.2f}msï¼‰\n\n")
            elif avg_single < 200:
                f.write(f"âš ï¸ **æœå°‹æ•ˆèƒ½è‰¯å¥½**ï¼ˆå¹³å‡ {avg_single:.2f}msï¼‰ï¼Œå¯æ¥å—\n\n")
            else:
                f.write(f"âŒ **æœå°‹æ•ˆèƒ½éœ€è¦å„ªåŒ–**ï¼ˆå¹³å‡ {avg_single:.2f}msï¼‰\n\n")
            
            f.write(f"**æœ€ä½³å¯¦è¸å»ºè­°**:\n\n")
            f.write(f"1. **å»ºè­° top_k**: 3-5ï¼ˆæ•ˆèƒ½èˆ‡æº–ç¢ºåº¦çš„å¹³è¡¡é»ï¼‰\n")
            f.write(f"2. **å»ºè­° threshold**: 0.7ï¼ˆè¦†è“‹ç‡èˆ‡ç²¾ç¢ºåº¦çš„å¹³è¡¡é»ï¼‰\n")
            f.write(f"3. **ä¸¦ç™¼è™•ç†èƒ½åŠ›**: ç³»çµ±å¯æ‰¿å— {concurrent['workers']} å€‹ä¸¦ç™¼è«‹æ±‚\n")
            f.write(f"4. **é æœŸååé‡**: {continuous['throughput_qps']:.2f} QPS\n\n")
            
            f.write(f"---\n\n")
            f.write(f"## ğŸ“ æ¸¬è©¦ç’°å¢ƒ\n\n")
            f.write(f"- è³‡æ–™åº«: PostgreSQL + pgvector\n")
            f.write(f"- Embedding æ¨¡å‹: intfloat/multilingual-e5-large (1024 ç¶­)\n")
            f.write(f"- ç´¢å¼•é¡å‹: IVFFlat (cosine similarity)\n")
            f.write(f"- æ¸¬è©¦æ•¸æ“š: Protocol Guide æ®µè½å‘é‡ï¼ˆdocument_section_embeddingsï¼‰\n\n")
        
        print(f"âœ… Markdown å ±å‘Šå·²ç”Ÿæˆ: {report_file}")
        return report_file


def main():
    """ä¸»ç¨‹å¼"""
    tester = SearchPerformanceTest()
    
    # è¼‰å…¥æ¸¬è©¦æŸ¥è©¢
    tester.load_test_queries()
    
    # åŸ·è¡Œæ‰€æœ‰æ¸¬è©¦
    tester.run_all_tests()
    
    # ç”Ÿæˆå ±å‘Š
    json_file = tester.save_json_report()
    md_file = tester.generate_markdown_report()
    
    print(f"\n{'='*70}")
    print(f"ğŸ‰ æ•ˆèƒ½æ¸¬è©¦å®Œæˆï¼")
    print(f"{'='*70}")
    print(f"ğŸ“„ JSON å ±å‘Š: {json_file}")
    print(f"ğŸ“„ Markdown å ±å‘Š: {md_file}")
    print(f"{'='*70}\n")


if __name__ == '__main__':
    main()
