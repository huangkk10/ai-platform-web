#!/usr/bin/env python
"""
å‘é‡æœå°‹ç³»çµ±å®Œæ•´å°æ¯”æ¸¬è©¦

åŠŸèƒ½ï¼š
1. å°æ¯”æ–°èˆŠç³»çµ±çš„æœå°‹æº–ç¢ºåº¦
2. å°æ¯”æ–°èˆŠç³»çµ±çš„å…§å®¹é•·åº¦
3. å°æ¯”æ–°èˆŠç³»çµ±çš„å›æ‡‰é€Ÿåº¦
4. ç”Ÿæˆè©³ç´°çš„å°æ¯”å ±å‘Š

ä½¿ç”¨æ–¹å¼ï¼š
    python tests/test_vector_search/test_section_search_comparison.py

è¼¸å‡ºï¼š
    - reports/comparison_YYYYMMDD_HHMMSS.csv (è©³ç´°æ•¸æ“š)
    - reports/comparison_YYYYMMDD_HHMMSS.md (ç¸½çµå ±å‘Š)
"""

import os
import sys
import json
import time
import csv
from datetime import datetime
from pathlib import Path

# æ·»åŠ å°ˆæ¡ˆæ ¹ç›®éŒ„åˆ° Python è·¯å¾‘
sys.path.insert(0, str(Path(__file__).resolve().parent.parent.parent))

# Django ç’°å¢ƒè¨­å®š
os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'ai_platform.settings')
import django
django.setup()

from library.protocol_guide.search_service import ProtocolGuideSearchService
from library.common.knowledge_base.section_search_service import SectionSearchService


class SearchComparisonTest:
    """æœå°‹ç³»çµ±å°æ¯”æ¸¬è©¦é¡åˆ¥"""
    
    def __init__(self):
        self.old_service = ProtocolGuideSearchService()
        self.new_service = SectionSearchService()
        self.results = []
        self.test_queries = []
        
    def load_test_queries(self):
        """è¼‰å…¥æ¸¬è©¦æŸ¥è©¢"""
        test_data_file = Path(__file__).parent / 'test_data' / 'test_queries.json'
        
        if test_data_file.exists():
            with open(test_data_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
                # åˆä½µæ‰€æœ‰é¡å‹çš„æŸ¥è©¢
                for category in ['basic_queries', 'technical_queries', 'semantic_queries', 'edge_cases']:
                    if category in data:
                        self.test_queries.extend(data[category])
        else:
            # é è¨­æ¸¬è©¦æŸ¥è©¢
            self.test_queries = [
                "ULINK é€£æ¥å¤±æ•—",
                "æ¸¬è©¦ç’°å¢ƒæº–å‚™",
                "æ—¥èªŒæª”æ¡ˆä½ç½®",
                "OpenCV ç‰ˆæœ¬ç›¸å®¹æ€§",
                "pytest fixture ä½¿ç”¨",
                "Docker compose ç¶²è·¯é…ç½®",
                "éŒ¯èª¤ç¢¼æŸ¥è©¢",
                "æ¸¬è©¦è…³æœ¬åŸ·è¡Œ",
                "å¦‚ä½•é™¤éŒ¯ç¨‹å¼",
                "æ¸¬è©¦å¤±æ•—æ€éº¼è¾¦",
            ]
        
        print(f"âœ… è¼‰å…¥ {len(self.test_queries)} å€‹æ¸¬è©¦æŸ¥è©¢")
        return self.test_queries
    
    def run_comparison(self, query, top_k=3, threshold=0.7):
        """åŸ·è¡Œå–®æ¬¡å°æ¯”æ¸¬è©¦"""
        print(f"\nğŸ” æ¸¬è©¦æŸ¥è©¢: {query}")
        
        result = {
            'query': query,
            'timestamp': datetime.now().isoformat(),
        }
        
        # æ¸¬è©¦èˆŠç³»çµ±
        try:
            start_time = time.time()
            old_results = self.old_service.search_knowledge(
                query=query,
                limit=top_k,
                use_vector=True
            )
            old_time = (time.time() - start_time) * 1000  # è½‰æ›ç‚ºæ¯«ç§’
            
            result['old_count'] = len(old_results)
            result['old_time_ms'] = round(old_time, 2)
            
            if old_results:
                # èˆŠç³»çµ±ä½¿ç”¨ 'score' æ¬„ä½ï¼Œä¸æ˜¯ 'similarity'
                result['old_avg_similarity'] = round(
                    sum(r.get('score', r.get('similarity', 0)) for r in old_results) / len(old_results) * 100, 
                    2
                )
                result['old_avg_content_length'] = round(
                    sum(len(r.get('content', '')) for r in old_results) / len(old_results), 
                    0
                )
                result['old_best_similarity'] = round(old_results[0].get('score', old_results[0].get('similarity', 0)) * 100, 2)
            else:
                result['old_avg_similarity'] = 0
                result['old_avg_content_length'] = 0
                result['old_best_similarity'] = 0
                
            print(f"  èˆŠç³»çµ±: {len(old_results)} å€‹çµæœ, å¹³å‡ç›¸ä¼¼åº¦ {result['old_avg_similarity']:.2f}%, è€—æ™‚ {old_time:.2f}ms")
            
        except Exception as e:
            print(f"  âŒ èˆŠç³»çµ±éŒ¯èª¤: {str(e)}")
            result['old_error'] = str(e)
            result['old_count'] = 0
            result['old_time_ms'] = 0
            result['old_avg_similarity'] = 0
            result['old_avg_content_length'] = 0
            result['old_best_similarity'] = 0
        
        # æ¸¬è©¦æ–°ç³»çµ±
        try:
            start_time = time.time()
            new_results = self.new_service.search_sections(
                query=query,
                source_table='protocol_guide',
                limit=top_k,
                threshold=threshold
            )
            new_time = (time.time() - start_time) * 1000  # è½‰æ›ç‚ºæ¯«ç§’
            
            result['new_count'] = len(new_results)
            result['new_time_ms'] = round(new_time, 2)
            
            if new_results:
                result['new_avg_similarity'] = round(
                    sum(r['similarity'] for r in new_results) / len(new_results) * 100, 
                    2
                )
                result['new_avg_content_length'] = round(
                    sum(len(r.get('content', '')) for r in new_results) / len(new_results), 
                    0
                )
                result['new_best_similarity'] = round(new_results[0]['similarity'] * 100, 2)
                
                # æ–°ç³»çµ±é¡å¤–è³‡è¨Šï¼šæ®µè½å±¤ç´šåˆ†å¸ƒ
                levels = [r.get('heading_level', 0) for r in new_results]
                result['new_level_distribution'] = ','.join(map(str, levels))
            else:
                result['new_avg_similarity'] = 0
                result['new_avg_content_length'] = 0
                result['new_best_similarity'] = 0
                result['new_level_distribution'] = ''
                
            print(f"  æ–°ç³»çµ±: {len(new_results)} å€‹çµæœ, å¹³å‡ç›¸ä¼¼åº¦ {result['new_avg_similarity']:.2f}%, è€—æ™‚ {new_time:.2f}ms")
            
        except Exception as e:
            print(f"  âŒ æ–°ç³»çµ±éŒ¯èª¤: {str(e)}")
            result['new_error'] = str(e)
            result['new_count'] = 0
            result['new_time_ms'] = 0
            result['new_avg_similarity'] = 0
            result['new_avg_content_length'] = 0
            result['new_best_similarity'] = 0
            result['new_level_distribution'] = ''
        
        # è¨ˆç®—æ”¹å–„æŒ‡æ¨™
        if result['old_avg_similarity'] > 0:
            result['similarity_improvement'] = round(
                result['new_avg_similarity'] - result['old_avg_similarity'], 
                2
            )
            result['similarity_improvement_pct'] = round(
                (result['new_avg_similarity'] - result['old_avg_similarity']) / result['old_avg_similarity'] * 100,
                2
            )
        else:
            result['similarity_improvement'] = 0
            result['similarity_improvement_pct'] = 0
            
        if result['old_avg_content_length'] > 0:
            result['content_reduction_pct'] = round(
                (1 - result['new_avg_content_length'] / result['old_avg_content_length']) * 100,
                2
            )
        else:
            result['content_reduction_pct'] = 0
            
        result['time_difference_ms'] = round(result['new_time_ms'] - result['old_time_ms'], 2)
        
        # åˆ¤æ–·å‹è² 
        if result['new_avg_similarity'] > result['old_avg_similarity']:
            result['winner'] = 'æ–°ç³»çµ±'
        elif result['new_avg_similarity'] < result['old_avg_similarity']:
            result['winner'] = 'èˆŠç³»çµ±'
        else:
            result['winner'] = 'å¹³æ‰‹'
        
        print(f"  ğŸ“Š çµæœ: {result['winner']} å‹å‡º (ç›¸ä¼¼åº¦æ”¹å–„ {result['similarity_improvement']:+.2f}%, å…§å®¹ç²¾ç°¡ {result['content_reduction_pct']:.1f}%)")
        
        self.results.append(result)
        return result
    
    def run_all_tests(self, top_k=3, threshold=0.7):
        """åŸ·è¡Œæ‰€æœ‰æ¸¬è©¦"""
        print(f"\n{'='*70}")
        print(f"ğŸš€ é–‹å§‹åŸ·è¡Œå‘é‡æœå°‹ç³»çµ±å°æ¯”æ¸¬è©¦")
        print(f"{'='*70}")
        print(f"æ¸¬è©¦åƒæ•¸: top_k={top_k}, threshold={threshold}")
        print(f"æ¸¬è©¦æŸ¥è©¢æ•¸é‡: {len(self.test_queries)}")
        
        for i, query in enumerate(self.test_queries, 1):
            print(f"\n[{i}/{len(self.test_queries)}]", end=" ")
            self.run_comparison(query, top_k, threshold)
            time.sleep(0.1)  # é¿å…éåº¦æŸ¥è©¢
        
        print(f"\n{'='*70}")
        print(f"âœ… æ‰€æœ‰æ¸¬è©¦å®Œæˆ")
        print(f"{'='*70}")
    
    def generate_csv_report(self):
        """ç”Ÿæˆ CSV è©³ç´°å ±å‘Š"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        report_file = Path(__file__).parent / 'reports' / f'comparison_{timestamp}.csv'
        
        fieldnames = [
            'query', 'timestamp', 'winner',
            'old_count', 'old_avg_similarity', 'old_best_similarity', 'old_avg_content_length', 'old_time_ms',
            'new_count', 'new_avg_similarity', 'new_best_similarity', 'new_avg_content_length', 'new_time_ms',
            'new_level_distribution',
            'similarity_improvement', 'similarity_improvement_pct',
            'content_reduction_pct', 'time_difference_ms'
        ]
        
        with open(report_file, 'w', newline='', encoding='utf-8') as f:
            writer = csv.DictWriter(f, fieldnames=fieldnames)
            writer.writeheader()
            
            for result in self.results:
                # åªå¯«å…¥å­˜åœ¨çš„æ¬„ä½
                row = {k: result.get(k, '') for k in fieldnames}
                writer.writerow(row)
        
        print(f"âœ… CSV å ±å‘Šå·²ç”Ÿæˆ: {report_file}")
        return report_file
    
    def generate_markdown_report(self):
        """ç”Ÿæˆ Markdown ç¸½çµå ±å‘Š"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        report_file = Path(__file__).parent / 'reports' / f'comparison_{timestamp}.md'
        
        # è¨ˆç®—çµ±è¨ˆæŒ‡æ¨™
        total_tests = len(self.results)
        new_wins = sum(1 for r in self.results if r['winner'] == 'æ–°ç³»çµ±')
        old_wins = sum(1 for r in self.results if r['winner'] == 'èˆŠç³»çµ±')
        ties = sum(1 for r in self.results if r['winner'] == 'å¹³æ‰‹')
        
        avg_similarity_improvement = sum(r['similarity_improvement'] for r in self.results) / total_tests if total_tests > 0 else 0
        avg_content_reduction = sum(r['content_reduction_pct'] for r in self.results) / total_tests if total_tests > 0 else 0
        avg_time_diff = sum(r['time_difference_ms'] for r in self.results) / total_tests if total_tests > 0 else 0
        
        # ç”Ÿæˆå ±å‘Šå…§å®¹
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(f"# å‘é‡æœå°‹ç³»çµ±å°æ¯”æ¸¬è©¦å ±å‘Š\n\n")
            f.write(f"**æ¸¬è©¦æ™‚é–“**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            f.write(f"**æ¸¬è©¦ç‰ˆæœ¬**: Protocol Guide Vector Search System v2.0\n\n")
            f.write(f"---\n\n")
            
            f.write(f"## ğŸ“Š æ¸¬è©¦ç¸½è¦½\n\n")
            f.write(f"| æŒ‡æ¨™ | æ•¸å€¼ |\n")
            f.write(f"|------|------|\n")
            f.write(f"| æ¸¬è©¦æŸ¥è©¢ç¸½æ•¸ | {total_tests} |\n")
            f.write(f"| æ–°ç³»çµ±å‹å‡º | {new_wins} ({new_wins/total_tests*100:.1f}%) |\n")
            f.write(f"| èˆŠç³»çµ±å‹å‡º | {old_wins} ({old_wins/total_tests*100:.1f}%) |\n")
            f.write(f"| å¹³æ‰‹ | {ties} ({ties/total_tests*100:.1f}%) |\n")
            f.write(f"| å¹³å‡ç›¸ä¼¼åº¦æ”¹å–„ | {avg_similarity_improvement:+.2f}% |\n")
            f.write(f"| å¹³å‡å…§å®¹ç²¾ç°¡ | {avg_content_reduction:.1f}% |\n")
            f.write(f"| å¹³å‡æ™‚é–“å·®ç•° | {avg_time_diff:+.2f}ms |\n\n")
            
            f.write(f"---\n\n")
            
            f.write(f"## ğŸ¯ çµè«–\n\n")
            if new_wins > old_wins:
                f.write(f"âœ… **æ–°ç³»çµ±ï¼ˆæ®µè½ç´šåˆ¥æœå°‹ï¼‰é¡¯è‘—å„ªæ–¼èˆŠç³»çµ±ï¼ˆæ•´ç¯‡æ–‡æª”æœå°‹ï¼‰**\n\n")
                f.write(f"- å‹ç‡: {new_wins/total_tests*100:.1f}%\n")
                f.write(f"- ç›¸ä¼¼åº¦å¹³å‡æå‡ {avg_similarity_improvement:.2f}%\n")
                f.write(f"- å…§å®¹å¹³å‡ç²¾ç°¡ {avg_content_reduction:.1f}%\n")
                f.write(f"- å»ºè­°: **å¯ä»¥è€ƒæ…®å°‡æ–°ç³»çµ±è¨­ç‚ºé è¨­æœå°‹å¼•æ“**\n\n")
            elif new_wins == old_wins:
                f.write(f"âš–ï¸ **æ–°èˆŠç³»çµ±è¡¨ç¾ç›¸ç•¶**\n\n")
                f.write(f"- å»ºè­°: ç¹¼çºŒä¸¦è¡Œé‹è¡Œï¼Œæ ¹æ“šç”¨æˆ¶åé¥‹æ±ºå®š\n\n")
            else:
                f.write(f"âš ï¸ **èˆŠç³»çµ±ä»ç„¶è¡¨ç¾æ›´å¥½**\n\n")
                f.write(f"- å»ºè­°: ç¹¼çºŒå„ªåŒ–æ–°ç³»çµ±ï¼Œæš«ä¸åˆ‡æ›\n\n")
            
            f.write(f"---\n\n")
            
            f.write(f"## ğŸ“ˆ è©³ç´°æ•¸æ“š\n\n")
            f.write(f"### Top 10 æ”¹å–„æœ€å¤šçš„æŸ¥è©¢\n\n")
            
            # æ’åºï¼šç›¸ä¼¼åº¦æ”¹å–„æœ€å¤š
            sorted_results = sorted(self.results, key=lambda x: x['similarity_improvement'], reverse=True)[:10]
            
            f.write(f"| æ’å | æŸ¥è©¢ | èˆŠç³»çµ±ç›¸ä¼¼åº¦ | æ–°ç³»çµ±ç›¸ä¼¼åº¦ | æ”¹å–„å¹…åº¦ |\n")
            f.write(f"|------|------|--------------|--------------|----------|\n")
            for i, r in enumerate(sorted_results, 1):
                f.write(f"| {i} | {r['query']} | {r['old_avg_similarity']:.2f}% | {r['new_avg_similarity']:.2f}% | {r['similarity_improvement']:+.2f}% |\n")
            
            f.write(f"\n### Top 10 å…§å®¹ç²¾ç°¡æœ€å¤šçš„æŸ¥è©¢\n\n")
            
            # æ’åºï¼šå…§å®¹ç²¾ç°¡æœ€å¤š
            sorted_results = sorted(self.results, key=lambda x: x['content_reduction_pct'], reverse=True)[:10]
            
            f.write(f"| æ’å | æŸ¥è©¢ | èˆŠç³»çµ±é•·åº¦ | æ–°ç³»çµ±é•·åº¦ | ç²¾ç°¡å¹…åº¦ |\n")
            f.write(f"|------|------|------------|------------|----------|\n")
            for i, r in enumerate(sorted_results, 1):
                f.write(f"| {i} | {r['query']} | {r['old_avg_content_length']:.0f} å­—å…ƒ | {r['new_avg_content_length']:.0f} å­—å…ƒ | {r['content_reduction_pct']:.1f}% |\n")
            
            f.write(f"\n---\n\n")
            f.write(f"## ğŸ“ å‚™è¨»\n\n")
            f.write(f"- æ¸¬è©¦åƒæ•¸: top_k=3, threshold=0.7\n")
            f.write(f"- èˆŠç³»çµ±: æ•´ç¯‡æ–‡æª”å‘é‡æœå°‹ (document_embeddings è¡¨)\n")
            f.write(f"- æ–°ç³»çµ±: æ®µè½ç´šåˆ¥å‘é‡æœå°‹ (document_section_embeddings è¡¨)\n")
            f.write(f"- è©³ç´°æ•¸æ“šè«‹åƒè€ƒ: `comparison_{timestamp}.csv`\n\n")
        
        print(f"âœ… Markdown å ±å‘Šå·²ç”Ÿæˆ: {report_file}")
        return report_file


def main():
    """ä¸»ç¨‹å¼"""
    tester = SearchComparisonTest()
    
    # è¼‰å…¥æ¸¬è©¦æŸ¥è©¢
    tester.load_test_queries()
    
    # åŸ·è¡Œæ‰€æœ‰æ¸¬è©¦
    tester.run_all_tests(top_k=3, threshold=0.7)
    
    # ç”Ÿæˆå ±å‘Š
    csv_file = tester.generate_csv_report()
    md_file = tester.generate_markdown_report()
    
    print(f"\n{'='*70}")
    print(f"ğŸ‰ æ¸¬è©¦å®Œæˆï¼")
    print(f"{'='*70}")
    print(f"ğŸ“„ CSV å ±å‘Š: {csv_file}")
    print(f"ğŸ“„ Markdown å ±å‘Š: {md_file}")
    print(f"{'='*70}\n")


if __name__ == '__main__':
    main()
