"""
Django Management Command - èŠå¤©æ¶ˆæ¯å‘é‡åŒ–é·ç§»

æ­¤å‘½ä»¤è² è²¬ï¼š
- è™•ç†ç¾æœ‰èŠå¤©æ¶ˆæ¯æ•¸æ“šçš„å‘é‡åŒ–
- æ‰¹é‡ç”Ÿæˆå‘é‡ä¸¦å­˜å„²åˆ° chat_message_embeddings_1024 è¡¨
- åŸ·è¡Œèšé¡åˆ†æ
- æä¾›é€²åº¦å ±å‘Šå’Œçµ±è¨ˆ
"""

import logging
from typing import Dict, List
from django.core.management.base import BaseCommand, CommandError
from django.db import connection, transaction
from django.utils import timezone

# å°å…¥æ¨¡å‹
try:
    from api.models import ChatMessage, ConversationSession
    MODELS_AVAILABLE = True
except ImportError:
    MODELS_AVAILABLE = False
    print("âš ï¸ ç„¡æ³•å°å…¥ ChatMessage æ¨¡å‹")

# å°å…¥å‘é‡åŒ–æœå‹™
try:
    from library.rvt_analytics.chat_vector_service import get_chat_vector_service
    from library.rvt_analytics.chat_clustering_service import get_clustering_service
    VECTOR_SERVICES_AVAILABLE = True
except ImportError:
    VECTOR_SERVICES_AVAILABLE = False
    print("âš ï¸ ç„¡æ³•å°å…¥å‘é‡åŒ–æœå‹™")

class Command(BaseCommand):
    help = 'æ‰¹é‡è™•ç†èŠå¤©æ¶ˆæ¯å‘é‡åŒ–å’Œèšé¡åˆ†æ'
    
    def add_arguments(self, parser):
        parser.add_argument(
            '--batch-size',
            type=int,
            default=50,
            help='æ‰¹é‡è™•ç†å¤§å°ï¼ˆé è¨­: 50ï¼‰'
        )
        
        parser.add_argument(
            '--user-role',
            type=str,
            default='user',
            choices=['user', 'assistant', 'all'],
            help='è™•ç†çš„æ¶ˆæ¯è§’è‰²ï¼ˆé è¨­: userï¼‰'
        )
        
        parser.add_argument(
            '--min-length',
            type=int,
            default=5,
            help='æœ€å°æ¶ˆæ¯é•·åº¦éæ¿¾ï¼ˆé è¨­: 5ï¼‰'
        )
        
        parser.add_argument(
            '--perform-clustering',
            action='store_true',
            help='è™•ç†å®Œæˆå¾ŒåŸ·è¡Œèšé¡åˆ†æ'
        )
        
        parser.add_argument(
            '--clustering-algorithm',
            type=str,
            default='kmeans',
            choices=['kmeans', 'dbscan'],
            help='èšé¡ç®—æ³•ï¼ˆé è¨­: kmeansï¼‰'
        )
        
        parser.add_argument(
            '--force-rebuild',
            action='store_true',
            help='å¼·åˆ¶é‡æ–°è™•ç†å·²æœ‰å‘é‡çš„æ¶ˆæ¯'
        )
        
        parser.add_argument(
            '--dry-run',
            action='store_true',
            help='åƒ…é¡¯ç¤ºè™•ç†è¨ˆåŠƒï¼Œä¸å¯¦éš›åŸ·è¡Œ'
        )
    
    def handle(self, *args, **options):
        """ä¸»è™•ç†æµç¨‹"""
        
        # æª¢æŸ¥ä¾è³´
        if not self._check_dependencies():
            return
        
        self.stdout.write(
            self.style.SUCCESS('ğŸš€ é–‹å§‹èŠå¤©æ¶ˆæ¯å‘é‡åŒ–è™•ç†')
        )
        
        # ç²å–åƒæ•¸
        batch_size = options['batch_size']
        user_role = options['user_role']
        min_length = options['min_length']
        perform_clustering = options['perform_clustering']
        clustering_algorithm = options['clustering_algorithm']
        force_rebuild = options['force_rebuild']
        dry_run = options['dry_run']
        
        self.stdout.write(f"ğŸ“‹ è™•ç†åƒæ•¸:")
        self.stdout.write(f"   - æ‰¹é‡å¤§å°: {batch_size}")
        self.stdout.write(f"   - ç”¨æˆ¶è§’è‰²: {user_role}")
        self.stdout.write(f"   - æœ€å°é•·åº¦: {min_length}")
        self.stdout.write(f"   - åŸ·è¡Œèšé¡: {perform_clustering}")
        self.stdout.write(f"   - èšé¡ç®—æ³•: {clustering_algorithm}")
        self.stdout.write(f"   - å¼·åˆ¶é‡å»º: {force_rebuild}")
        self.stdout.write(f"   - æ¨¡æ“¬åŸ·è¡Œ: {dry_run}")
        
        try:
            # åˆå§‹åŒ–æœå‹™
            vector_service = get_chat_vector_service()
            
            # ç²å–å¾…è™•ç†çš„èŠå¤©æ¶ˆæ¯
            messages = self._get_chat_messages(user_role, min_length, force_rebuild)
            
            if not messages:
                self.stdout.write(
                    self.style.WARNING('âš ï¸ æ²’æœ‰æ‰¾åˆ°éœ€è¦è™•ç†çš„èŠå¤©æ¶ˆæ¯')
                )
                return
            
            total_messages = len(messages)
            self.stdout.write(f"ğŸ“Š æ‰¾åˆ° {total_messages} æ¢å¾…è™•ç†æ¶ˆæ¯")
            
            if dry_run:
                self.stdout.write(
                    self.style.WARNING('ğŸ” æ¨¡æ“¬åŸ·è¡Œæ¨¡å¼ï¼Œä¸æœƒå¯¦éš›è™•ç†æ•¸æ“š')
                )
                self._show_processing_plan(messages, batch_size)
                return
            
            # æ‰¹é‡è™•ç†å‘é‡åŒ–
            results = self._process_vectorization(messages, vector_service, batch_size)
            
            # é¡¯ç¤ºè™•ç†çµæœ
            self._show_vectorization_results(results)
            
            # åŸ·è¡Œèšé¡åˆ†æï¼ˆå¦‚æœæŒ‡å®šï¼‰
            if perform_clustering and results['successful'] > 0:
                self.stdout.write("\nğŸ§  é–‹å§‹åŸ·è¡Œèšé¡åˆ†æ...")
                clustering_results = self._perform_clustering_analysis(clustering_algorithm)
                self._show_clustering_results(clustering_results)
            
            # é¡¯ç¤ºæœ€çµ‚çµ±è¨ˆ
            self._show_final_stats(vector_service)
            
            self.stdout.write(
                self.style.SUCCESS('\nâœ… èŠå¤©æ¶ˆæ¯å‘é‡åŒ–è™•ç†å®Œæˆ!')
            )
            
        except Exception as e:
            self.stdout.write(
                self.style.ERROR(f'âŒ è™•ç†éç¨‹ç™¼ç”ŸéŒ¯èª¤: {str(e)}')
            )
            raise CommandError(f'å‘é‡åŒ–è™•ç†å¤±æ•—: {str(e)}')
    
    def _check_dependencies(self) -> bool:
        """æª¢æŸ¥ä¾è³´æ˜¯å¦å¯ç”¨"""
        if not MODELS_AVAILABLE:
            self.stdout.write(
                self.style.ERROR('âŒ ChatMessage æ¨¡å‹ä¸å¯ç”¨')
            )
            return False
        
        if not VECTOR_SERVICES_AVAILABLE:
            self.stdout.write(
                self.style.ERROR('âŒ å‘é‡åŒ–æœå‹™ä¸å¯ç”¨')
            )
            return False
        
        # æª¢æŸ¥è³‡æ–™åº«è¡¨æ˜¯å¦å­˜åœ¨
        try:
            with connection.cursor() as cursor:
                cursor.execute("""
                    SELECT COUNT(*) FROM information_schema.tables 
                    WHERE table_name = 'chat_message_embeddings_1024'
                """)
                if cursor.fetchone()[0] == 0:
                    self.stdout.write(
                        self.style.ERROR('âŒ chat_message_embeddings_1024 è¡¨ä¸å­˜åœ¨')
                    )
                    return False
        except Exception as e:
            self.stdout.write(
                self.style.ERROR(f'âŒ è³‡æ–™åº«æª¢æŸ¥å¤±æ•—: {str(e)}')
            )
            return False
        
        return True
    
    def _get_chat_messages(self, user_role: str, min_length: int, 
                          force_rebuild: bool) -> List[Dict]:
        """ç²å–å¾…è™•ç†çš„èŠå¤©æ¶ˆæ¯"""
        try:
            # æ§‹å»ºæŸ¥è©¢æ¢ä»¶
            role_filter = ""
            if user_role != 'all':
                role_filter = f"AND cm.role = '{user_role}'"
            
            # å¦‚æœä¸å¼·åˆ¶é‡å»ºï¼Œæ’é™¤å·²è™•ç†çš„æ¶ˆæ¯
            exclude_processed = ""
            if not force_rebuild:
                exclude_processed = """
                AND NOT EXISTS (
                    SELECT 1 FROM chat_message_embeddings_1024 ce 
                    WHERE ce.chat_message_id = cm.id
                )
                """
            
            with connection.cursor() as cursor:
                cursor.execute(f"""
                    SELECT 
                        cm.id,
                        cm.conversation_id,
                        cm.content,
                        cm.role,
                        LENGTH(cm.content) as content_length,
                        cm.created_at
                    FROM chat_messages cm
                    WHERE LENGTH(cm.content) >= %s
                    {role_filter}
                    {exclude_processed}
                    ORDER BY cm.created_at DESC
                """, [min_length])
                
                columns = [col[0] for col in cursor.description]
                results = []
                
                for row in cursor.fetchall():
                    message_data = dict(zip(columns, row))
                    results.append(message_data)
                
                return results
                
        except Exception as e:
            self.stdout.write(
                self.style.ERROR(f'âŒ ç²å–èŠå¤©æ¶ˆæ¯å¤±æ•—: {str(e)}')
            )
            return []
    
    def _show_processing_plan(self, messages: List[Dict], batch_size: int):
        """é¡¯ç¤ºè™•ç†è¨ˆåŠƒ"""
        total_messages = len(messages)
        total_batches = (total_messages + batch_size - 1) // batch_size
        
        self.stdout.write(f"\nğŸ“‹ è™•ç†è¨ˆåŠƒ:")
        self.stdout.write(f"   - ç¸½æ¶ˆæ¯æ•¸: {total_messages}")
        self.stdout.write(f"   - æ‰¹é‡å¤§å°: {batch_size}")
        self.stdout.write(f"   - ç¸½æ‰¹æ¬¡æ•¸: {total_batches}")
        
        # è§’è‰²åˆ†å¸ƒ
        role_counts = {}
        for msg in messages:
            role = msg.get('role', 'unknown')
            role_counts[role] = role_counts.get(role, 0) + 1
        
        self.stdout.write(f"\nğŸ‘¥ è§’è‰²åˆ†å¸ƒ:")
        for role, count in role_counts.items():
            self.stdout.write(f"   - {role}: {count}")
        
        # é•·åº¦åˆ†å¸ƒ
        lengths = [msg.get('content_length', 0) for msg in messages]
        if lengths:
            avg_length = sum(lengths) / len(lengths)
            min_length = min(lengths)
            max_length = max(lengths)
            
            self.stdout.write(f"\nğŸ“ æ¶ˆæ¯é•·åº¦çµ±è¨ˆ:")
            self.stdout.write(f"   - å¹³å‡é•·åº¦: {avg_length:.1f}")
            self.stdout.write(f"   - æœ€çŸ­é•·åº¦: {min_length}")
            self.stdout.write(f"   - æœ€é•·é•·åº¦: {max_length}")
    
    def _process_vectorization(self, messages: List[Dict], 
                             vector_service, batch_size: int) -> Dict:
        """æ‰¹é‡è™•ç†å‘é‡åŒ–"""
        total_messages = len(messages)
        processed = 0
        successful = 0
        failed = 0
        errors = []
        
        self.stdout.write(f"\nğŸ”„ é–‹å§‹æ‰¹é‡å‘é‡åŒ–è™•ç†...")
        
        # åˆ†æ‰¹è™•ç†
        for i in range(0, total_messages, batch_size):
            batch = messages[i:i + batch_size]
            batch_num = (i // batch_size) + 1
            total_batches = (total_messages + batch_size - 1) // batch_size
            
            self.stdout.write(
                f"âš¡ è™•ç†æ‰¹æ¬¡ {batch_num}/{total_batches} "
                f"({len(batch)} æ¢æ¶ˆæ¯)..."
            )
            
            # è™•ç†ç•¶å‰æ‰¹æ¬¡
            for msg in batch:
                try:
                    success = vector_service.generate_and_store_vector(
                        chat_message_id=msg['id'],
                        content=msg['content'],
                        conversation_id=msg.get('conversation_id'),
                        user_role=msg.get('role', 'user')
                    )
                    
                    if success:
                        successful += 1
                    else:
                        failed += 1
                        
                    processed += 1
                    
                    # é¡¯ç¤ºé€²åº¦
                    if processed % 10 == 0:
                        progress = (processed / total_messages) * 100
                        self.stdout.write(
                            f"   é€²åº¦: {processed}/{total_messages} ({progress:.1f}%)"
                        )
                
                except Exception as e:
                    failed += 1
                    processed += 1
                    errors.append({
                        'message_id': msg['id'],
                        'error': str(e)
                    })
                    self.stdout.write(
                        self.style.WARNING(f"   âš ï¸ æ¶ˆæ¯ {msg['id']} è™•ç†å¤±æ•—: {str(e)}")
                    )
        
        return {
            'total_processed': processed,
            'successful': successful,
            'failed': failed,
            'errors': errors
        }
    
    def _show_vectorization_results(self, results: Dict):
        """é¡¯ç¤ºå‘é‡åŒ–è™•ç†çµæœ"""
        self.stdout.write(f"\nğŸ“Š å‘é‡åŒ–è™•ç†çµæœ:")
        self.stdout.write(f"   - ç¸½è™•ç†æ•¸: {results['total_processed']}")
        self.stdout.write(f"   - æˆåŠŸæ•¸é‡: {results['successful']}")
        self.stdout.write(f"   - å¤±æ•—æ•¸é‡: {results['failed']}")
        
        if results['successful'] > 0:
            success_rate = (results['successful'] / results['total_processed']) * 100
            self.stdout.write(
                self.style.SUCCESS(f"   - æˆåŠŸç‡: {success_rate:.1f}%")
            )
        
        if results['errors']:
            self.stdout.write(
                self.style.WARNING(f"   - éŒ¯èª¤è©³æƒ…: {len(results['errors'])} å€‹éŒ¯èª¤")
            )
    
    def _perform_clustering_analysis(self, algorithm: str) -> Dict:
        """åŸ·è¡Œèšé¡åˆ†æ"""
        try:
            clustering_service = get_clustering_service()
            results = clustering_service.perform_clustering_analysis(algorithm)
            return results
            
        except Exception as e:
            self.stdout.write(
                self.style.ERROR(f'âŒ èšé¡åˆ†æå¤±æ•—: {str(e)}')
            )
            return {'error': str(e)}
    
    def _show_clustering_results(self, results: Dict):
        """é¡¯ç¤ºèšé¡åˆ†æçµæœ"""
        if 'error' in results:
            self.stdout.write(
                self.style.ERROR(f"âŒ èšé¡åˆ†æéŒ¯èª¤: {results['error']}")
            )
            return
        
        summary = results.get('analysis_summary', {})
        
        self.stdout.write(f"\nğŸ§  èšé¡åˆ†æçµæœ:")
        self.stdout.write(f"   - ç¸½æ¶ˆæ¯æ•¸: {summary.get('total_messages', 0)}")
        self.stdout.write(f"   - èšé¡æ•¸é‡: {summary.get('n_clusters', 0)}")
        self.stdout.write(f"   - ä½¿ç”¨ç®—æ³•: {summary.get('algorithm_used', 'unknown')}")
        self.stdout.write(f"   - ç”Ÿæˆé¡åˆ¥: {summary.get('categories_generated', 0)}")
        
        # é¡¯ç¤ºé¡åˆ¥å»ºè­°
        categories = results.get('category_suggestions', {})
        if categories:
            self.stdout.write(f"\nğŸ·ï¸ è‡ªå‹•ç”Ÿæˆé¡åˆ¥:")
            for cluster_id, cat_info in categories.items():
                category = cat_info.get('category', 'unknown')
                confidence = cat_info.get('confidence', 0)
                keywords = cat_info.get('keywords', [])
                
                self.stdout.write(
                    f"   - èšé¡ {cluster_id}: {category} "
                    f"(ä¿¡å¿ƒåº¦: {confidence:.2f}, é—œéµå­—: {', '.join(keywords[:3])})"
                )
    
    def _show_final_stats(self, vector_service):
        """é¡¯ç¤ºæœ€çµ‚çµ±è¨ˆ"""
        try:
            stats = vector_service.get_embedding_stats()
            basic_stats = stats.get('basic_stats', {})
            
            self.stdout.write(f"\nğŸ“ˆ æœ€çµ‚çµ±è¨ˆ:")
            self.stdout.write(f"   - ç¸½å‘é‡æ•¸: {basic_stats.get('total_embeddings', 0)}")
            self.stdout.write(f"   - ç”¨æˆ¶æ¶ˆæ¯: {basic_stats.get('user_messages', 0)}")
            self.stdout.write(f"   - AI æ¶ˆæ¯: {basic_stats.get('assistant_messages', 0)}")
            self.stdout.write(f"   - å·²åˆ†é¡æ•¸: {basic_stats.get('categorized_messages', 0)}")
            self.stdout.write(f"   - å·²èšé¡æ•¸: {basic_stats.get('clustered_messages', 0)}")
            
            # èªè¨€åˆ†å¸ƒ
            lang_dist = stats.get('language_distribution', {})
            if lang_dist:
                self.stdout.write(f"\nğŸŒ èªè¨€åˆ†å¸ƒ:")
                for lang, count in lang_dist.items():
                    self.stdout.write(f"   - {lang}: {count}")
            
            # é¡åˆ¥åˆ†å¸ƒ
            cat_dist = stats.get('category_distribution', {})
            if cat_dist:
                self.stdout.write(f"\nğŸ·ï¸ é¡åˆ¥åˆ†å¸ƒ (å‰5å):")
                sorted_categories = sorted(cat_dist.items(), key=lambda x: x[1], reverse=True)[:5]
                for category, count in sorted_categories:
                    self.stdout.write(f"   - {category}: {count}")
                    
        except Exception as e:
            self.stdout.write(
                self.style.WARNING(f'âš ï¸ ç²å–æœ€çµ‚çµ±è¨ˆå¤±æ•—: {str(e)}')
            )