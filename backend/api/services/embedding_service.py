"""
é–‹æºå‘é‡åµŒå…¥æœå‹™ - æ›¿ä»£ OpenAI Embedding API
ä½¿ç”¨ Sentence Transformers ä¾†ç”Ÿæˆå‘é‡åµŒå…¥
"""
import logging
from typing import List, Optional, Union
import numpy as np
from sentence_transformers import SentenceTransformer
import hashlib
from django.conf import settings
from django.db import connection
import json

logger = logging.getLogger(__name__)

class OpenSourceEmbeddingService:
    """é–‹æºåµŒå…¥æœå‹™ - ä½¿ç”¨ Sentence Transformers"""
    
    # é å®šç¾©æ¨¡å‹é…ç½®
    MODEL_CONFIGS = {
        'lightweight': {
            'name': 'paraphrase-multilingual-MiniLM-L12-v2',
            'dimension': 384,
            'description': 'è¼•é‡ç´šå¤šèªè¨€æ¨¡å‹ï¼Œå¹³è¡¡æ•ˆèƒ½èˆ‡ç²¾æº–åº¦'
        },
        'standard': {
            'name': 'paraphrase-multilingual-mpnet-base-v2', 
            'dimension': 768,
            'description': 'æ¨™æº–å¤šèªè¨€æ¨¡å‹ï¼Œæ›´é«˜ç²¾æº–åº¦'
        },
        'high_precision': {
            'name': 'sentence-transformers/all-mpnet-base-v2',
            'dimension': 768,
            'description': 'é«˜ç²¾æº–åº¦æ¨¡å‹ï¼Œä¸»è¦æ”¯æ´è‹±æ–‡'
        },
        'ultra_high': {
            'name': 'intfloat/multilingual-e5-large',
            'dimension': 1024,
            'description': 'è¶…é«˜ç²¾æº–åº¦å¤šèªè¨€æ¨¡å‹ï¼Œ1024ç¶­å‘é‡'
        },
        'maximum': {
            'name': 'sentence-transformers/all-MiniLM-L6-v2',
            'dimension': 384,
            'description': 'æ¸¬è©¦ç”¨ - å¯æ“´å±•åˆ°1536ç¶­'
        }
    }
    
    def __init__(self, model_type: str = 'ultra_high'):
        """
        åˆå§‹åŒ–åµŒå…¥æœå‹™
        
        Args:
            model_type: æ¨¡å‹é¡å‹ (é è¨­: 'ultra_high' - 1024ç¶­å¤šèªè¨€æ¨¡å‹)
                       å¯é¸: 'lightweight' (384ç¶­), 'standard' (768ç¶­), 'high_precision' (768ç¶­)
        """
        if model_type not in self.MODEL_CONFIGS:
            # å¦‚æœæ˜¯èˆŠçš„æ¨¡å‹åç¨±ï¼Œå›é€€åˆ° ultra_high
            if isinstance(model_type, str) and 'MiniLM' in model_type:
                model_type = 'lightweight'
            else:
                model_type = 'ultra_high'  # é è¨­ä½¿ç”¨ 1024 ç¶­æ¨¡å‹ï¼ˆèˆ‡è³‡æ–™åº«ä¸€è‡´ï¼‰
            
        config = self.MODEL_CONFIGS[model_type]
        self.model_name = config['name']
        self.embedding_dimension = config['dimension']
        self.model_type = model_type
        self._model = None
        
        logger.info(f"é¸æ“‡åµŒå…¥æ¨¡å‹: {config['description']} ({self.embedding_dimension}ç¶­)")
        
    @property
    def model(self):
        """å»¶é²è¼‰å…¥æ¨¡å‹"""
        if self._model is None:
            logger.info(f"è¼‰å…¥ Sentence Transformers æ¨¡å‹: {self.model_name}")
            try:
                self._model = SentenceTransformer(self.model_name)
                logger.info("æ¨¡å‹è¼‰å…¥æˆåŠŸ")
            except Exception as e:
                logger.error(f"æ¨¡å‹è¼‰å…¥å¤±æ•—: {str(e)}")
                raise
        return self._model
    
    def generate_embedding(self, text: str) -> List[float]:
        """
        ç‚ºå–®å€‹æ–‡æœ¬ç”Ÿæˆå‘é‡åµŒå…¥
        
        Args:
            text: è¦è™•ç†çš„æ–‡æœ¬
            
        Returns:
            å‘é‡åµŒå…¥åˆ—è¡¨
        """
        try:
            if not text or not text.strip():
                return [0.0] * self.embedding_dimension
                
            # ä½¿ç”¨æ¨¡å‹ç”ŸæˆåµŒå…¥
            embedding = self.model.encode(text.strip())
            
            # ç¢ºä¿è¿”å› Python åˆ—è¡¨æ ¼å¼
            if isinstance(embedding, np.ndarray):
                embedding = embedding.tolist()
                
            return embedding
            
        except Exception as e:
            logger.error(f"ç”ŸæˆåµŒå…¥å¤±æ•—: {str(e)}")
            # è¿”å›é›¶å‘é‡ä½œç‚ºå‚™ç”¨
            return [0.0] * self.embedding_dimension
    
    def generate_embeddings_batch(self, texts: List[str]) -> List[List[float]]:
        """
        æ‰¹é‡ç”Ÿæˆå‘é‡åµŒå…¥
        
        Args:
            texts: æ–‡æœ¬åˆ—è¡¨
            
        Returns:
            å‘é‡åµŒå…¥åˆ—è¡¨çš„åˆ—è¡¨
        """
        try:
            if not texts:
                return []
                
            # éæ¿¾ç©ºæ–‡æœ¬
            valid_texts = [text.strip() for text in texts if text and text.strip()]
            
            if not valid_texts:
                return [[0.0] * self.embedding_dimension] * len(texts)
            
            # æ‰¹é‡ç”ŸæˆåµŒå…¥
            embeddings = self.model.encode(valid_texts)
            
            # è½‰æ›ç‚º Python åˆ—è¡¨æ ¼å¼
            if isinstance(embeddings, np.ndarray):
                embeddings = embeddings.tolist()
                
            return embeddings
            
        except Exception as e:
            logger.error(f"æ‰¹é‡ç”ŸæˆåµŒå…¥å¤±æ•—: {str(e)}")
            # è¿”å›é›¶å‘é‡ä½œç‚ºå‚™ç”¨
            return [[0.0] * self.embedding_dimension] * len(texts)
    
    def get_content_hash(self, content: str) -> str:
        """ç”Ÿæˆå…§å®¹å“ˆå¸Œå€¼ï¼Œç”¨æ–¼æª¢æŸ¥å…§å®¹æ˜¯å¦è®Šæ›´"""
        return hashlib.md5(content.encode('utf-8')).hexdigest()
    
    def store_document_embedding(self, source_table: str, source_id: int, content: str, use_1024_table: bool = False) -> bool:
        """
        å­˜å„²æ–‡æª”åµŒå…¥åˆ°è³‡æ–™åº«
        
        Args:
            source_table: ä¾†æºè¡¨å
            source_id: ä¾†æºè¨˜éŒ„ID
            content: æ–‡æª”å…§å®¹
            use_1024_table: æ˜¯å¦ä½¿ç”¨ 1024 ç¶­è¡¨æ ¼
            
        Returns:
            æ˜¯å¦æˆåŠŸå­˜å„²
        """
        try:
            # ç”Ÿæˆå…§å®¹å“ˆå¸Œ
            content_hash = self.get_content_hash(content)
            
            # é¸æ“‡ç›®æ¨™è¡¨æ ¼
            # æ³¨æ„ï¼šdocument_embeddings è¡¨å·²ç¶“æ˜¯ 1024 ç¶­ï¼Œçµ±ä¸€ä½¿ç”¨å®ƒ
            target_table = 'document_embeddings'
            
            # æª¢æŸ¥æ˜¯å¦å·²å­˜åœ¨ä¸”å…§å®¹æœªè®Šæ›´
            with connection.cursor() as cursor:
                cursor.execute(f"""
                    SELECT content_hash FROM {target_table}
                    WHERE source_table = %s AND source_id = %s
                """, [source_table, source_id])
                
                existing = cursor.fetchone()
                if existing and existing[0] == content_hash:
                    logger.info(f"æ–‡æª” {source_table}:{source_id} å…§å®¹æœªè®Šæ›´ï¼Œè·³éåµŒå…¥ç”Ÿæˆ")
                    return True
            
            # ç”ŸæˆåµŒå…¥å‘é‡
            embedding = self.generate_embedding(content)
            
            # å­˜å„²åˆ°è³‡æ–™åº«
            with connection.cursor() as cursor:
                cursor.execute(f"""
                    INSERT INTO {target_table} (source_table, source_id, text_content, content_hash, embedding)
                    VALUES (%s, %s, %s, %s, %s)
                    ON CONFLICT (source_table, source_id)
                    DO UPDATE SET 
                        text_content = EXCLUDED.text_content,
                        content_hash = EXCLUDED.content_hash,
                        embedding = EXCLUDED.embedding,
                        updated_at = CURRENT_TIMESTAMP
                """, [source_table, source_id, content, content_hash, json.dumps(embedding)])
                
            logger.info(f"æˆåŠŸå­˜å„²æ–‡æª”åµŒå…¥åˆ° {target_table}: {source_table}:{source_id}")
            return True
            
        except Exception as e:
            logger.error(f"å­˜å„²æ–‡æª”åµŒå…¥å¤±æ•—: {str(e)}")
            return False
    
    def delete_document_embedding(self, source_table: str, source_id: int, use_1024_table: bool = False) -> bool:
        """
        åˆªé™¤æŒ‡å®šæ–‡æª”çš„å‘é‡åµŒå…¥
        
        Args:
            source_table: ä¾†æºè¡¨å
            source_id: ä¾†æºè¨˜éŒ„ID
            use_1024_table: æ˜¯å¦ä½¿ç”¨ 1024 ç¶­è¡¨æ ¼
            
        Returns:
            æ˜¯å¦æˆåŠŸåˆªé™¤
        """
        try:
            # é¸æ“‡ç›®æ¨™è¡¨æ ¼
            # æ³¨æ„ï¼šdocument_embeddings è¡¨å·²ç¶“æ˜¯ 1024 ç¶­ï¼Œçµ±ä¸€ä½¿ç”¨å®ƒ
            target_table = 'document_embeddings'
            
            # åˆªé™¤å‘é‡è¨˜éŒ„
            with connection.cursor() as cursor:
                cursor.execute(f"""
                    DELETE FROM {target_table}
                    WHERE source_table = %s AND source_id = %s
                """, [source_table, source_id])
                
                deleted_count = cursor.rowcount
                
            if deleted_count > 0:
                table_name = "1024ç¶­" if use_1024_table else "768ç¶­"
                logger.info(f"æˆåŠŸåˆªé™¤æ–‡æª”åµŒå…¥ ({table_name}): {source_table}:{source_id}")
                return True
            else:
                logger.warning(f"æœªæ‰¾åˆ°è¦åˆªé™¤çš„æ–‡æª”åµŒå…¥: {source_table}:{source_id}")
                return False
                
        except Exception as e:
            logger.error(f"åˆªé™¤æ–‡æª”åµŒå…¥å¤±æ•—: {str(e)}")
            return False
    
    def search_similar_documents(self, query: str, source_table: str = None, limit: int = 5, threshold: float = 0.0, use_1024_table: bool = False) -> List[dict]:
        """
        æœç´¢ç›¸ä¼¼æ–‡æª”
        
        Args:
            query: æŸ¥è©¢æ–‡æœ¬
            source_table: é™åˆ¶æœç´¢çš„ä¾†æºè¡¨ï¼ˆå¯é¸ï¼‰
            limit: è¿”å›çµæœæ•¸é‡é™åˆ¶
            threshold: ç›¸ä¼¼åº¦é–¾å€¼
            use_1024_table: æ˜¯å¦ä½¿ç”¨ 1024 ç¶­è¡¨æ ¼
            
        Returns:
            ç›¸ä¼¼æ–‡æª”åˆ—è¡¨
        """
        try:
            # ç”ŸæˆæŸ¥è©¢å‘é‡
            query_embedding = self.generate_embedding(query)
            
            # é¸æ“‡ç›®æ¨™è¡¨æ ¼
            # æ³¨æ„ï¼šdocument_embeddings è¡¨å·²ç¶“æ˜¯ 1024 ç¶­ï¼Œçµ±ä¸€ä½¿ç”¨å®ƒ
            target_table = 'document_embeddings'
            
            # æ§‹å»º SQL æŸ¥è©¢
            sql_parts = []
            params = []
            
            if source_table:
                sql_parts.append("WHERE de.source_table = %s")
                params.append(source_table)
            
            sql = f"""
                SELECT 
                    de.source_table,
                    de.source_id,
                    1 - (de.embedding <=> %s) as similarity_score,
                    de.created_at,
                    de.updated_at
                FROM {target_table} de
                {' '.join(sql_parts)}
                ORDER BY de.embedding <=> %s
                LIMIT %s
            """
            
            params = [json.dumps(query_embedding)] + params + [json.dumps(query_embedding), limit]
            
            results = []
            with connection.cursor() as cursor:
                cursor.execute(sql, params)
                
                for row in cursor.fetchall():
                    source_table_name, source_id, similarity_score, created_at, updated_at = row
                    
                    # éæ¿¾ä½æ–¼é–¾å€¼çš„çµæœ
                    if similarity_score >= threshold:
                        results.append({
                            'source_table': source_table_name,
                            'source_id': source_id,
                            'similarity_score': float(similarity_score),
                            'created_at': created_at,
                            'updated_at': updated_at
                        })
            
            table_name = "1024ç¶­" if use_1024_table else "768ç¶­"
            logger.info(f"å‘é‡æœç´¢å®Œæˆ ({table_name})ï¼Œè¿”å› {len(results)} å€‹çµæœ")
            return results
            
        except Exception as e:
            logger.error(f"å‘é‡æœç´¢å¤±æ•—: {str(e)}")
            return []
    
    def store_document_embeddings_multi(
        self, 
        source_table: str, 
        source_id: int, 
        title: str,
        content: str,
        use_1024_table: bool = True
    ) -> bool:
        """
        ç‚ºæ–‡æª”ç”Ÿæˆä¸¦å­˜å„²æ¨™é¡Œå’Œå…§å®¹å‘é‡ï¼ˆæ–¹æ¡ˆ Aï¼šå¤šå‘é‡æ–¹æ³•ï¼‰
        
        Args:
            source_table: ä¾†æºè¡¨å
            source_id: ä¾†æºè¨˜éŒ„ ID
            title: æ¨™é¡Œæ–‡æœ¬
            content: å…§å®¹æ–‡æœ¬
            use_1024_table: æ˜¯å¦ä½¿ç”¨ 1024 ç¶­è¡¨ï¼ˆå›ºå®šç‚º Trueï¼‰
        
        Returns:
            bool: æ˜¯å¦æˆåŠŸ
        """
        try:
            # ç”Ÿæˆæ¨™é¡Œå‘é‡
            logger.info(f"ç”Ÿæˆæ¨™é¡Œå‘é‡: {source_table} ID {source_id}")
            title_embedding = self.generate_embedding(title) if title else [0.0] * self.embedding_dimension
            
            # ç”Ÿæˆå…§å®¹å‘é‡
            logger.info(f"ç”Ÿæˆå…§å®¹å‘é‡: {source_table} ID {source_id}")
            content_embedding = self.generate_embedding(content) if content else [0.0] * self.embedding_dimension
            
            # è¨ˆç®—å…§å®¹é›œæ¹Šï¼ˆç”¨æ–¼æª¢æ¸¬è®Šæ›´ï¼‰
            combined_content = f"{title}|{content}"
            content_hash = hashlib.sha256(combined_content.encode()).hexdigest()
            
            # å­˜å„²åˆ°è³‡æ–™åº«ï¼ˆdocument_embeddings è¡¨ï¼‰
            with connection.cursor() as cursor:
                cursor.execute(
                    """
                    INSERT INTO document_embeddings 
                        (source_table, source_id, text_content, content_hash, 
                         title_embedding, content_embedding, embedding)
                    VALUES (%s, %s, %s, %s, %s, %s, %s)
                    ON CONFLICT (source_table, source_id) 
                    DO UPDATE SET
                        text_content = EXCLUDED.text_content,
                        content_hash = EXCLUDED.content_hash,
                        title_embedding = EXCLUDED.title_embedding,
                        content_embedding = EXCLUDED.content_embedding,
                        embedding = EXCLUDED.embedding,
                        updated_at = CURRENT_TIMESTAMP;
                    """,
                    [
                        source_table,
                        source_id,
                        combined_content[:10000],  # å„²å­˜å‰ 10000 å­—å…ƒï¼ˆæå‡ 10 å€ï¼Œæ¶µè“‹å¤§éƒ¨åˆ†æ–‡ç« ï¼‰
                        content_hash,
                        json.dumps(title_embedding),
                        json.dumps(content_embedding),
                        json.dumps(title_embedding),  # ä¿ç•™èˆŠçš„ embedding æ¬„ä½ï¼ˆå‘å¾Œå…¼å®¹ï¼‰
                    ]
                )
            
            logger.info(f"âœ… å¤šå‘é‡å­˜å„²æˆåŠŸ: {source_table} ID {source_id}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ å¤šå‘é‡å­˜å„²å¤±æ•—: {source_table} ID {source_id}, éŒ¯èª¤: {str(e)}")
            return False
    
    def search_similar_documents_multi(
        self, 
        query: str, 
        source_table: str = None, 
        limit: int = 5, 
        threshold: float = 0.0,
        title_weight: float = 0.6,
        content_weight: float = 0.4
    ) -> List[dict]:
        """
        ä½¿ç”¨å¤šå‘é‡æ–¹æ³•æœç´¢ç›¸ä¼¼æ–‡æª”ï¼ˆæ–¹æ¡ˆ Aï¼šæ¨™é¡Œ/å…§å®¹åˆ†é–‹è¨ˆç®—ï¼‰
        
        Args:
            query: æŸ¥è©¢æ–‡æœ¬
            source_table: é™åˆ¶æœç´¢çš„ä¾†æºè¡¨
            limit: è¿”å›çµæœæ•¸é‡
            threshold: ç›¸ä¼¼åº¦é–¾å€¼
            title_weight: æ¨™é¡Œæ¬Šé‡ (0.0 ~ 1.0)
            content_weight: å…§å®¹æ¬Šé‡ (0.0 ~ 1.0)
        
        Returns:
            ç›¸ä¼¼æ–‡æª”åˆ—è¡¨ï¼ˆåŒ…å« title_score, content_score, final_scoreï¼‰
        """
        try:
            # ç”ŸæˆæŸ¥è©¢å‘é‡
            query_embedding = self.generate_embedding(query)
            embedding_json = json.dumps(query_embedding)
            
            # æ§‹å»º SQL æŸ¥è©¢
            sql_parts = []
            params = []
            
            if source_table:
                sql_parts.append("WHERE de.source_table = %s")
                params.append(source_table)
            
            sql = f"""
                SELECT 
                    de.source_table,
                    de.source_id,
                    -- æ¨™é¡Œç›¸ä¼¼åº¦
                    1 - (de.title_embedding <=> %s::vector) as title_score,
                    -- å…§å®¹ç›¸ä¼¼åº¦
                    1 - (de.content_embedding <=> %s::vector) as content_score,
                    -- åŠ æ¬Šæœ€çµ‚åˆ†æ•¸
                    (%s * (1 - (de.title_embedding <=> %s::vector))) + 
                    (%s * (1 - (de.content_embedding <=> %s::vector))) as final_score,
                    de.created_at,
                    de.updated_at
                FROM document_embeddings de
                {' '.join(sql_parts)}
                ORDER BY final_score DESC
                LIMIT %s
            """
            
            # æº–å‚™åƒæ•¸
            query_params = [
                embedding_json,  # title_score
                embedding_json,  # content_score
                title_weight,    # title weight
                embedding_json,  # title weight calculation
                content_weight,  # content weight
                embedding_json,  # content weight calculation
            ]
            params = query_params + params + [limit]
            
            results = []
            with connection.cursor() as cursor:
                cursor.execute(sql, params)
                
                for row in cursor.fetchall():
                    (source_table_name, source_id, title_score, content_score, 
                     final_score, created_at, updated_at) = row
                    
                    # éæ¿¾ä½æ–¼é–¾å€¼çš„çµæœ
                    if final_score >= threshold:
                        # åˆ¤æ–·åŒ¹é…é¡å‹
                        if title_score > content_score * 1.5:
                            match_type = 'title_primary'
                        elif content_score > title_score * 1.5:
                            match_type = 'content_primary'
                        else:
                            match_type = 'balanced'
                        
                        results.append({
                            'source_table': source_table_name,
                            'source_id': source_id,
                            'title_score': float(title_score),
                            'content_score': float(content_score),
                            'similarity_score': float(final_score),  # å‘å¾Œå…¼å®¹
                            'final_score': float(final_score),
                            'match_type': match_type,
                            'weights': {
                                'title': title_weight,
                                'content': content_weight
                            },
                            'created_at': created_at,
                            'updated_at': updated_at
                        })
            
            logger.info(
                f"å¤šå‘é‡æœç´¢å®Œæˆï¼Œè¿”å› {len(results)} å€‹çµæœ "
                f"(weights: title={title_weight}, content={content_weight})"
            )
            return results
            
        except Exception as e:
            logger.error(f"å¤šå‘é‡æœç´¢å¤±æ•—: {str(e)}")
            return []

# å…¨å±€æœå‹™å¯¦ä¾‹
_embedding_service = None

def get_embedding_service(model_type: str = 'ultra_high') -> OpenSourceEmbeddingService:
    """
    ç²å–å…¨å±€åµŒå…¥æœå‹™å¯¦ä¾‹
    
    Args:
        model_type: æ¨¡å‹é¡å‹ ('lightweight', 'standard', 'high_precision', 'ultra_high')
                   - lightweight: 384ç¶­ï¼Œé€Ÿåº¦å¿«ï¼Œé©åˆå°è¦æ¨¡æ‡‰ç”¨
                   - standard: 768ç¶­ï¼Œå¹³è¡¡ç²¾æº–åº¦èˆ‡æ•ˆèƒ½
                   - high_precision: 768ç¶­ï¼Œæœ€é«˜ç²¾æº–åº¦
                   - ultra_high: 1024ç¶­ï¼Œæœ€ä½³ç²¾æº–åº¦ (é»˜èª)
    """
    global _embedding_service
    if _embedding_service is None or _embedding_service.model_type != model_type:
        logger.info(f"åˆå§‹åŒ–åµŒå…¥æœå‹™ï¼Œæ¨¡å‹é¡å‹: {model_type}")
        _embedding_service = OpenSourceEmbeddingService(model_type)
    return _embedding_service

def search_rvt_guide_with_vectors(query: str, limit: int = 5, threshold: float = 0.3, search_mode: str = 'auto') -> List[dict]:
    """
    ä½¿ç”¨å‘é‡æœç´¢ RVT Guide (1024ç¶­ - é è¨­)
    
    âš ï¸ å‘å¾Œå…¼å®¹å‡½æ•¸ - å·²é‡æ§‹ä½¿ç”¨ RVTGuideSearchService
    ğŸ”— æ–°ä»£ç¢¼å»ºè­°ç›´æ¥ä½¿ç”¨ RVTGuideSearchService.search_knowledge()
    
    Args:
        query: æŸ¥è©¢æ–‡æœ¬
        limit: è¿”å›çµæœæ•¸é‡
        threshold: ç›¸ä¼¼åº¦é–¾å€¼
        search_mode: æœç´¢æ¨¡å¼ ('auto', 'section_only', 'document_only')
        
    Returns:
        æœç´¢çµæœåˆ—è¡¨
    """
    from library.rvt_guide.search_service import RVTGuideSearchService
    
    # âœ… ä½¿ç”¨ RVTGuideSearchServiceï¼ˆæ”¯æ´ search_modeï¼‰
    service = RVTGuideSearchService()
    return service.search_with_vectors(
        query=query,
        limit=limit,
        threshold=threshold,
        search_mode=search_mode
    )

# âœ… 768ç¶­ç›¸é—œå‡½æ•¸å·²ç§»é™¤ï¼ˆ2025-01-XXï¼‰
# åŸå› ï¼šç³»çµ±å·²å…¨é¢æ”¹ç”¨ 1024 ç¶­å‘é‡ï¼Œ768 ç¶­ç›¸é—œç¨‹å¼ç¢¼å·²å»¢æ£„
# åƒè€ƒï¼š/docs/vector-search/vector-dimension-default-change-report.md


def _format_rvt_guide_content(item):
    """
    RVT Guide ç‰¹æ®Šçš„å…§å®¹æ ¼å¼åŒ–é‚è¼¯
    
    åŒ…å«åœ–ç‰‡æª¢æ¸¬å’Œæç¤º
    """
    content = f"æ–‡æª”æ¨™é¡Œ: {item.title}\n"
    
    # æª¢æŸ¥æ˜¯å¦åŒ…å«åœ–ç‰‡
    has_images = any(keyword in item.content.lower() for keyword in [
        'ğŸ–¼ï¸', '--- ç›¸é—œåœ–ç‰‡ ---', 'åœ–ç‰‡', 'æˆªåœ–', 'image', 'picture'
    ])
    
    if has_images:
        content += "ğŸ“¸ **é‡è¦ï¼šæ­¤å…§å®¹åŒ…å«ç›¸é—œåœ–ç‰‡èªªæ˜ï¼Œè«‹åœ¨å›ç­”æ™‚æåŠä¸¦å¼•å°ç”¨æˆ¶æŸ¥çœ‹åœ–ç‰‡è³‡è¨Š**\n\n"
    
    content += f"å…§å®¹: {item.content}\n"
    return content


def search_know_issue_with_vectors(query: str, top_k: int = 5, threshold: float = 0.3) -> List[dict]:
    """
    ä½¿ç”¨å‘é‡æœç´¢ Know Issue (1024ç¶­)
    
    âš ï¸ å‘å¾Œå…¼å®¹å‡½æ•¸ - å·²é‡æ§‹ä½¿ç”¨ vector_search_helper
    ğŸ”— æ–°ä»£ç¢¼å»ºè­°ç›´æ¥ä½¿ç”¨ KnowIssueSearchService.search_knowledge()
    
    Args:
        query: æŸ¥è©¢æ–‡æœ¬
        top_k: è¿”å›çµæœæ•¸é‡
        threshold: ç›¸ä¼¼åº¦é–¾å€¼
        
    Returns:
        æœç´¢çµæœåˆ—è¡¨
    """
    from library.common.knowledge_base.vector_search_helper import search_with_vectors_generic
    from api.models import KnowIssue
    
    # ä½¿ç”¨é€šç”¨ helperï¼ˆå…§éƒ¨æœƒè‡ªå‹•è™•ç† DB æŸ¥è©¢å’Œæ ¼å¼åŒ–ï¼‰
    return search_with_vectors_generic(
        query=query,
        model_class=KnowIssue,
        source_table='know_issue',
        limit=top_k,
        threshold=threshold,
        use_1024=True
    )


def _get_know_issue_results(vector_results: List[dict], version_info: str) -> List[dict]:
    """
    âš ï¸ DEPRECATED - å·²æ£„ç”¨ï¼Œä¿ç•™ä»¥é˜²å›æ»¾éœ€è¦
    
    æ­¤å‡½æ•¸å·²è¢« vector_search_helper.format_vector_results() å–ä»£
    æ–°ä»£ç¢¼è«‹ä½¿ç”¨ search_with_vectors_generic() æˆ– KnowIssueSearchService
    
    å¾å‘é‡æœç´¢çµæœç²å– Know Issue è©³ç´°è³‡æ–™
    
    Args:
        vector_results: å‘é‡æœç´¢åŸå§‹çµæœ
        version_info: ç‰ˆæœ¬ä¿¡æ¯ï¼ˆç”¨æ–¼æ—¥èªŒï¼‰
        
    Returns:
        æ ¼å¼åŒ–çš„æœç´¢çµæœ
    """
    try:
        # æå– source_id åˆ—è¡¨
        source_ids = [result['source_id'] for result in vector_results]
        
        if not source_ids:
            return []
        
        # å¾è³‡æ–™åº«ç²å– Know Issue è©³ç´°è³‡æ–™
        with connection.cursor() as cursor:
            placeholders = ','.join(['%s'] * len(source_ids))
            cursor.execute(f"""
                SELECT 
                    ki.id, ki.issue_id, ki.project, ki.test_version,
                    ki.issue_type, ki.status, ki.error_message,
                    ki.supplement, ki.script, ki.jira_number,
                    ki.created_at, ki.updated_at,
                    tc.name as test_class_name
                FROM know_issue ki
                LEFT JOIN protocol_test_class tc ON ki.test_class_id = tc.id
                WHERE ki.id IN ({placeholders})
            """, source_ids)
            
            columns = [desc[0] for desc in cursor.description]
            know_issues = {}
            
            for row in cursor.fetchall():
                issue_data = dict(zip(columns, row))
                know_issues[issue_data['id']] = issue_data
        
        # çµ„åˆçµæœï¼Œä¿æŒå‘é‡æœç´¢çš„é †åº
        final_results = []
        for vector_result in vector_results:
            source_id = vector_result['source_id']
            if source_id in know_issues:
                issue_data = know_issues[source_id]
                
                # æ ¼å¼åŒ–å…§å®¹ç”¨æ–¼ Dify
                content = f"å•é¡Œç·¨è™Ÿ: {issue_data['issue_id']}\n"
                content += f"å°ˆæ¡ˆ: {issue_data['project']}\n"
                content += f"å•é¡Œé¡å‹: {issue_data['issue_type']}\n"
                content += f"ç‹€æ…‹: {issue_data['status']}\n"
                content += f"éŒ¯èª¤è¨Šæ¯: {issue_data['error_message']}\n"
                if issue_data['supplement']:
                    content += f"è£œå……èªªæ˜: {issue_data['supplement']}\n"
                if issue_data['script']:
                    content += f"ç›¸é—œè…³æœ¬: {issue_data['script']}\n"
                
                final_results.append({
                    'id': str(source_id),
                    'title': f"{issue_data['issue_id']} - {issue_data['project']}",
                    'content': content,
                    'score': vector_result['similarity_score'],
                    'metadata': {
                        'source': f'know_issue_vector_search_{version_info}',
                        'issue_id': issue_data['issue_id'],
                        'project': issue_data['project'],
                        'issue_type': issue_data['issue_type'],
                        'status': issue_data['status']
                    }
                })
        
        logger.info(f"å‘é‡æœç´¢è¿”å› {len(final_results)} å€‹ Know Issue çµæœ ({version_info})")
        return final_results
        
    except Exception as e:
        logger.error(f"ç²å– Know Issue è©³ç´°è³‡æ–™å¤±æ•—: {str(e)}")
        return []