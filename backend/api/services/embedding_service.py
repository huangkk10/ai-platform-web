"""
é–‹æºå‘é‡åµŒå…¥æœå‹™ - æ›¿ä»£ OpenAI Embedding API
ä½¿ç”¨ Sentence Transformers ä¾†ç”Ÿæˆå‘é‡åµŒå…¥
"""
import logging
from typing import List, Optional, Union
import numpy as np
from sentence_transformers import SentenceTransformer
import hashlib
from django.conf import settings
from django.db import connection
import json

logger = logging.getLogger(__name__)

class OpenSourceEmbeddingService:
    """é–‹æºåµŒå…¥æœå‹™ - ä½¿ç”¨ Sentence Transformers"""
    
    # é å®šç¾©æ¨¡å‹é…ç½®
    MODEL_CONFIGS = {
        'lightweight': {
            'name': 'paraphrase-multilingual-MiniLM-L12-v2',
            'dimension': 384,
            'description': 'è¼•é‡ç´šå¤šèªè¨€æ¨¡å‹ï¼Œå¹³è¡¡æ•ˆèƒ½èˆ‡ç²¾æº–åº¦'
        },
        'standard': {
            'name': 'paraphrase-multilingual-mpnet-base-v2', 
            'dimension': 768,
            'description': 'æ¨™æº–å¤šèªè¨€æ¨¡å‹ï¼Œæ›´é«˜ç²¾æº–åº¦'
        },
        'high_precision': {
            'name': 'sentence-transformers/all-mpnet-base-v2',
            'dimension': 768,
            'description': 'é«˜ç²¾æº–åº¦æ¨¡å‹ï¼Œä¸»è¦æ”¯æ´è‹±æ–‡'
        },
        'ultra_high': {
            'name': 'intfloat/multilingual-e5-large',
            'dimension': 1024,
            'description': 'è¶…é«˜ç²¾æº–åº¦å¤šèªè¨€æ¨¡å‹ï¼Œ1024ç¶­å‘é‡'
        },
        'maximum': {
            'name': 'sentence-transformers/all-MiniLM-L6-v2',
            'dimension': 384,
            'description': 'æ¸¬è©¦ç”¨ - å¯æ“´å±•åˆ°1536ç¶­'
        }
    }
    
    def __init__(self, model_type: str = 'standard'):
        """
        åˆå§‹åŒ–åµŒå…¥æœå‹™
        
        Args:
            model_type: æ¨¡å‹é¡å‹ ('lightweight', 'standard', 'high_precision')
        """
        if model_type not in self.MODEL_CONFIGS:
            # å¦‚æœæ˜¯èˆŠçš„æ¨¡å‹åç¨±ï¼Œå›é€€åˆ°è¼•é‡ç´šæ¨¡å‹
            if isinstance(model_type, str) and 'MiniLM' in model_type:
                model_type = 'lightweight'
            else:
                model_type = 'standard'  # é»˜èªä½¿ç”¨ 768 ç¶­æ¨™æº–æ¨¡å‹
            
        config = self.MODEL_CONFIGS[model_type]
        self.model_name = config['name']
        self.embedding_dimension = config['dimension']
        self.model_type = model_type
        self._model = None
        
        logger.info(f"é¸æ“‡åµŒå…¥æ¨¡å‹: {config['description']} ({self.embedding_dimension}ç¶­)")
        
    @property
    def model(self):
        """å»¶é²è¼‰å…¥æ¨¡å‹"""
        if self._model is None:
            logger.info(f"è¼‰å…¥ Sentence Transformers æ¨¡å‹: {self.model_name}")
            try:
                self._model = SentenceTransformer(self.model_name)
                logger.info("æ¨¡å‹è¼‰å…¥æˆåŠŸ")
            except Exception as e:
                logger.error(f"æ¨¡å‹è¼‰å…¥å¤±æ•—: {str(e)}")
                raise
        return self._model
    
    def generate_embedding(self, text: str) -> List[float]:
        """
        ç‚ºå–®å€‹æ–‡æœ¬ç”Ÿæˆå‘é‡åµŒå…¥
        
        Args:
            text: è¦è™•ç†çš„æ–‡æœ¬
            
        Returns:
            å‘é‡åµŒå…¥åˆ—è¡¨
        """
        try:
            if not text or not text.strip():
                return [0.0] * self.embedding_dimension
                
            # ä½¿ç”¨æ¨¡å‹ç”ŸæˆåµŒå…¥
            embedding = self.model.encode(text.strip())
            
            # ç¢ºä¿è¿”å› Python åˆ—è¡¨æ ¼å¼
            if isinstance(embedding, np.ndarray):
                embedding = embedding.tolist()
                
            return embedding
            
        except Exception as e:
            logger.error(f"ç”ŸæˆåµŒå…¥å¤±æ•—: {str(e)}")
            # è¿”å›é›¶å‘é‡ä½œç‚ºå‚™ç”¨
            return [0.0] * self.embedding_dimension
    
    def generate_embeddings_batch(self, texts: List[str]) -> List[List[float]]:
        """
        æ‰¹é‡ç”Ÿæˆå‘é‡åµŒå…¥
        
        Args:
            texts: æ–‡æœ¬åˆ—è¡¨
            
        Returns:
            å‘é‡åµŒå…¥åˆ—è¡¨çš„åˆ—è¡¨
        """
        try:
            if not texts:
                return []
                
            # éæ¿¾ç©ºæ–‡æœ¬
            valid_texts = [text.strip() for text in texts if text and text.strip()]
            
            if not valid_texts:
                return [[0.0] * self.embedding_dimension] * len(texts)
            
            # æ‰¹é‡ç”ŸæˆåµŒå…¥
            embeddings = self.model.encode(valid_texts)
            
            # è½‰æ›ç‚º Python åˆ—è¡¨æ ¼å¼
            if isinstance(embeddings, np.ndarray):
                embeddings = embeddings.tolist()
                
            return embeddings
            
        except Exception as e:
            logger.error(f"æ‰¹é‡ç”ŸæˆåµŒå…¥å¤±æ•—: {str(e)}")
            # è¿”å›é›¶å‘é‡ä½œç‚ºå‚™ç”¨
            return [[0.0] * self.embedding_dimension] * len(texts)
    
    def get_content_hash(self, content: str) -> str:
        """ç”Ÿæˆå…§å®¹å“ˆå¸Œå€¼ï¼Œç”¨æ–¼æª¢æŸ¥å…§å®¹æ˜¯å¦è®Šæ›´"""
        return hashlib.md5(content.encode('utf-8')).hexdigest()
    
    def store_document_embedding(self, source_table: str, source_id: int, content: str, use_1024_table: bool = False) -> bool:
        """
        å­˜å„²æ–‡æª”åµŒå…¥åˆ°è³‡æ–™åº«
        
        Args:
            source_table: ä¾†æºè¡¨å
            source_id: ä¾†æºè¨˜éŒ„ID
            content: æ–‡æª”å…§å®¹
            use_1024_table: æ˜¯å¦ä½¿ç”¨ 1024 ç¶­è¡¨æ ¼
            
        Returns:
            æ˜¯å¦æˆåŠŸå­˜å„²
        """
        try:
            # ç”Ÿæˆå…§å®¹å“ˆå¸Œ
            content_hash = self.get_content_hash(content)
            
            # é¸æ“‡ç›®æ¨™è¡¨æ ¼
            target_table = 'document_embeddings_1024' if use_1024_table else 'document_embeddings'
            
            # æª¢æŸ¥æ˜¯å¦å·²å­˜åœ¨ä¸”å…§å®¹æœªè®Šæ›´
            with connection.cursor() as cursor:
                cursor.execute(f"""
                    SELECT content_hash FROM {target_table}
                    WHERE source_table = %s AND source_id = %s
                """, [source_table, source_id])
                
                existing = cursor.fetchone()
                if existing and existing[0] == content_hash:
                    logger.info(f"æ–‡æª” {source_table}:{source_id} å…§å®¹æœªè®Šæ›´ï¼Œè·³éåµŒå…¥ç”Ÿæˆ")
                    return True
            
            # ç”ŸæˆåµŒå…¥å‘é‡
            embedding = self.generate_embedding(content)
            
            # å­˜å„²åˆ°è³‡æ–™åº«
            with connection.cursor() as cursor:
                cursor.execute(f"""
                    INSERT INTO {target_table} (source_table, source_id, text_content, content_hash, embedding)
                    VALUES (%s, %s, %s, %s, %s)
                    ON CONFLICT (source_table, source_id)
                    DO UPDATE SET 
                        text_content = EXCLUDED.text_content,
                        content_hash = EXCLUDED.content_hash,
                        embedding = EXCLUDED.embedding,
                        updated_at = CURRENT_TIMESTAMP
                """, [source_table, source_id, content, content_hash, json.dumps(embedding)])
                
            logger.info(f"æˆåŠŸå­˜å„²æ–‡æª”åµŒå…¥åˆ° {target_table}: {source_table}:{source_id}")
            return True
            
        except Exception as e:
            logger.error(f"å­˜å„²æ–‡æª”åµŒå…¥å¤±æ•—: {str(e)}")
            return False
    
    def search_similar_documents(self, query: str, source_table: str = None, limit: int = 5, threshold: float = 0.0, use_1024_table: bool = False) -> List[dict]:
        """
        æœç´¢ç›¸ä¼¼æ–‡æª”
        
        Args:
            query: æŸ¥è©¢æ–‡æœ¬
            source_table: é™åˆ¶æœç´¢çš„ä¾†æºè¡¨ï¼ˆå¯é¸ï¼‰
            limit: è¿”å›çµæœæ•¸é‡é™åˆ¶
            threshold: ç›¸ä¼¼åº¦é–¾å€¼
            use_1024_table: æ˜¯å¦ä½¿ç”¨ 1024 ç¶­è¡¨æ ¼
            
        Returns:
            ç›¸ä¼¼æ–‡æª”åˆ—è¡¨
        """
        try:
            # ç”ŸæˆæŸ¥è©¢å‘é‡
            query_embedding = self.generate_embedding(query)
            
            # é¸æ“‡ç›®æ¨™è¡¨æ ¼
            target_table = 'document_embeddings_1024' if use_1024_table else 'document_embeddings'
            
            # æ§‹å»º SQL æŸ¥è©¢
            sql_parts = []
            params = []
            
            if source_table:
                sql_parts.append("WHERE de.source_table = %s")
                params.append(source_table)
            
            sql = f"""
                SELECT 
                    de.source_table,
                    de.source_id,
                    1 - (de.embedding <=> %s) as similarity_score,
                    de.created_at,
                    de.updated_at
                FROM {target_table} de
                {' '.join(sql_parts)}
                ORDER BY de.embedding <=> %s
                LIMIT %s
            """
            
            params = [json.dumps(query_embedding)] + params + [json.dumps(query_embedding), limit]
            
            results = []
            with connection.cursor() as cursor:
                cursor.execute(sql, params)
                
                for row in cursor.fetchall():
                    source_table_name, source_id, similarity_score, created_at, updated_at = row
                    
                    # éæ¿¾ä½æ–¼é–¾å€¼çš„çµæœ
                    if similarity_score >= threshold:
                        results.append({
                            'source_table': source_table_name,
                            'source_id': source_id,
                            'similarity_score': float(similarity_score),
                            'created_at': created_at,
                            'updated_at': updated_at
                        })
            
            table_name = "1024ç¶­" if use_1024_table else "768ç¶­"
            logger.info(f"å‘é‡æœç´¢å®Œæˆ ({table_name})ï¼Œè¿”å› {len(results)} å€‹çµæœ")
            return results
            
        except Exception as e:
            logger.error(f"å‘é‡æœç´¢å¤±æ•—: {str(e)}")
            return []

# å…¨å±€æœå‹™å¯¦ä¾‹
_embedding_service = None

def get_embedding_service(model_type: str = 'ultra_high') -> OpenSourceEmbeddingService:
    """
    ç²å–å…¨å±€åµŒå…¥æœå‹™å¯¦ä¾‹
    
    Args:
        model_type: æ¨¡å‹é¡å‹ ('lightweight', 'standard', 'high_precision', 'ultra_high')
                   - lightweight: 384ç¶­ï¼Œé€Ÿåº¦å¿«ï¼Œé©åˆå°è¦æ¨¡æ‡‰ç”¨
                   - standard: 768ç¶­ï¼Œå¹³è¡¡ç²¾æº–åº¦èˆ‡æ•ˆèƒ½
                   - high_precision: 768ç¶­ï¼Œæœ€é«˜ç²¾æº–åº¦
                   - ultra_high: 1024ç¶­ï¼Œæœ€ä½³ç²¾æº–åº¦ (é»˜èª)
    """
    global _embedding_service
    if _embedding_service is None or _embedding_service.model_type != model_type:
        logger.info(f"åˆå§‹åŒ–åµŒå…¥æœå‹™ï¼Œæ¨¡å‹é¡å‹: {model_type}")
        _embedding_service = OpenSourceEmbeddingService(model_type)
    return _embedding_service

def search_rvt_guide_with_vectors(query: str, limit: int = 5, threshold: float = 0.3) -> List[dict]:
    """
    ä½¿ç”¨å‘é‡æœç´¢ RVT Guide (1024ç¶­ - é è¨­)
    
    Args:
        query: æŸ¥è©¢æ–‡æœ¬
        limit: è¿”å›çµæœæ•¸é‡
        threshold: ç›¸ä¼¼åº¦é–¾å€¼
        
    Returns:
        æœç´¢çµæœåˆ—è¡¨
    """
    service = get_embedding_service()  # ç¾åœ¨é è¨­ä½¿ç”¨ 1024 ç¶­
    
    # æœç´¢ç›¸ä¼¼å‘é‡
    vector_results = service.search_similar_documents(
        query=query,
        source_table='rvt_guide',
        limit=limit,
        threshold=threshold,
        use_1024_table=True  # ä½¿ç”¨æ–°çš„ 1024 ç¶­è¡¨æ ¼
    )
    
    if not vector_results:
        logger.info("å‘é‡æœç´¢ç„¡çµæœ")
        return []
    
    return _get_rvt_guide_results(vector_results, "1024ç¶­")

def search_rvt_guide_with_vectors_768_legacy(query: str, limit: int = 5, threshold: float = 0.3) -> List[dict]:
    """
    ä½¿ç”¨å‘é‡æœç´¢ RVT Guide (768ç¶­ - èˆŠç‰ˆæœ¬)
    
    Args:
        query: æŸ¥è©¢æ–‡æœ¬
        limit: è¿”å›çµæœæ•¸é‡
        threshold: ç›¸ä¼¼åº¦é–¾å€¼
        
    Returns:
        æœç´¢çµæœåˆ—è¡¨
    """
    service = get_embedding_service('standard')  # ä½¿ç”¨768ç¶­æ¨¡å‹
    
    # æœç´¢ç›¸ä¼¼å‘é‡
    vector_results = service.search_similar_documents(
        query=query,
        source_table='rvt_guide',
        limit=limit,
        threshold=threshold,
        use_1024_table=False  # ä½¿ç”¨èˆŠçš„768ç¶­è¡¨æ ¼
    )
    
    if not vector_results:
        logger.info("768ç¶­å‘é‡æœç´¢ç„¡çµæœ")
        return []
    
    return _get_rvt_guide_results(vector_results, "768ç¶­")

def _get_rvt_guide_results(vector_results: List[dict], version_info: str) -> List[dict]:
    """
    ç²å– RVT Guide çš„å®Œæ•´çµæœè³‡æ–™
    
    Args:
        vector_results: å‘é‡æœç´¢çµæœ
        version_info: ç‰ˆæœ¬è³‡è¨Š (ç”¨æ–¼æ—¥èªŒ)
        
    Returns:
        å®Œæ•´çš„ RVT Guide çµæœåˆ—è¡¨
    """
    # ç²å–å®Œæ•´çš„ RVT Guide è³‡æ–™
    source_ids = [result['source_id'] for result in vector_results]
    
    try:
        with connection.cursor() as cursor:
            placeholders = ','.join(['%s'] * len(source_ids))
            cursor.execute(f"""
                SELECT 
                    id, title,
                    content,
                    created_at, updated_at
                FROM rvt_guide
                WHERE id IN ({placeholders})
            """, source_ids)
            
            columns = [desc[0] for desc in cursor.description]
            rvt_guides = {}
            
            for row in cursor.fetchall():
                rvt_data = dict(zip(columns, row))
                rvt_guides[rvt_data['id']] = rvt_data
        
        # çµ„åˆçµæœï¼Œä¿æŒå‘é‡æœç´¢çš„é †åº
        final_results = []
        for vector_result in vector_results:
            source_id = vector_result['source_id']
            if source_id in rvt_guides:
                rvt_data = rvt_guides[source_id]
                
                # æ ¼å¼åŒ–å…§å®¹ç”¨æ–¼ Dify
                content = f"æ–‡æª”æ¨™é¡Œ: {rvt_data['title']}\n"
                content += f"å…§å®¹: {rvt_data['content']}\n"
                
                final_results.append({
                    'id': str(source_id),
                    'title': rvt_data['title'],
                    'content': content,
                    'score': vector_result['similarity_score'],
                    'metadata': {
                        'source': f'rvt_guide_vector_search_{version_info}'
                    }
                })
        
        logger.info(f"å‘é‡æœç´¢è¿”å› {len(final_results)} å€‹ RVT Guide çµæœ ({version_info})")
        return final_results
        
    except Exception as e:
        logger.error(f"ç²å– RVT Guide è©³ç´°è³‡æ–™å¤±æ•—: {str(e)}")
        return []


def search_know_issue_with_vectors(query: str, top_k: int = 5, threshold: float = 0.3) -> List[dict]:
    """
    ğŸ†• ä½¿ç”¨å‘é‡æœç´¢ Know Issue (1024ç¶­)
    
    Args:
        query: æŸ¥è©¢æ–‡æœ¬
        top_k: è¿”å›çµæœæ•¸é‡
        threshold: ç›¸ä¼¼åº¦é–¾å€¼
        
    Returns:
        æœç´¢çµæœåˆ—è¡¨
    """
    try:
        service = get_embedding_service()  # ä½¿ç”¨ 1024 ç¶­æ¨¡å‹
        
        # æœç´¢ç›¸ä¼¼å‘é‡
        vector_results = service.search_similar_documents(
            query=query,
            source_table='know_issue',
            limit=top_k,
            use_1024_table=True  # ä½¿ç”¨ 1024 ç¶­è¡¨æ ¼
        )
        
        if not vector_results:
            logger.info("Know Issue å‘é‡æœç´¢ç„¡çµæœ")
            return []
        
        return _get_know_issue_results(vector_results, "1024ç¶­")
        
    except Exception as e:
        logger.error(f"Know Issue å‘é‡æœç´¢å¤±æ•—: {str(e)}")
        return []


def _get_know_issue_results(vector_results: List[dict], version_info: str) -> List[dict]:
    """
    ğŸ†• å¾å‘é‡æœç´¢çµæœç²å– Know Issue è©³ç´°è³‡æ–™
    
    Args:
        vector_results: å‘é‡æœç´¢åŸå§‹çµæœ
        version_info: ç‰ˆæœ¬ä¿¡æ¯ï¼ˆç”¨æ–¼æ—¥èªŒï¼‰
        
    Returns:
        æ ¼å¼åŒ–çš„æœç´¢çµæœ
    """
    try:
        # æå– source_id åˆ—è¡¨
        source_ids = [result['source_id'] for result in vector_results]
        
        if not source_ids:
            return []
        
        # å¾è³‡æ–™åº«ç²å– Know Issue è©³ç´°è³‡æ–™
        with connection.cursor() as cursor:
            placeholders = ','.join(['%s'] * len(source_ids))
            cursor.execute(f"""
                SELECT 
                    ki.id, ki.issue_id, ki.project, ki.test_version,
                    ki.issue_type, ki.status, ki.error_message,
                    ki.supplement, ki.script, ki.jira_number,
                    ki.created_at, ki.updated_at,
                    tc.name as test_class_name
                FROM know_issue ki
                LEFT JOIN protocol_test_class tc ON ki.test_class_id = tc.id
                WHERE ki.id IN ({placeholders})
            """, source_ids)
            
            columns = [desc[0] for desc in cursor.description]
            know_issues = {}
            
            for row in cursor.fetchall():
                issue_data = dict(zip(columns, row))
                know_issues[issue_data['id']] = issue_data
        
        # çµ„åˆçµæœï¼Œä¿æŒå‘é‡æœç´¢çš„é †åº
        final_results = []
        for vector_result in vector_results:
            source_id = vector_result['source_id']
            if source_id in know_issues:
                issue_data = know_issues[source_id]
                
                # æ ¼å¼åŒ–å…§å®¹ç”¨æ–¼ Dify
                content = f"å•é¡Œç·¨è™Ÿ: {issue_data['issue_id']}\n"
                content += f"å°ˆæ¡ˆ: {issue_data['project']}\n"
                content += f"å•é¡Œé¡å‹: {issue_data['issue_type']}\n"
                content += f"ç‹€æ…‹: {issue_data['status']}\n"
                content += f"éŒ¯èª¤è¨Šæ¯: {issue_data['error_message']}\n"
                if issue_data['supplement']:
                    content += f"è£œå……èªªæ˜: {issue_data['supplement']}\n"
                if issue_data['script']:
                    content += f"ç›¸é—œè…³æœ¬: {issue_data['script']}\n"
                
                final_results.append({
                    'id': str(source_id),
                    'title': f"{issue_data['issue_id']} - {issue_data['project']}",
                    'content': content,
                    'score': vector_result['similarity_score'],
                    'metadata': {
                        'source': f'know_issue_vector_search_{version_info}',
                        'issue_id': issue_data['issue_id'],
                        'project': issue_data['project'],
                        'issue_type': issue_data['issue_type'],
                        'status': issue_data['status']
                    }
                })
        
        logger.info(f"å‘é‡æœç´¢è¿”å› {len(final_results)} å€‹ Know Issue çµæœ ({version_info})")
        return final_results
        
    except Exception as e:
        logger.error(f"ç²å– Know Issue è©³ç´°è³‡æ–™å¤±æ•—: {str(e)}")
        return []