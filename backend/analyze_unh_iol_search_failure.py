"""
æ·±åº¦åˆ†æï¼šä¸ºä»€ä¹ˆ UNH-IOL æœç´¢ä¸åˆ°
"""
import os
import sys
import django

sys.path.insert(0, '/app')
os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'ai_platform.settings')
django.setup()

from library.common.knowledge_base.section_search_service import SectionSearchService
from api.services.embedding_service import get_embedding_service
from api.models import ProtocolGuide

def analyze_unh_iol_search():
    """åˆ†æä¸ºä»€ä¹ˆ UNH-IOL æœç´¢ä¸åˆ°"""
    
    print("=" * 80)
    print("ğŸ” UNH-IOL æœç´¢å¤±è´¥æ·±åº¦åˆ†æ")
    print("=" * 80)
    print()
    
    # åˆå§‹åŒ–æœåŠ¡
    search_service = SectionSearchService()
    embedding_service = get_embedding_service()
    
    # æŸ¥è¯¢æ–‡æœ¬
    query = "iol å¦‚ä½•æ”¾æ¸¬"
    
    print(f"ğŸ“‹ æŸ¥è¯¢æ–‡æœ¬: \"{query}\"")
    print()
    
    # æ­¥éª¤ 1ï¼šç”ŸæˆæŸ¥è¯¢å‘é‡
    print("æ­¥éª¤ 1ï¼šç”ŸæˆæŸ¥è¯¢å‘é‡")
    print("-" * 80)
    query_embedding = embedding_service.generate_embedding(query)
    print(f"âœ… æŸ¥è¯¢å‘é‡ç»´åº¦: {len(query_embedding)}")
    print(f"âœ… å‘é‡å‰ 5 ä¸ªå€¼: {query_embedding[:5]}")
    print()
    
    # æ­¥éª¤ 2ï¼šè·å– UNH-IOL çš„æ‰€æœ‰æ®µè½å‘é‡
    print("æ­¥éª¤ 2ï¼šè·å– UNH-IOL çš„æ‰€æœ‰æ®µè½")
    print("-" * 80)
    
    from django.db import connection
    with connection.cursor() as cursor:
        cursor.execute("""
            SELECT 
                id,
                section_id,
                heading_text,
                LENGTH(content) as content_len,
                SUBSTRING(content, 1, 100) as content_preview
            FROM document_section_embeddings
            WHERE source_table = 'protocol_guide' AND source_id = 10
            ORDER BY section_id
        """)
        unh_sections = cursor.fetchall()
    
    print(f"æ‰¾åˆ° {len(unh_sections)} ä¸ª UNH-IOL æ®µè½ï¼š")
    for sec in unh_sections:
        sec_id, section_id, heading, content_len, preview = sec
        print(f"  - {section_id}: {heading} ({content_len} å­—å…ƒ)")
    print()
    
    # æ­¥éª¤ 3ï¼šæ‰‹åŠ¨è®¡ç®—ç›¸ä¼¼åº¦
    print("æ­¥éª¤ 3ï¼šæ‰‹åŠ¨è®¡ç®—æ¯ä¸ªæ®µè½ä¸æŸ¥è¯¢çš„ç›¸ä¼¼åº¦")
    print("-" * 80)
    
    import numpy as np
    from numpy.linalg import norm
    
    def cosine_similarity(a, b):
        return np.dot(a, b) / (norm(a) * norm(b))
    
    # è·å– UNH-IOL æ®µè½çš„å‘é‡
    with connection.cursor() as cursor:
        cursor.execute("""
            SELECT 
                section_id,
                heading_text,
                LENGTH(content) as content_len,
                embedding
            FROM document_section_embeddings
            WHERE source_table = 'protocol_guide' AND source_id = 10
            ORDER BY section_id
        """)
        sections_with_vectors = cursor.fetchall()
    
    print("UNH-IOL å„æ®µè½çš„ç›¸ä¼¼åº¦ï¼š")
    print()
    
    similarities = []
    for section_id, heading, content_len, embedding_bytes in sections_with_vectors:
        # å°† pgvector æ ¼å¼è½¬æ¢ä¸º numpy æ•°ç»„
        embedding_str = embedding_bytes.strip('[]')
        embedding_vec = np.array([float(x) for x in embedding_str.split(',')])
        
        # è®¡ç®—ç›¸ä¼¼åº¦
        similarity = cosine_similarity(query_embedding, embedding_vec)
        similarities.append((section_id, heading, content_len, similarity))
        
        print(f"  {section_id}: {heading}")
        print(f"    å†…å®¹é•¿åº¦: {content_len} å­—å…ƒ")
        print(f"    ç›¸ä¼¼åº¦: {similarity:.4f} ({similarity*100:.2f}%)")
        print()
    
    # æ‰¾å‡ºæœ€é«˜ç›¸ä¼¼åº¦
    max_similarity = max(similarities, key=lambda x: x[3])
    print(f"âœ… UNH-IOL æœ€é«˜ç›¸ä¼¼åº¦: {max_similarity[3]:.4f} ({max_similarity[3]*100:.2f}%)")
    print(f"   æ®µè½: {max_similarity[0]} - {max_similarity[1]}")
    print()
    
    # æ­¥éª¤ 4ï¼šå¯¹æ¯”å…¶ä»–æ–‡æ¡£çš„ç›¸ä¼¼åº¦
    print("æ­¥éª¤ 4ï¼šå¯¹æ¯”å…¶ä»–æ–‡æ¡£ï¼ˆå‰ 5 åç»“æœï¼‰")
    print("-" * 80)
    
    results = search_service.search_sections(
        query=query,
        source_table='protocol_guide',
        limit=10,
        threshold=0.0  # é™ä½é˜ˆå€¼ï¼Œçœ‹æ‰€æœ‰ç»“æœ
    )
    
    print(f"æœç´¢åˆ° {len(results)} ä¸ªç»“æœï¼š")
    print()
    
    unh_iol_rank = None
    for i, result in enumerate(results, 1):
        source_id = result.get('source_id')
        guide = ProtocolGuide.objects.get(id=source_id)
        similarity = result.get('similarity', 0)
        
        is_unh = (source_id == 10)
        symbol = "âœ…" if is_unh else "  "
        
        print(f"{symbol} #{i}: {guide.title}")
        print(f"     æ®µè½: {result.get('section_id')} - {result.get('heading_text')}")
        print(f"     ç›¸ä¼¼åº¦: {similarity:.4f} ({similarity*100:.2f}%)")
        
        if is_unh and unh_iol_rank is None:
            unh_iol_rank = i
        print()
    
    if unh_iol_rank:
        print(f"ğŸ¯ UNH-IOL æ’å: #{unh_iol_rank}")
    else:
        print(f"âŒ UNH-IOL ä¸åœ¨æœç´¢ç»“æœä¸­")
    print()
    
    # æ­¥éª¤ 5ï¼šåˆ†æé˜ˆå€¼é—®é¢˜
    print("æ­¥éª¤ 5ï¼šåˆ†æé˜ˆå€¼é—®é¢˜")
    print("-" * 80)
    
    threshold = 0.7
    print(f"å½“å‰æœç´¢é˜ˆå€¼: {threshold} ({threshold*100}%)")
    print(f"UNH-IOL æœ€é«˜ç›¸ä¼¼åº¦: {max_similarity[3]:.4f} ({max_similarity[3]*100:.2f}%)")
    
    if max_similarity[3] < threshold:
        print(f"âŒ UNH-IOL æœ€é«˜ç›¸ä¼¼åº¦ < é˜ˆå€¼")
        print(f"   å·®è·: {(threshold - max_similarity[3])*100:.2f}%")
        print()
        print("ğŸ” åŸå› åˆ†æï¼š")
        print("   1. æŸ¥è¯¢æ–‡æœ¬ 'æ”¾æ¸¬' å¯èƒ½ä¸å¸¸è§äº UNH-IOL æ–‡æ¡£")
        print("   2. UNH-IOL æ®µè½å†…å®¹è¾ƒçŸ­ï¼ˆå¹³å‡ 101 å­—å…ƒï¼‰")
        print("   3. å…¶ä»–æ–‡æ¡£ï¼ˆBurn in Test, I3Cï¼‰å†…å®¹æ›´è¯¦ç»†")
    else:
        print(f"âœ… UNH-IOL ç›¸ä¼¼åº¦ >= é˜ˆå€¼ï¼Œåº”è¯¥ä¼šè¢«æ‰¾åˆ°")
    
    print()
    print("=" * 80)
    print("åˆ†æå®Œæˆ")
    print("=" * 80)

if __name__ == '__main__':
    analyze_unh_iol_search()
