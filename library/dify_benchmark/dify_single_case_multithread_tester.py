"""
Dify å–®ä¸€æ¸¬è©¦æ¡ˆä¾‹å¤šåŸ·è¡Œç·’ç‰ˆæœ¬æ¸¬è©¦å™¨ (Dify Single Case Multithread Tester)
=========================================================================

ç”¨æ–¼å°å–®ä¸€ VSA æ¸¬è©¦æ¡ˆä¾‹ï¼Œä½¿ç”¨å¤šåŸ·è¡Œç·’ä¸¦è¡Œæ¸¬è©¦æŒ‡å®šçš„ DifyConfigVersion ç‰ˆæœ¬ã€‚

ä½¿ç”¨å ´æ™¯ï¼š
- å¿«é€Ÿæ¸¬è©¦å–®ä¸€å•é¡Œåœ¨å¤šå€‹ Dify ç‰ˆæœ¬çš„è¡¨ç¾
- éœ€è¦ç”¨æˆ¶é¸æ“‡ç‰¹å®šç‰ˆæœ¬æ¸¬è©¦
- éœ€è¦ä¸¦è¡ŒåŸ·è¡Œä»¥åŠ é€Ÿæ¸¬è©¦

èˆ‡ Protocol Benchmark çš„ SingleCaseMultithreadTester ä¸åŒï¼š
- ä½¿ç”¨ DifyConfigVersion è€Œé SearchAlgorithmVersion
- ä½¿ç”¨ Dify API åŸ·è¡Œæ¸¬è©¦è€Œéæœ¬åœ°æœå°‹ç­–ç•¥
- ä½¿ç”¨ DifyTestRun/DifyTestResult å„²å­˜çµæœ
"""

import logging
from datetime import datetime
from typing import List, Dict, Any, Optional
from decimal import Decimal
from concurrent.futures import ThreadPoolExecutor, as_completed
import threading
import uuid

logger = logging.getLogger(__name__)


class DifySingleCaseMultithreadTester:
    """Dify å–®ä¸€æ¸¬è©¦æ¡ˆä¾‹å¤šåŸ·è¡Œç·’ç‰ˆæœ¬æ¸¬è©¦å™¨"""
    
    def __init__(
        self, 
        test_case_id: int, 
        version_ids: List[int], 
        max_workers: int = 3,
        verbose: bool = False,
        api_timeout: int = 75
    ):
        """
        åˆå§‹åŒ–æ¸¬è©¦å™¨
        
        Args:
            test_case_id: æ¸¬è©¦æ¡ˆä¾‹ ID (DifyBenchmarkTestCase)
            version_ids: è¦æ¸¬è©¦çš„ç‰ˆæœ¬ ID åˆ—è¡¨ (DifyConfigVersion)
            max_workers: æœ€å¤§ä¸¦è¡ŒåŸ·è¡Œç·’æ•¸ï¼ˆé è¨­ 3ï¼Œå»ºè­° 1-5ï¼‰
            verbose: æ˜¯å¦è¼¸å‡ºè©³ç´°æ—¥èªŒ
            api_timeout: Dify API è¶…æ™‚æ™‚é–“ï¼ˆç§’ï¼‰
        """
        if not version_ids:
            raise ValueError("version_ids ä¸èƒ½ç‚ºç©ºï¼Œå¿…é ˆæŒ‡å®šè¦æ¸¬è©¦çš„ç‰ˆæœ¬")
        
        self.test_case_id = test_case_id
        self.version_ids = version_ids
        self.max_workers = min(max_workers, len(version_ids), 5)  # é™åˆ¶æœ€å¤§ 5 å€‹åŸ·è¡Œç·’
        self.verbose = verbose
        self.api_timeout = api_timeout
        self.test_case = None
        self.versions = []
        
        # åŸ·è¡Œç·’å®‰å…¨çš„çµæœæ”¶é›†
        self._results_lock = threading.Lock()
        self._results = []
        self._test_run_ids = []
    
    def run_test(self) -> Dict[str, Any]:
        """
        åŸ·è¡Œå¤šåŸ·è¡Œç·’æ¸¬è©¦
        
        Returns:
            Dict: æ¸¬è©¦çµæœ
        """
        try:
            self._log(f"\n{'='*80}")
            self._log(f"ğŸš€ é–‹å§‹ Dify å¤šåŸ·è¡Œç·’ç‰ˆæœ¬æ¸¬è©¦")
            self._log(f"{'='*80}")
            
            # 1. æº–å‚™æ¸¬è©¦æ¡ˆä¾‹å’Œç‰ˆæœ¬
            self._log(f"ğŸ“‹ æº–å‚™æ¸¬è©¦æ¡ˆä¾‹ (ID: {self.test_case_id})...")
            self._prepare_test_case()
            
            self._log(f"ğŸ“‹ æº–å‚™æ¸¬è©¦ç‰ˆæœ¬ (æŒ‡å®š {len(self.version_ids)} å€‹)...")
            self._prepare_versions()
            
            if not self.test_case:
                return {
                    'success': False,
                    'error': f'æ‰¾ä¸åˆ°æ¸¬è©¦æ¡ˆä¾‹ ID: {self.test_case_id}'
                }
            
            if not self.versions:
                return {
                    'success': False,
                    'error': 'æ²’æœ‰æ‰¾åˆ°æŒ‡å®šçš„ç‰ˆæœ¬ï¼Œè«‹ç¢ºèªç‰ˆæœ¬ ID æ˜¯å¦æ­£ç¢º'
                }
            
            self._log(f"âœ… æ¸¬è©¦æ¡ˆä¾‹: {self.test_case.question[:80]}...")
            self._log(f"âœ… å…± {len(self.versions)} å€‹ç‰ˆæœ¬: {[v.version_name for v in self.versions]}")
            self._log(f"âœ… æœ€å¤§ä¸¦è¡Œæ•¸: {self.max_workers}")
            
            # 2. ä½¿ç”¨ ThreadPoolExecutor ä¸¦è¡ŒåŸ·è¡Œæ¸¬è©¦
            start_time = datetime.now()
            
            self._log(f"\n{'â”€'*80}")
            self._log(f"âš¡ é–‹å§‹ä¸¦è¡Œæ¸¬è©¦ï¼ˆ{self.max_workers} å€‹åŸ·è¡Œç·’ï¼‰")
            self._log(f"{'â”€'*80}")
            
            with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
                # æäº¤æ‰€æœ‰ç‰ˆæœ¬çš„æ¸¬è©¦ä»»å‹™
                future_to_version = {
                    executor.submit(self._test_single_version_safe, version): version
                    for version in self.versions
                }
                
                # æ”¶é›†çµæœ
                completed_count = 0
                for future in as_completed(future_to_version):
                    version = future_to_version[future]
                    completed_count += 1
                    
                    try:
                        result = future.result(timeout=120)  # 2 åˆ†é˜è¶…æ™‚
                        with self._results_lock:
                            self._results.append(result)
                            if result.get('test_run_id'):
                                self._test_run_ids.append(result['test_run_id'])
                        
                        status_icon = "âœ…" if result.get('status') == 'success' else "âŒ"
                        score = result.get('metrics', {}).get('score', 0)
                        self._log(f"  [{completed_count}/{len(self.versions)}] {status_icon} {version.version_name}: Score={score:.2f}")
                        
                    except Exception as e:
                        error_result = {
                            'version_id': version.id,
                            'version_name': version.version_name,
                            'version_code': version.version_code,
                            'status': 'error',
                            'error_message': str(e),
                            'metrics': {
                                'score': 0.0,
                                'precision': 0.0,
                                'recall': 0.0,
                                'f1_score': 0.0
                            },
                            'response_time': 0.0,
                            'matched_keywords': [],
                            'total_keywords': 0
                        }
                        with self._results_lock:
                            self._results.append(error_result)
                        
                        self._log(f"  [{completed_count}/{len(self.versions)}] âŒ {version.version_name}: {str(e)}", level='error')
            
            total_time = (datetime.now() - start_time).total_seconds()
            
            # 3. ç”Ÿæˆæ‘˜è¦
            summary = self._generate_summary(total_time)
            
            self._log(f"\n{'='*80}")
            self._log(f"âœ… Dify å¤šåŸ·è¡Œç·’æ¸¬è©¦å®Œæˆï¼")
            self._log(f"   ç¸½æ™‚é–“: {total_time:.2f} ç§’")
            self._log(f"   æˆåŠŸ: {summary['successful_tests']}/{summary['total_versions']}")
            if summary.get('best_version'):
                self._log(f"   æœ€ä½³ç‰ˆæœ¬: {summary['best_version']['version_name']} (Score: {summary['best_version']['metrics']['score']:.2f})")
            self._log(f"{'='*80}")
            
            return {
                'success': True,
                'test_case': {
                    'id': self.test_case.id,
                    'question': self.test_case.question,
                    'difficulty_level': self.test_case.difficulty_level,
                    'expected_keywords': self.test_case.answer_keywords
                },
                'results': self._results,
                'summary': summary
            }
            
        except Exception as e:
            error_msg = f"Dify å¤šåŸ·è¡Œç·’ç‰ˆæœ¬æ¸¬è©¦å¤±æ•—: {str(e)}"
            self._log(error_msg, level='error')
            import traceback
            traceback.print_exc()
            return {
                'success': False,
                'error': error_msg
            }
    
    def _prepare_test_case(self):
        """æº–å‚™æ¸¬è©¦æ¡ˆä¾‹"""
        from api.models import DifyBenchmarkTestCase
        
        try:
            self.test_case = DifyBenchmarkTestCase.objects.get(
                id=self.test_case_id,
                is_active=True
            )
        except DifyBenchmarkTestCase.DoesNotExist:
            self._log(f"æ¸¬è©¦æ¡ˆä¾‹ä¸å­˜åœ¨æˆ–å·²åœç”¨: {self.test_case_id}", level='warning')
            self.test_case = None
    
    def _prepare_versions(self):
        """æº–å‚™è¦æ¸¬è©¦çš„ç‰ˆæœ¬"""
        from api.models import DifyConfigVersion
        
        # åªç²å–æŒ‡å®šä¸”å•Ÿç”¨çš„ç‰ˆæœ¬
        self.versions = list(
            DifyConfigVersion.objects.filter(
                id__in=self.version_ids,
                is_active=True
            ).order_by('id')
        )
        
        # æª¢æŸ¥æ˜¯å¦æœ‰æ‰¾ä¸åˆ°çš„ç‰ˆæœ¬
        found_ids = {v.id for v in self.versions}
        missing_ids = set(self.version_ids) - found_ids
        if missing_ids:
            self._log(f"âš ï¸ ä»¥ä¸‹ç‰ˆæœ¬ ID æœªæ‰¾åˆ°æˆ–å·²åœç”¨: {missing_ids}", level='warning')
    
    def _test_single_version_safe(self, version) -> Dict[str, Any]:
        """
        æ¸¬è©¦å–®ä¸€ç‰ˆæœ¬ï¼ˆåŸ·è¡Œç·’å®‰å…¨ç‰ˆæœ¬ï¼‰
        
        ç¢ºä¿æ¯å€‹åŸ·è¡Œç·’éƒ½æœ‰ç¨ç«‹çš„è³‡æ–™åº«é€£æ¥
        """
        # ç¢ºä¿ Django è³‡æ–™åº«é€£æ¥åœ¨æ–°åŸ·è¡Œç·’ä¸­æ­£ç¢ºåˆå§‹åŒ–
        from django.db import connection
        connection.ensure_connection()
        
        try:
            return self._test_single_version(version)
        finally:
            # æ¸…ç†åŸ·è¡Œç·’çš„è³‡æ–™åº«é€£æ¥
            connection.close()
    
    def _test_single_version(self, version) -> Dict[str, Any]:
        """
        æ¸¬è©¦å–®ä¸€ç‰ˆæœ¬
        
        Args:
            version: DifyConfigVersion å¯¦ä¾‹
            
        Returns:
            Dict: æ¸¬è©¦çµæœ
        """
        from .dify_api_client import DifyAPIClient
        from .evaluators import KeywordEvaluator
        from library.dify_integration.dynamic_threshold_loader import DynamicThresholdLoader
        
        start_time = datetime.now()
        thread_name = threading.current_thread().name
        
        self._log(f"[{thread_name}] ğŸ§ª é–‹å§‹æ¸¬è©¦ç‰ˆæœ¬ï¼š{version.version_name}")
        
        try:
            # 1. è¼‰å…¥ç‰ˆæœ¬é…ç½®ï¼ˆæ”¯æ´å‹•æ…‹ Thresholdï¼‰
            if DynamicThresholdLoader.is_dynamic_version(version.rag_settings):
                rag_settings = DynamicThresholdLoader.load_full_rag_settings(version.rag_settings)
            else:
                rag_settings = version.rag_settings
            
            version_config = {
                'version_code': version.version_code,
                'version_name': version.version_name,
                'rag_settings': rag_settings
            }
            
            # 2. åˆå§‹åŒ– API Client å’Œè©•åˆ†å™¨
            api_client = DifyAPIClient(timeout=self.api_timeout)
            evaluator = KeywordEvaluator()
            
            # 3. å‘¼å« Dify API ç²å–ç­”æ¡ˆ
            # æ³¨æ„ï¼šæ–°å°è©±ä¸å‚³é conversation_idï¼Œè®“ Dify è‡ªå‹•ç”Ÿæˆ
            api_response = api_client.send_question(
                question=self.test_case.question,
                conversation_id=None,  # æ–°å°è©±ä¸å‚³é conversation_id
                user_id=f"benchmark_test_{self.test_case.id}",
                version_config=version_config
            )
            
            # 4. æå–ç­”æ¡ˆ
            answer = api_response.get('answer', '')
            response_time = (datetime.now() - start_time).total_seconds()
            
            # 5. è©•ä¼°ç­”æ¡ˆ
            eval_result = evaluator.evaluate(
                question=self.test_case.question,
                expected_answer=self.test_case.expected_answer or '',
                actual_answer=answer,
                keywords=self.test_case.answer_keywords or []
            )
            
            # 6. å„²å­˜çµæœåˆ°è³‡æ–™åº«
            test_run = self._save_test_result(
                version=version,
                answer=answer,
                eval_result=eval_result,
                response_time=response_time,
                api_response=api_response
            )
            
            self._log(f"[{thread_name}] âœ… {version.version_name} å®Œæˆ - Score: {eval_result['score']}, è€—æ™‚: {response_time:.2f}s")
            
            # å°‡ score (0-100) è½‰æ›ç‚º precision/recall/f1 (0-1)
            # KeywordEvaluator çš„ score æœ¬è³ªä¸Šå°±æ˜¯ recallï¼ˆåŒ¹é…é—œéµå­—æ•¸ / ç¸½é—œéµå­—æ•¸ï¼‰
            score_ratio = float(eval_result['score']) / 100.0
            
            return {
                'version_id': version.id,
                'version_name': version.version_name,
                'version_code': version.version_code,
                'strategy_type': rag_settings.get('retrieval_mode', version.retrieval_mode or '-'),
                'metrics': {
                    'score': float(eval_result['score']),
                    'precision': score_ratio,  # é—œéµå­—è©•åˆ†æ¨¡å¼ä¸‹ï¼Œprecision = recall = score
                    'recall': score_ratio,
                    'f1_score': score_ratio
                },
                'response_time': response_time,
                'matched_keywords': eval_result.get('matched_keywords', []),
                'total_keywords': len(self.test_case.answer_keywords or []),
                'answer': answer[:500],  # æˆªæ–·ç­”æ¡ˆ
                'status': 'success',
                'test_run_id': test_run.id if test_run else None
            }
            
        except Exception as e:
            self._log(f"[{thread_name}] âŒ {version.version_name} å¤±æ•—: {str(e)}", level='error')
            return {
                'version_id': version.id,
                'version_name': version.version_name,
                'version_code': version.version_code,
                'strategy_type': version.retrieval_mode or '-',
                'status': 'error',
                'error_message': str(e),
                'metrics': {
                    'score': 0.0,
                    'precision': 0.0,
                    'recall': 0.0,
                    'f1_score': 0.0
                },
                'response_time': (datetime.now() - start_time).total_seconds(),
                'matched_keywords': [],
                'total_keywords': 0
            }
    
    def _save_test_result(
        self,
        version,
        answer: str,
        eval_result: Dict[str, Any],
        response_time: float,
        api_response: Dict[str, Any]
    ):
        """
        å„²å­˜æ¸¬è©¦çµæœåˆ°è³‡æ–™åº«
        """
        from api.models import DifyTestRun, DifyTestResult
        
        try:
            # å‰µå»ºæ¸¬è©¦é‹è¡Œè¨˜éŒ„
            test_run = DifyTestRun.objects.create(
                version=version,
                run_name=f"é¸æ“‡ç‰ˆæœ¬æ¸¬è©¦ - {self.test_case.question[:30]}...",
                batch_id=f"selected_{datetime.now().strftime('%Y%m%d%H%M%S')}",
                total_cases=1,
                passed_cases=1 if eval_result.get('is_passed', False) else 0,
                failed_cases=0 if eval_result.get('is_passed', False) else 1,
                average_score=Decimal(str(eval_result['score'])),
                pass_rate=Decimal('100.0') if eval_result.get('is_passed', False) else Decimal('0'),
                status='completed'
            )
            
            # å‰µå»ºæ¸¬è©¦çµæœè¨˜éŒ„
            DifyTestResult.objects.create(
                test_run=test_run,
                test_case=self.test_case,
                dify_answer=answer,
                dify_conversation_id=api_response.get('conversation_id', ''),
                score=Decimal(str(eval_result['score'])),
                is_passed=eval_result.get('is_passed', False),
                response_time_ms=int(response_time * 1000),
                metadata={
                    'matched_keywords': eval_result.get('matched_keywords', []),
                    'total_keywords': eval_result.get('total_keywords', 0),
                    'version_name': version.version_name,
                    'test_type': 'selected_version_multithread'
                }
            )
            
            return test_run
            
        except Exception as e:
            self._log(f"å„²å­˜æ¸¬è©¦çµæœå¤±æ•—: {str(e)}", level='error')
            return None
    
    def _generate_summary(self, total_time: float) -> Dict[str, Any]:
        """ç”Ÿæˆæ¸¬è©¦æ‘˜è¦"""
        successful_results = [r for r in self._results if r.get('status') == 'success']
        failed_results = [r for r in self._results if r.get('status') == 'error']
        
        # æ‰¾å‡ºæœ€ä½³ç‰ˆæœ¬ï¼ˆä¾æ“š scoreï¼‰
        best_version = None
        if successful_results:
            best_version = max(
                successful_results,
                key=lambda x: x['metrics']['score']
            )
        
        # è¨ˆç®—å¹³å‡å›æ‡‰æ™‚é–“
        avg_response_time = 0.0
        if successful_results:
            avg_response_time = sum(
                r['response_time'] for r in successful_results
            ) / len(successful_results)
        
        return {
            'total_versions': len(self._results),
            'successful_tests': len(successful_results),
            'failed_tests': len(failed_results),
            'best_version': best_version,
            'avg_response_time': round(avg_response_time, 2),
            'total_execution_time': round(total_time, 2),
            'test_run_ids': self._test_run_ids,
            'max_workers_used': self.max_workers
        }
    
    def _log(self, message: str, level: str = 'info'):
        """è¼¸å‡ºæ—¥èªŒ"""
        if self.verbose:
            print(f"[DifyMultithreadTester] {message}")
        
        log_func = getattr(logger, level, logger.info)
        log_func(f"[DifySingleCaseMultithreadTester] {message}")


# ===================== ä¾¿åˆ©å‡½æ•¸ =====================

def test_dify_single_case_selected_versions_multithread(
    test_case_id: int,
    version_ids: List[int],
    max_workers: int = 3,
    verbose: bool = False
) -> Dict[str, Any]:
    """
    ä½¿ç”¨å¤šåŸ·è¡Œç·’æ¸¬è©¦å–®ä¸€ Dify æ¡ˆä¾‹çš„æŒ‡å®šç‰ˆæœ¬
    
    Args:
        test_case_id: æ¸¬è©¦æ¡ˆä¾‹ ID (DifyBenchmarkTestCase)
        version_ids: ç‰ˆæœ¬ ID åˆ—è¡¨ (DifyConfigVersion)
        max_workers: æœ€å¤§ä¸¦è¡Œæ•¸ï¼ˆé è¨­ 3ï¼‰
        verbose: æ˜¯å¦è¼¸å‡ºè©³ç´°æ—¥èªŒ
        
    Returns:
        Dict: æ¸¬è©¦çµæœ
    """
    tester = DifySingleCaseMultithreadTester(
        test_case_id=test_case_id,
        version_ids=version_ids,
        max_workers=max_workers,
        verbose=verbose
    )
    return tester.run_test()
