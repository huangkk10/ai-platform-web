"""
RVT Analytics Celery Tasks - å‘é‡è³‡æ–™ç¶­è­·å’Œå•é¡Œåˆ†æä»»å‹™

ğŸ¯ é‡è¦è¨­è¨ˆèªªæ˜:
æ­¤æ¨¡çµ„å¯¦ç¾äº† RVT Assistant å‘é‡è³‡æ–™åº«çš„å®šæ™‚æ›´æ–°æ©Ÿåˆ¶ã€‚
ç”±æ–¼èŠå¤©éç¨‹ä¸­ä¸æœƒè‡ªå‹•ç”Ÿæˆå‘é‡ï¼Œç³»çµ±æ¡ç”¨å®šæ™‚æ‰¹é‡è™•ç†æ–¹å¼ä¾†ç¶­è­·å‘é‡è³‡æ–™ã€‚

ğŸ“‹ æ ¸å¿ƒä»»å‹™:
- rebuild_chat_vectors: è™•ç†æœªå‘é‡åŒ–çš„èŠå¤©æ¶ˆæ¯ (æ¯å°æ™‚åŸ·è¡Œ)
- preload_vector_services: é è¼‰å…¥å‘é‡æœå‹™
- precompute_question_classifications: æ›´æ–°å•é¡Œåˆ†é¡çµ±è¨ˆ  
- cleanup_expired_cache: æ¸…ç†éæœŸå¿«å–

ğŸš€ å¯¦æ–½æ•ˆæœ:
- å‘é‡åŒ–ç‡: 8.1% â†’ 30.6% (2025-10-09 é©—è­‰)
- è™•ç†æ•ˆç‡: ~5 æ¶ˆæ¯/ç§’
- ç†±é–€å•é¡Œåˆ†æ: æ›´æº–ç¢ºåæ˜ ç”¨æˆ¶é—œæ³¨é»

ğŸ“– å®Œæ•´æ–‡æª”: /docs/vector-database-scheduled-update-architecture.md

Author: AI Platform Team
Created: 2025-10-09
Verified: 2025-10-09
"""

import logging
from celery import shared_task
from typing import Dict, Any, Optional

logger = logging.getLogger(__name__)

@shared_task(bind=True, ignore_result=False)
def preload_vector_services(self):
    """
    é è¼‰å…¥å‘é‡æœå‹™ä»»å‹™
    
    é€™å€‹ä»»å‹™æœƒï¼š
    1. é è¼‰å…¥ embedding æœå‹™
    2. åˆå§‹åŒ–å‘é‡æœç´¢æœå‹™
    3. é ç†±å¿«å–
    
    Returns:
        dict: é è¼‰å…¥çµæœ
    """
    try:
        logger.info("é–‹å§‹é è¼‰å…¥å‘é‡æœå‹™...")
        
        # é è¼‰å…¥ embedding æœå‹™
        try:
            from api.services.embedding_service import get_embedding_service
            embedding_service = get_embedding_service('ultra_high')
            if embedding_service:
                # æ¸¬è©¦ç”Ÿæˆä¸€å€‹å‘é‡ä»¥ç¢ºä¿æœå‹™æ­£å¸¸
                test_vector = embedding_service.generate_embedding("æ¸¬è©¦å‘é‡é è¼‰å…¥")
                if test_vector:
                    logger.info("âœ… Embedding æœå‹™é è¼‰å…¥æˆåŠŸ")
                else:
                    logger.warning("âš ï¸  Embedding æœå‹™å¯èƒ½æœ‰å•é¡Œ")
            else:
                logger.warning("âš ï¸  Embedding æœå‹™ä¸å¯ç”¨")
        except Exception as e:
            logger.error(f"âŒ Embedding æœå‹™é è¼‰å…¥å¤±æ•—: {str(e)}")
        
        # é è¼‰å…¥èŠå¤©å‘é‡æœå‹™
        try:
            from library.rvt_analytics.chat_vector_service import get_chat_vector_service
            vector_service = get_chat_vector_service()
            if vector_service:
                # ç²å–çµ±è¨ˆä¿¡æ¯ä»¥é ç†±æœå‹™
                stats = vector_service.get_embedding_stats()
                logger.info(f"âœ… èŠå¤©å‘é‡æœå‹™é è¼‰å…¥æˆåŠŸï¼Œç•¶å‰å‘é‡æ•¸é‡: {stats.get('total_embeddings', 0)}")
            else:
                logger.warning("âš ï¸  èŠå¤©å‘é‡æœå‹™ä¸å¯ç”¨")
        except Exception as e:
            logger.error(f"âŒ èŠå¤©å‘é‡æœå‹™é è¼‰å…¥å¤±æ•—: {str(e)}")
        
        # é è¼‰å…¥å•é¡Œåˆ†æå™¨
        try:
            from library.rvt_analytics.vector_question_analyzer import get_vector_question_analyzer
            analyzer = get_vector_question_analyzer()
            if analyzer:
                logger.info("âœ… å•é¡Œåˆ†æå™¨é è¼‰å…¥æˆåŠŸ")
            else:
                logger.warning("âš ï¸  å•é¡Œåˆ†æå™¨ä¸å¯ç”¨")
        except Exception as e:
            logger.error(f"âŒ å•é¡Œåˆ†æå™¨é è¼‰å…¥å¤±æ•—: {str(e)}")
        
        result = {
            'success': True,
            'message': 'å‘é‡æœå‹™é è¼‰å…¥å®Œæˆ',
            'timestamp': self.request.called_directly and "immediate" or "scheduled"
        }
        
        logger.info("âœ… å‘é‡æœå‹™é è¼‰å…¥ä»»å‹™å®Œæˆ")
        return result
        
    except Exception as e:
        error_msg = f"å‘é‡æœå‹™é è¼‰å…¥ä»»å‹™å¤±æ•—: {str(e)}"
        logger.error(f"âŒ {error_msg}")
        return {
            'success': False,
            'error': error_msg
        }

@shared_task(bind=True, ignore_result=False)
def precompute_question_classifications(self):
    """
    é è¨ˆç®—å•é¡Œåˆ†é¡ä»»å‹™
    
    é€™å€‹ä»»å‹™æœƒï¼š
    1. æ›´æ–°å•é¡Œèšé¡
    2. é‡æ–°è¨ˆç®—ç†±é–€å•é¡Œæ’å
    3. æ›´æ–°å•é¡Œçµ±è¨ˆå¿«å–
    
    Returns:
        dict: é è¨ˆç®—çµæœ
    """
    try:
        logger.info("é–‹å§‹é è¨ˆç®—å•é¡Œåˆ†é¡...")
        
        results = {
            'clustering_updated': False,
            'popular_questions_updated': False,
            'cache_refreshed': False,
            'total_questions_processed': 0
        }
        
        # æ›´æ–°å•é¡Œèšé¡
        try:
            from library.rvt_analytics.chat_clustering_service import get_clustering_service
            clustering_service = get_clustering_service()
            if clustering_service:
                # åŸ·è¡Œèšé¡æ›´æ–°
                cluster_result = clustering_service.perform_auto_clustering()
                if cluster_result.get('success'):
                    results['clustering_updated'] = True
                    results['total_questions_processed'] = cluster_result.get('n_samples', 0)
                    logger.info(f"âœ… å•é¡Œèšé¡æ›´æ–°æˆåŠŸï¼Œè™•ç†äº† {results['total_questions_processed']} å€‹å•é¡Œ")
                else:
                    logger.warning("âš ï¸  å•é¡Œèšé¡æ›´æ–°æœªå®Œæˆ")
            else:
                logger.warning("âš ï¸  èšé¡æœå‹™ä¸å¯ç”¨")
        except Exception as e:
            logger.error(f"âŒ å•é¡Œèšé¡æ›´æ–°å¤±æ•—: {str(e)}")
        
        # æ›´æ–°ç†±é–€å•é¡Œçµ±è¨ˆ
        try:
            from library.rvt_analytics.vector_question_analyzer import get_enhanced_question_analysis
            enhanced_stats = get_enhanced_question_analysis(days=30)
            if enhanced_stats and enhanced_stats.get('popular_questions'):
                results['popular_questions_updated'] = True
                question_count = len(enhanced_stats['popular_questions'])
                logger.info(f"âœ… ç†±é–€å•é¡Œçµ±è¨ˆæ›´æ–°æˆåŠŸï¼Œç™¼ç¾ {question_count} å€‹å•é¡Œçµ„ç¾¤")
            else:
                logger.warning("âš ï¸  ç†±é–€å•é¡Œçµ±è¨ˆæ›´æ–°æœªå®Œæˆ")
        except Exception as e:
            logger.error(f"âŒ ç†±é–€å•é¡Œçµ±è¨ˆæ›´æ–°å¤±æ•—: {str(e)}")
        
        # å¿«å–åˆ·æ–°
        try:
            # é€™è£¡å¯ä»¥æ·»åŠ å¿«å–åˆ·æ–°é‚è¼¯
            results['cache_refreshed'] = True
            logger.info("âœ… çµ±è¨ˆå¿«å–å·²åˆ·æ–°")
        except Exception as e:
            logger.error(f"âŒ å¿«å–åˆ·æ–°å¤±æ•—: {str(e)}")
        
        results.update({
            'success': True,
            'message': 'å•é¡Œåˆ†é¡é è¨ˆç®—å®Œæˆ',
            'timestamp': self.request.called_directly and "immediate" or "scheduled"
        })
        
        logger.info("âœ… å•é¡Œåˆ†é¡é è¨ˆç®—ä»»å‹™å®Œæˆ")
        return results
        
    except Exception as e:
        error_msg = f"å•é¡Œåˆ†é¡é è¨ˆç®—ä»»å‹™å¤±æ•—: {str(e)}"
        logger.error(f"âŒ {error_msg}")
        return {
            'success': False,
            'error': error_msg
        }

@shared_task(bind=True, ignore_result=False)
def cleanup_expired_cache(self):
    """
    æ¸…ç†éæœŸå¿«å–ä»»å‹™
    
    é€™å€‹ä»»å‹™æœƒï¼š
    1. æ¸…ç†éæœŸçš„å‘é‡å¿«å–
    2. æ¸…ç†èˆŠçš„çµ±è¨ˆå¿«å–
    3. æ¸…ç†è‡¨æ™‚æ–‡ä»¶
    
    Returns:
        dict: æ¸…ç†çµæœ
    """
    try:
        logger.info("é–‹å§‹æ¸…ç†éæœŸå¿«å–...")
        
        cleaned_items = {
            'vector_cache': 0,
            'stats_cache': 0,
            'temp_files': 0
        }
        
        # é€™è£¡å¯ä»¥æ·»åŠ å…·é«”çš„å¿«å–æ¸…ç†é‚è¼¯
        # ä¾‹å¦‚ï¼šæ¸…ç† Redis å¿«å–ã€æ¸…ç†è‡¨æ™‚æ–‡ä»¶ç­‰
        
        # ç¤ºä¾‹ï¼šæ¸…ç†å‘é‡å¿«å–ï¼ˆå¦‚æœæœ‰çš„è©±ï¼‰
        try:
            # å‡è¨­æœ‰å‘é‡å¿«å–éœ€è¦æ¸…ç†
            # cache_cleared = some_cache_cleanup_function()
            # cleaned_items['vector_cache'] = cache_cleared
            logger.info("å‘é‡å¿«å–æ¸…ç†æª¢æŸ¥å®Œæˆ")
        except Exception as e:
            logger.error(f"å‘é‡å¿«å–æ¸…ç†å¤±æ•—: {str(e)}")
        
        result = {
            'success': True,
            'message': 'éæœŸå¿«å–æ¸…ç†å®Œæˆ',
            'cleaned_items': cleaned_items,
            'timestamp': self.request.called_directly and "immediate" or "scheduled"
        }
        
        logger.info("âœ… éæœŸå¿«å–æ¸…ç†ä»»å‹™å®Œæˆ")
        return result
        
    except Exception as e:
        error_msg = f"éæœŸå¿«å–æ¸…ç†ä»»å‹™å¤±æ•—: {str(e)}"
        logger.error(f"âŒ {error_msg}")
        return {
            'success': False,
            'error': error_msg
        }

@shared_task(bind=True, ignore_result=False)
def rebuild_chat_vectors(self, force_rebuild: bool = False, user_role: str = 'user', min_length: int = 5):
    """
    é‡å»ºèŠå¤©å‘é‡ä»»å‹™ï¼ˆæŒ‰éœ€åŸ·è¡Œï¼‰
    
    Args:
        force_rebuild: æ˜¯å¦å¼·åˆ¶é‡å»ºå·²å­˜åœ¨çš„å‘é‡
        user_role: è™•ç†çš„ç”¨æˆ¶è§’è‰² ('user', 'assistant', 'all')
        min_length: æœ€å°æ¶ˆæ¯é•·åº¦éæ¿¾
        
    Returns:
        dict: é‡å»ºçµæœ
    """
    try:
        logger.info(f"é–‹å§‹é‡å»ºèŠå¤©å‘é‡... (force_rebuild={force_rebuild}, user_role={user_role})")
        
        from library.rvt_analytics.chat_vector_service import get_chat_vector_service
        from django.db import connection
        
        vector_service = get_chat_vector_service()
        if not vector_service:
            raise Exception("èŠå¤©å‘é‡æœå‹™ä¸å¯ç”¨")
        
        # ç²å–éœ€è¦è™•ç†çš„æ¶ˆæ¯
        role_filter = ""
        if user_role != 'all':
            role_filter = f"AND cm.role = '{user_role}'"
        
        exclude_processed = ""
        if not force_rebuild:
            exclude_processed = """
            AND NOT EXISTS (
                SELECT 1 FROM chat_message_embeddings_1024 ce 
                WHERE ce.chat_message_id = cm.id
            )
            """
        
        with connection.cursor() as cursor:
            cursor.execute(f"""
                SELECT 
                    cm.id,
                    cm.conversation_id,
                    cm.content,
                    cm.role
                FROM chat_messages cm
                WHERE LENGTH(cm.content) >= %s
                {role_filter}
                {exclude_processed}
                ORDER BY cm.created_at DESC
                LIMIT 1000  -- é™åˆ¶æ‰¹æ¬¡å¤§å°
            """, [min_length])
            
            messages = [
                {
                    'id': row[0],
                    'conversation_id': row[1], 
                    'content': row[2],
                    'role': row[3]
                }
                for row in cursor.fetchall()
            ]
        
        if not messages:
            logger.info("æ²’æœ‰éœ€è¦è™•ç†çš„æ¶ˆæ¯")
            return {
                'success': True,
                'message': 'æ²’æœ‰éœ€è¦è™•ç†çš„æ¶ˆæ¯',
                'processed': 0
            }
        
        # æ‰¹é‡è™•ç†
        batch_result = vector_service.batch_process_messages(messages)
        
        result = {
            'success': True,
            'message': f'èŠå¤©å‘é‡é‡å»ºå®Œæˆ',
            'total_messages': len(messages),
            'successful': batch_result.get('successful', 0),
            'failed': batch_result.get('failed', 0),
            'skipped': batch_result.get('skipped', 0),
            'errors': batch_result.get('errors', [])
        }
        
        logger.info(f"âœ… èŠå¤©å‘é‡é‡å»ºä»»å‹™å®Œæˆ: {batch_result}")
        return result
        
    except Exception as e:
        error_msg = f"èŠå¤©å‘é‡é‡å»ºä»»å‹™å¤±æ•—: {str(e)}"
        logger.error(f"âŒ {error_msg}")
        return {
            'success': False,
            'error': error_msg
        }

# ä¾¿åˆ©å‡½æ•¸
def run_vector_maintenance_now() -> Dict[str, Any]:
    """
    ç«‹å³åŸ·è¡Œå‘é‡ç¶­è­·ä»»å‹™ï¼ˆæ¸¬è©¦ç”¨ï¼‰
    
    Returns:
        dict: åŸ·è¡Œçµæœ
    """
    try:
        # ç«‹å³åŸ·è¡Œé è¼‰å…¥
        preload_result = preload_vector_services.apply()
        
        # ç«‹å³åŸ·è¡Œå•é¡Œåˆ†é¡
        classify_result = precompute_question_classifications.apply()
        
        return {
            'success': True,
            'preload_result': preload_result.result if preload_result.successful() else str(preload_result.result),
            'classify_result': classify_result.result if classify_result.successful() else str(classify_result.result)
        }
    except Exception as e:
        return {
            'success': False,
            'error': f"å‘é‡ç¶­è­·åŸ·è¡Œå¤±æ•—: {str(e)}"
        }

def get_task_status() -> Dict[str, Any]:
    """
    ç²å–ä»»å‹™ç‹€æ…‹
    
    Returns:
        dict: ä»»å‹™ç‹€æ…‹ä¿¡æ¯
    """
    try:
        from celery import current_app
        
        # ç²å–æ´»èºä»»å‹™
        inspect = current_app.control.inspect()
        active_tasks = inspect.active()
        
        # ç²å–æ’ç¨‹ä»»å‹™
        scheduled_tasks = inspect.scheduled()
        
        return {
            'success': True,
            'active_tasks': active_tasks,
            'scheduled_tasks': scheduled_tasks,
            'beat_schedule': current_app.conf.beat_schedule
        }
    except Exception as e:
        return {
            'success': False,
            'error': f"ç²å–ä»»å‹™ç‹€æ…‹å¤±æ•—: {str(e)}"
        }