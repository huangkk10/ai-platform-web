# âš¡ æ•ˆèƒ½æ¸¬è©¦ç¯„ä¾‹

æœ¬æ–‡ä»¶æä¾› DeepSeek AI æ•ˆèƒ½è©•ä¼°å’Œå£“åŠ›æ¸¬è©¦çš„å®Œæ•´ç¯„ä¾‹ã€‚

## ğŸ¯ æ•ˆèƒ½æ¸¬è©¦ç›®æ¨™

### æ¸¬è©¦ç¶­åº¦
- **å›æ‡‰æ™‚é–“**: ä¸åŒå•é¡Œè¤‡é›œåº¦çš„å›æ‡‰æ™‚é–“
- **ååé‡**: ç³»çµ±è™•ç†è«‹æ±‚çš„èƒ½åŠ›
- **ä¸¦ç™¼èƒ½åŠ›**: å¤šä½¿ç”¨è€…åŒæ™‚ä½¿ç”¨çš„è¡¨ç¾
- **ç©©å®šæ€§**: é•·æ™‚é–“é‹è¡Œçš„ç©©å®šæ€§
- **è³‡æºä½¿ç”¨**: è¨˜æ†¶é«”å’Œ CPU ä½¿ç”¨æƒ…æ³

### æ•ˆèƒ½æŒ‡æ¨™
- å¹³å‡å›æ‡‰æ™‚é–“ (Average Response Time)
- 95 ç™¾åˆ†ä½å›æ‡‰æ™‚é–“ (95th Percentile)
- æ¯ç§’è™•ç†è«‹æ±‚æ•¸ (RPS - Requests Per Second)
- éŒ¯èª¤ç‡ (Error Rate)
- è³‡æºä½¿ç”¨ç‡ (Resource Utilization)

## ğŸ§ª åŸºç¤æ•ˆèƒ½æ¸¬è©¦

### å›æ‡‰æ™‚é–“åŸºæº–æ¸¬è©¦
```python
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
DeepSeek AI å›æ‡‰æ™‚é–“åŸºæº–æ¸¬è©¦
"""
import paramiko
import time
import statistics
import json
from datetime import datetime

class ResponseTimeBenchmark:
    """å›æ‡‰æ™‚é–“åŸºæº–æ¸¬è©¦"""
    
    def __init__(self, host="10.10.172.5", username="svd", password="1234"):
        self.host = host
        self.username = username
        self.password = password
        self.ssh = None
        
    def connect(self):
        """å»ºç«‹ SSH é€£æ¥"""
        try:
            self.ssh = paramiko.SSHClient()
            self.ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())
            self.ssh.connect(self.host, username=self.username, password=self.password, timeout=10)
            return True
        except Exception as e:
            print(f"âŒ é€£æ¥å¤±æ•—: {e}")
            return False
    
    def run_benchmark(self):
        """åŸ·è¡ŒåŸºæº–æ¸¬è©¦"""
        print("âš¡ DeepSeek AI å›æ‡‰æ™‚é–“åŸºæº–æ¸¬è©¦")
        print("=" * 50)
        
        if not self.connect():
            return None
        
        # ä¸åŒè¤‡é›œåº¦çš„æ¸¬è©¦å•é¡Œ
        test_categories = {
            "simple": {
                "questions": [
                    "Hello",
                    "Hi there",
                    "Good morning",
                    "How are you?",
                    "What's your name?"
                ],
                "description": "ç°¡å–®å•å€™",
                "expected_time": 5
            },
            "medium": {
                "questions": [
                    "What is artificial intelligence?",
                    "Explain machine learning",
                    "What is Python programming?",
                    "Tell me about neural networks",
                    "What is data science?"
                ],
                "description": "ä¸­ç­‰è¤‡é›œåº¦å•é¡Œ",
                "expected_time": 15
            },
            "complex": {
                "questions": [
                    "Explain the differences between supervised and unsupervised learning in detail",
                    "Describe the architecture and training process of a transformer model",
                    "Compare different optimization algorithms used in deep learning",
                    "Explain the concept of gradient descent and its variants",
                    "Discuss the challenges and solutions in natural language processing"
                ],
                "description": "è¤‡é›œæŠ€è¡“å•é¡Œ",
                "expected_time": 30
            }
        }
        
        all_results = {}
        
        try:
            for category, config in test_categories.items():
                print(f"\nğŸ“‹ æ¸¬è©¦é¡åˆ¥: {config['description']}")
                print(f"é æœŸå›æ‡‰æ™‚é–“: < {config['expected_time']}ç§’")
                
                category_results = []
                
                for i, question in enumerate(config['questions'], 1):
                    print(f"\n  ğŸ§ª æ¸¬è©¦ {i}/{len(config['questions'])}: {question[:50]}...")
                    
                    result = self._test_single_question(question)
                    category_results.append(result)
                    
                    status = "âœ…" if result['success'] else "âŒ"
                    print(f"  {status} å›æ‡‰æ™‚é–“: {result['response_time']:.2f}s")
                    
                    time.sleep(1)  # é¿å…éè¼‰
                
                # åˆ†æé¡åˆ¥çµæœ
                analysis = self._analyze_category_results(category_results, config)
                all_results[category] = {
                    "config": config,
                    "results": category_results,
                    "analysis": analysis
                }
                
                self._print_category_summary(category, analysis)
        
        finally:
            if self.ssh:
                self.ssh.close()
        
        # ç”Ÿæˆå®Œæ•´å ±å‘Š
        self._generate_benchmark_report(all_results)
        return all_results
    
    def _test_single_question(self, question):
        """æ¸¬è©¦å–®ä¸€å•é¡Œ"""
        try:
            command = f'echo "{question}" | ollama run deepseek-r1:14b --'
            start_time = time.time()
            
            stdin, stdout, stderr = self.ssh.exec_command(command, timeout=60)
            response = stdout.read().decode('utf-8')
            
            elapsed = time.time() - start_time
            success = bool(response.strip())
            
            return {
                "question": question,
                "response_time": elapsed,
                "success": success,
                "response_length": len(response.strip()),
                "timestamp": datetime.now().isoformat()
            }
            
        except Exception as e:
            return {
                "question": question,
                "response_time": 0,
                "success": False,
                "response_length": 0,
                "error": str(e),
                "timestamp": datetime.now().isoformat()
            }
    
    def _analyze_category_results(self, results, config):
        """åˆ†æé¡åˆ¥çµæœ"""
        successful_results = [r for r in results if r['success']]
        
        if not successful_results:
            return {
                "success_rate": 0,
                "avg_response_time": 0,
                "median_response_time": 0,
                "min_response_time": 0,
                "max_response_time": 0,
                "std_deviation": 0,
                "performance_grade": "F"
            }
        
        response_times = [r['response_time'] for r in successful_results]
        
        analysis = {
            "success_rate": len(successful_results) / len(results) * 100,
            "avg_response_time": statistics.mean(response_times),
            "median_response_time": statistics.median(response_times),
            "min_response_time": min(response_times),
            "max_response_time": max(response_times),
            "std_deviation": statistics.stdev(response_times) if len(response_times) > 1 else 0,
            "total_tests": len(results),
            "successful_tests": len(successful_results)
        }
        
        # æ•ˆèƒ½è©•ç´š
        avg_time = analysis['avg_response_time']
        expected_time = config['expected_time']
        
        if avg_time <= expected_time * 0.5:
            grade = "A+"
        elif avg_time <= expected_time * 0.7:
            grade = "A"
        elif avg_time <= expected_time:
            grade = "B"
        elif avg_time <= expected_time * 1.5:
            grade = "C"
        else:
            grade = "D"
        
        analysis['performance_grade'] = grade
        
        return analysis
    
    def _print_category_summary(self, category, analysis):
        """åˆ—å°é¡åˆ¥æ‘˜è¦"""
        print(f"\n  ğŸ“Š {category.upper()} é¡åˆ¥æ‘˜è¦:")
        print(f"    æˆåŠŸç‡: {analysis['success_rate']:.1f}%")
        print(f"    å¹³å‡å›æ‡‰æ™‚é–“: {analysis['avg_response_time']:.2f}s")
        print(f"    ä¸­ä½æ•¸å›æ‡‰æ™‚é–“: {analysis['median_response_time']:.2f}s")
        print(f"    æœ€å¿«/æœ€æ…¢: {analysis['min_response_time']:.2f}s / {analysis['max_response_time']:.2f}s")
        print(f"    æ•ˆèƒ½è©•ç´š: {analysis['performance_grade']}")
    
    def _generate_benchmark_report(self, all_results):
        """ç”ŸæˆåŸºæº–æ¸¬è©¦å ±å‘Š"""
        print("\n" + "=" * 60)
        print("ğŸ“ˆ å›æ‡‰æ™‚é–“åŸºæº–æ¸¬è©¦ç¸½å ±å‘Š")
        print("=" * 60)
        
        for category, data in all_results.items():
            analysis = data['analysis']
            config = data['config']
            
            print(f"\nğŸ·ï¸ {config['description']} ({category.upper()})")
            print(f"  ğŸ“Š æˆåŠŸç‡: {analysis['success_rate']:.1f}%")
            print(f"  â±ï¸ å¹³å‡æ™‚é–“: {analysis['avg_response_time']:.2f}s (é æœŸ: <{config['expected_time']}s)")
            print(f"  ğŸ† æ•ˆèƒ½è©•ç´š: {analysis['performance_grade']}")
        
        # å„²å­˜è©³ç´°å ±å‘Š
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"response_time_benchmark_{timestamp}.json"
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(all_results, f, indent=2, ensure_ascii=False)
        
        print(f"\nğŸ’¾ è©³ç´°å ±å‘Šå·²å„²å­˜è‡³: {filename}")

if __name__ == "__main__":
    benchmark = ResponseTimeBenchmark()
    benchmark.run_benchmark()
```

### å£“åŠ›æ¸¬è©¦
```python
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
DeepSeek AI å£“åŠ›æ¸¬è©¦
"""
import paramiko
import time
import threading
import queue
from concurrent.futures import ThreadPoolExecutor, as_completed
from dataclasses import dataclass
from typing import List
import statistics

@dataclass
class StressTestConfig:
    """å£“åŠ›æ¸¬è©¦é…ç½®"""
    concurrent_users: int = 5          # ä¸¦ç™¼ç”¨æˆ¶æ•¸
    test_duration_minutes: int = 10    # æ¸¬è©¦æŒçºŒæ™‚é–“(åˆ†é˜)
    ramp_up_time_seconds: int = 30     # å‡å£“æ™‚é–“(ç§’)
    think_time_seconds: int = 3        # æ€è€ƒæ™‚é–“(ç§’)

class StressTestRunner:
    """å£“åŠ›æ¸¬è©¦åŸ·è¡Œå™¨"""
    
    def __init__(self, config: StressTestConfig):
        self.config = config
        self.results_queue = queue.Queue()
        self.stop_event = threading.Event()
        
        # æ¸¬è©¦å•é¡Œæ± 
        self.question_pool = [
            "Hello, how are you?",
            "What is AI?",
            "Explain machine learning",
            "Tell me about Python",
            "What is data science?",
            "How does neural network work?",
            "What is deep learning?",
            "Explain natural language processing",
            "What is computer vision?",
            "Tell me about robotics"
        ]
    
    def run_stress_test(self):
        """åŸ·è¡Œå£“åŠ›æ¸¬è©¦"""
        print("ğŸ”¥ DeepSeek AI å£“åŠ›æ¸¬è©¦")
        print("=" * 50)
        print(f"ä¸¦ç™¼ç”¨æˆ¶æ•¸: {self.config.concurrent_users}")
        print(f"æ¸¬è©¦æ™‚é–“: {self.config.test_duration_minutes} åˆ†é˜")
        print(f"å‡å£“æ™‚é–“: {self.config.ramp_up_time_seconds} ç§’")
        
        start_time = time.time()
        end_time = start_time + (self.config.test_duration_minutes * 60)
        
        # å•Ÿå‹•ç›£æ§ç·šç¨‹
        monitor_thread = threading.Thread(target=self._monitor_progress, args=(start_time, end_time))
        monitor_thread.daemon = True
        monitor_thread.start()
        
        # ä½¿ç”¨ ThreadPoolExecutor æ¨¡æ“¬ä¸¦ç™¼ç”¨æˆ¶
        with ThreadPoolExecutor(max_workers=self.config.concurrent_users) as executor:
            # æäº¤ç”¨æˆ¶ä»»å‹™
            futures = []
            for user_id in range(self.config.concurrent_users):
                # è¨ˆç®—æ¯å€‹ç”¨æˆ¶çš„å•Ÿå‹•å»¶é² (æ¼¸é€²å¼å‡å£“)
                delay = (user_id * self.config.ramp_up_time_seconds) / self.config.concurrent_users
                future = executor.submit(self._simulate_user, user_id, start_time + delay, end_time)
                futures.append(future)
            
            # ç­‰å¾…æ‰€æœ‰ç”¨æˆ¶å®Œæˆ
            for future in as_completed(futures):
                try:
                    user_results = future.result()
                    print(f"âœ… ç”¨æˆ¶ {user_results['user_id']} å®Œæˆ: {user_results['total_requests']} è«‹æ±‚")
                except Exception as e:
                    print(f"âŒ ç”¨æˆ¶åŸ·è¡Œå¤±æ•—: {e}")
        
        # æ”¶é›†å’Œåˆ†æçµæœ
        all_results = self._collect_results()
        analysis = self._analyze_stress_test_results(all_results)
        self._generate_stress_test_report(analysis)
        
        return analysis
    
    def _simulate_user(self, user_id, start_delay, end_time):
        """æ¨¡æ“¬å–®ä¸€ç”¨æˆ¶è¡Œç‚º"""
        # ç­‰å¾…å•Ÿå‹•æ™‚é–“
        time.sleep(start_delay - time.time())
        
        user_results = {
            "user_id": user_id,
            "total_requests": 0,
            "successful_requests": 0,
            "failed_requests": 0,
            "response_times": [],
            "errors": []
        }
        
        # å»ºç«‹ SSH é€£æ¥
        ssh = None
        try:
            ssh = paramiko.SSHClient()
            ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())
            ssh.connect("10.10.172.5", username="svd", password="1234", timeout=10)
            
            # æŒçºŒç™¼é€è«‹æ±‚ç›´åˆ°æ¸¬è©¦çµæŸ
            while time.time() < end_time and not self.stop_event.is_set():
                request_start = time.time()
                
                try:
                    # éš¨æ©Ÿé¸æ“‡å•é¡Œ
                    import random
                    question = random.choice(self.question_pool)
                    
                    # ç™¼é€è«‹æ±‚
                    command = f'echo "{question}" | ollama run deepseek-r1:14b --'
                    stdin, stdout, stderr = ssh.exec_command(command, timeout=30)
                    response = stdout.read().decode('utf-8')
                    
                    response_time = time.time() - request_start
                    
                    # è¨˜éŒ„çµæœ
                    result = {
                        "user_id": user_id,
                        "question": question,
                        "response_time": response_time,
                        "success": bool(response.strip()),
                        "response_length": len(response.strip()),
                        "timestamp": time.time()
                    }
                    
                    self.results_queue.put(result)
                    
                    user_results["total_requests"] += 1
                    
                    if result["success"]:
                        user_results["successful_requests"] += 1
                        user_results["response_times"].append(response_time)
                    else:
                        user_results["failed_requests"] += 1
                    
                except Exception as e:
                    user_results["total_requests"] += 1
                    user_results["failed_requests"] += 1
                    user_results["errors"].append(str(e))
                
                # æ€è€ƒæ™‚é–“
                time.sleep(self.config.think_time_seconds)
        
        except Exception as e:
            print(f"âŒ ç”¨æˆ¶ {user_id} SSH é€£æ¥å¤±æ•—: {e}")
        
        finally:
            if ssh:
                ssh.close()
        
        return user_results
    
    def _monitor_progress(self, start_time, end_time):
        """ç›£æ§æ¸¬è©¦é€²åº¦"""
        while time.time() < end_time:
            elapsed = time.time() - start_time
            remaining = end_time - time.time()
            progress = (elapsed / (end_time - start_time)) * 100
            
            print(f"\rğŸ”„ æ¸¬è©¦é€²åº¦: {progress:.1f}% | å‰©é¤˜æ™‚é–“: {remaining/60:.1f}åˆ†é˜", end="", flush=True)
            time.sleep(10)
        
        print("\nâ¹ï¸ æ¸¬è©¦æ™‚é–“çµæŸ")
        self.stop_event.set()
    
    def _collect_results(self):
        """æ”¶é›†æ‰€æœ‰æ¸¬è©¦çµæœ"""
        results = []
        while not self.results_queue.empty():
            try:
                result = self.results_queue.get_nowait()
                results.append(result)
            except queue.Empty:
                break
        return results
    
    def _analyze_stress_test_results(self, results):
        """åˆ†æå£“åŠ›æ¸¬è©¦çµæœ"""
        if not results:
            return {"error": "ç„¡æ¸¬è©¦çµæœ"}
        
        successful_results = [r for r in results if r['success']]
        total_requests = len(results)
        successful_requests = len(successful_results)
        
        # åŸºæœ¬çµ±è¨ˆ
        success_rate = (successful_requests / total_requests) * 100 if total_requests > 0 else 0
        
        # æ™‚é–“çµ±è¨ˆ
        if successful_results:
            response_times = [r['response_time'] for r in successful_results]
            avg_response_time = statistics.mean(response_times)
            median_response_time = statistics.median(response_times)
            p95_response_time = statistics.quantiles(response_times, n=20)[18]  # 95th percentile
            min_response_time = min(response_times)
            max_response_time = max(response_times)
        else:
            avg_response_time = median_response_time = p95_response_time = 0
            min_response_time = max_response_time = 0
        
        # ååé‡è¨ˆç®—
        test_duration = self.config.test_duration_minutes * 60
        rps = successful_requests / test_duration if test_duration > 0 else 0
        
        # ä¸¦ç™¼æ•ˆèƒ½åˆ†æ
        user_stats = {}
        for result in results:
            user_id = result['user_id']
            if user_id not in user_stats:
                user_stats[user_id] = {"requests": 0, "successes": 0}
            
            user_stats[user_id]["requests"] += 1
            if result['success']:
                user_stats[user_id]["successes"] += 1
        
        analysis = {
            "test_config": self.config.__dict__,
            "summary": {
                "total_requests": total_requests,
                "successful_requests": successful_requests,
                "failed_requests": total_requests - successful_requests,
                "success_rate": success_rate,
                "requests_per_second": rps
            },
            "response_time_stats": {
                "average": avg_response_time,
                "median": median_response_time,
                "p95": p95_response_time,
                "minimum": min_response_time,
                "maximum": max_response_time
            },
            "user_statistics": user_stats,
            "detailed_results": results
        }
        
        return analysis
    
    def _generate_stress_test_report(self, analysis):
        """ç”Ÿæˆå£“åŠ›æ¸¬è©¦å ±å‘Š"""
        print("\n" + "=" * 60)
        print("ğŸ”¥ å£“åŠ›æ¸¬è©¦å ±å‘Š")
        print("=" * 60)
        
        summary = analysis['summary']
        response_stats = analysis['response_time_stats']
        
        print(f"ğŸ“Š æ¸¬è©¦æ‘˜è¦:")
        print(f"  ç¸½è«‹æ±‚æ•¸: {summary['total_requests']}")
        print(f"  æˆåŠŸè«‹æ±‚æ•¸: {summary['successful_requests']}")
        print(f"  å¤±æ•—è«‹æ±‚æ•¸: {summary['failed_requests']}")
        print(f"  æˆåŠŸç‡: {summary['success_rate']:.1f}%")
        print(f"  ååé‡: {summary['requests_per_second']:.2f} RPS")
        
        print(f"\nâ±ï¸ å›æ‡‰æ™‚é–“çµ±è¨ˆ:")
        print(f"  å¹³å‡æ™‚é–“: {response_stats['average']:.2f}s")
        print(f"  ä¸­ä½æ•¸æ™‚é–“: {response_stats['median']:.2f}s")
        print(f"  95ç™¾åˆ†ä½: {response_stats['p95']:.2f}s")
        print(f"  æœ€å¿«/æœ€æ…¢: {response_stats['minimum']:.2f}s / {response_stats['maximum']:.2f}s")
        
        print(f"\nğŸ‘¥ ç”¨æˆ¶çµ±è¨ˆ:")
        for user_id, stats in analysis['user_statistics'].items():
            user_success_rate = (stats['successes'] / stats['requests']) * 100 if stats['requests'] > 0 else 0
            print(f"  ç”¨æˆ¶ {user_id}: {stats['requests']} è«‹æ±‚, {user_success_rate:.1f}% æˆåŠŸç‡")
        
        # æ•ˆèƒ½è©•ç´š
        if summary['success_rate'] >= 99 and response_stats['p95'] <= 30:
            grade = "å„ªç§€ ğŸ†"
        elif summary['success_rate'] >= 95 and response_stats['p95'] <= 45:
            grade = "è‰¯å¥½ ğŸ‘"
        elif summary['success_rate'] >= 90 and response_stats['p95'] <= 60:
            grade = "å¯æ¥å— âš¡"
        else:
            grade = "éœ€æ”¹å–„ âš ï¸"
        
        print(f"\nğŸ† æ•´é«”æ•ˆèƒ½è©•ç´š: {grade}")
        
        # å„²å­˜å ±å‘Š
        timestamp = time.strftime("%Y%m%d_%H%M%S")
        filename = f"stress_test_report_{timestamp}.json"
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(analysis, f, indent=2, ensure_ascii=False)
        
        print(f"\nğŸ’¾ è©³ç´°å ±å‘Šå·²å„²å­˜è‡³: {filename}")

# ä½¿ç”¨ç¯„ä¾‹
if __name__ == "__main__":
    # é…ç½®å£“åŠ›æ¸¬è©¦
    config = StressTestConfig(
        concurrent_users=3,         # 3å€‹ä¸¦ç™¼ç”¨æˆ¶
        test_duration_minutes=5,    # æ¸¬è©¦5åˆ†é˜
        ramp_up_time_seconds=30,    # 30ç§’å‡å£“
        think_time_seconds=5        # 5ç§’æ€è€ƒæ™‚é–“
    )
    
    # åŸ·è¡Œæ¸¬è©¦
    runner = StressTestRunner(config)
    results = runner.run_stress_test()
```

### é•·æœŸç©©å®šæ€§æ¸¬è©¦
```python
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
DeepSeek AI é•·æœŸç©©å®šæ€§æ¸¬è©¦
"""
import paramiko
import time
import json
import threading
from datetime import datetime, timedelta
import statistics

class LongTermStabilityTest:
    """é•·æœŸç©©å®šæ€§æ¸¬è©¦"""
    
    def __init__(self, test_duration_hours=24, check_interval_minutes=30):
        self.test_duration_hours = test_duration_hours
        self.check_interval_minutes = check_interval_minutes
        self.results = []
        self.stop_event = threading.Event()
        
    def run_stability_test(self):
        """åŸ·è¡Œé•·æœŸç©©å®šæ€§æ¸¬è©¦"""
        print("ğŸ”„ DeepSeek AI é•·æœŸç©©å®šæ€§æ¸¬è©¦")
        print("=" * 50)
        print(f"æ¸¬è©¦æ™‚é•·: {self.test_duration_hours} å°æ™‚")
        print(f"æª¢æŸ¥é–“éš”: {self.check_interval_minutes} åˆ†é˜")
        
        start_time = datetime.now()
        end_time = start_time + timedelta(hours=self.test_duration_hours)
        
        print(f"é–‹å§‹æ™‚é–“: {start_time}")
        print(f"é è¨ˆçµæŸ: {end_time}")
        
        check_count = 0
        
        try:
            while datetime.now() < end_time and not self.stop_event.is_set():
                check_count += 1
                current_time = datetime.now()
                elapsed_hours = (current_time - start_time).total_seconds() / 3600
                
                print(f"\nğŸ§ª æª¢æŸ¥ #{check_count} (å·²é‹è¡Œ {elapsed_hours:.1f} å°æ™‚)")
                
                # åŸ·è¡Œå¥åº·æª¢æŸ¥
                health_result = self._perform_health_check(check_count)
                self.results.append(health_result)
                
                # é¡¯ç¤ºå³æ™‚çµæœ
                self._print_check_result(health_result)
                
                # ç­‰å¾…ä¸‹ä¸€æ¬¡æª¢æŸ¥
                if not self.stop_event.is_set():
                    time.sleep(self.check_interval_minutes * 60)
        
        except KeyboardInterrupt:
            print("\nâ¹ï¸ æ”¶åˆ°ä¸­æ–·ä¿¡è™Ÿï¼Œæ­£åœ¨åœæ­¢æ¸¬è©¦...")
            self.stop_event.set()
        
        # ç”Ÿæˆæœ€çµ‚å ±å‘Š
        self._generate_stability_report(start_time, datetime.now())
        
    def _perform_health_check(self, check_number):
        """åŸ·è¡Œå¥åº·æª¢æŸ¥"""
        result = {
            "check_number": check_number,
            "timestamp": datetime.now().isoformat(),
            "connection_test": False,
            "response_test": False,
            "performance_test": False,
            "connection_time": 0,
            "response_time": 0,
            "response_quality": 0,
            "errors": []
        }
        
        ssh = None
        
        try:
            # 1. é€£æ¥æ¸¬è©¦
            connect_start = time.time()
            ssh = paramiko.SSHClient()
            ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())
            ssh.connect("10.10.172.5", username="svd", password="1234", timeout=15)
            result["connection_time"] = time.time() - connect_start
            result["connection_test"] = True
            
            # 2. åŸºæœ¬å›æ‡‰æ¸¬è©¦
            test_question = "Hello, please respond briefly"
            command = f'echo "{test_question}" | ollama run deepseek-r1:14b --'
            
            response_start = time.time()
            stdin, stdout, stderr = ssh.exec_command(command, timeout=45)
            response = stdout.read().decode('utf-8')
            result["response_time"] = time.time() - response_start
            
            if response.strip():
                result["response_test"] = True
                result["response_quality"] = self._evaluate_response_quality(response)
            
            # 3. æ•ˆèƒ½æ¸¬è©¦ (ç°¡åŒ–ç‰ˆ)
            if result["response_time"] <= 30 and result["response_quality"] >= 0.7:
                result["performance_test"] = True
            
        except Exception as e:
            result["errors"].append(str(e))
        
        finally:
            if ssh:
                ssh.close()
        
        return result
    
    def _evaluate_response_quality(self, response):
        """è©•ä¼°å›æ‡‰å“è³ª"""
        # ç°¡å–®çš„å“è³ªè©•ä¼°
        if not response.strip():
            return 0.0
        
        quality_score = 0.5  # åŸºç¤åˆ†æ•¸
        
        # é•·åº¦æª¢æŸ¥
        if len(response.strip()) >= 10:
            quality_score += 0.2
        
        # æ˜¯å¦åŒ…å«å¸¸è¦‹å•å€™å›æ‡‰
        common_responses = ["hello", "hi", "good", "thank", "help", "assist"]
        if any(word in response.lower() for word in common_responses):
            quality_score += 0.2
        
        # æ˜¯å¦æœ‰æ˜é¡¯çš„ç·¨ç¢¼å•é¡Œ
        if 'ï¿½' not in response and not response.count('\\'):
            quality_score += 0.1
        
        return min(quality_score, 1.0)
    
    def _print_check_result(self, result):
        """åˆ—å°æª¢æŸ¥çµæœ"""
        status_indicators = {
            "connection_test": "âœ…" if result["connection_test"] else "âŒ",
            "response_test": "âœ…" if result["response_test"] else "âŒ",
            "performance_test": "âœ…" if result["performance_test"] else "âŒ"
        }
        
        print(f"  é€£æ¥æ¸¬è©¦: {status_indicators['connection_test']} ({result['connection_time']:.2f}s)")
        print(f"  å›æ‡‰æ¸¬è©¦: {status_indicators['response_test']} ({result['response_time']:.2f}s)")
        print(f"  æ•ˆèƒ½æ¸¬è©¦: {status_indicators['performance_test']}")
        
        if result["errors"]:
            print(f"  âŒ éŒ¯èª¤: {', '.join(result['errors'][:2])}")
        
        # å¥åº·åˆ†æ•¸
        health_score = sum([
            result["connection_test"],
            result["response_test"],
            result["performance_test"]
        ]) / 3 * 100
        
        print(f"  ğŸ¥ å¥åº·åˆ†æ•¸: {health_score:.0f}%")
    
    def _generate_stability_report(self, start_time, end_time):
        """ç”Ÿæˆç©©å®šæ€§å ±å‘Š"""
        if not self.results:
            print("âŒ ç„¡æ¸¬è©¦è³‡æ–™")
            return
        
        # è¨ˆç®—çµ±è¨ˆè³‡æ–™
        total_checks = len(self.results)
        successful_connections = sum(1 for r in self.results if r['connection_test'])
        successful_responses = sum(1 for r in self.results if r['response_test'])
        successful_performance = sum(1 for r in self.results if r['performance_test'])
        
        connection_rate = (successful_connections / total_checks) * 100
        response_rate = (successful_responses / total_checks) * 100
        performance_rate = (successful_performance / total_checks) * 100
        
        # æ™‚é–“çµ±è¨ˆ
        response_times = [r['response_time'] for r in self.results if r['response_test']]
        if response_times:
            avg_response_time = statistics.mean(response_times)
            median_response_time = statistics.median(response_times)
        else:
            avg_response_time = median_response_time = 0
        
        # ç”Ÿæˆå ±å‘Š
        report = {
            "test_period": {
                "start_time": start_time.isoformat(),
                "end_time": end_time.isoformat(),
                "duration_hours": (end_time - start_time).total_seconds() / 3600
            },
            "summary": {
                "total_checks": total_checks,
                "connection_success_rate": connection_rate,
                "response_success_rate": response_rate,
                "performance_success_rate": performance_rate,
                "overall_availability": min(connection_rate, response_rate)
            },
            "performance_metrics": {
                "avg_response_time": avg_response_time,
                "median_response_time": median_response_time
            },
            "detailed_results": self.results
        }
        
        # é¡¯ç¤ºå ±å‘Š
        print("\n" + "=" * 60)
        print("ğŸ”„ é•·æœŸç©©å®šæ€§æ¸¬è©¦å ±å‘Š")
        print("=" * 60)
        
        duration_hours = (end_time - start_time).total_seconds() / 3600
        print(f"ğŸ“… æ¸¬è©¦æœŸé–“: {start_time.strftime('%Y-%m-%d %H:%M')} - {end_time.strftime('%Y-%m-%d %H:%M')}")
        print(f"â±ï¸ æ¸¬è©¦æ™‚é•·: {duration_hours:.1f} å°æ™‚")
        print(f"ğŸ” æª¢æŸ¥æ¬¡æ•¸: {total_checks}")
        
        print(f"\nğŸ“Š å¯ç”¨æ€§çµ±è¨ˆ:")
        print(f"  é€£æ¥æˆåŠŸç‡: {connection_rate:.1f}%")
        print(f"  å›æ‡‰æˆåŠŸç‡: {response_rate:.1f}%")
        print(f"  æ•ˆèƒ½é”æ¨™ç‡: {performance_rate:.1f}%")
        print(f"  æ•´é«”å¯ç”¨æ€§: {min(connection_rate, response_rate):.1f}%")
        
        if response_times:
            print(f"\nâ±ï¸ æ•ˆèƒ½çµ±è¨ˆ:")
            print(f"  å¹³å‡å›æ‡‰æ™‚é–“: {avg_response_time:.2f}s")
            print(f"  ä¸­ä½æ•¸å›æ‡‰æ™‚é–“: {median_response_time:.2f}s")
        
        # ç©©å®šæ€§è©•ç´š
        overall_availability = min(connection_rate, response_rate)
        if overall_availability >= 99.9:
            stability_grade = "æ¥µä½³ ğŸ†"
        elif overall_availability >= 99.0:
            stability_grade = "å„ªç§€ ğŸ‘"
        elif overall_availability >= 95.0:
            stability_grade = "è‰¯å¥½ âš¡"
        elif overall_availability >= 90.0:
            stability_grade = "å¯æ¥å— âš ï¸"
        else:
            stability_grade = "éœ€æ”¹å–„ âŒ"
        
        print(f"\nğŸ† ç©©å®šæ€§è©•ç´š: {stability_grade}")
        
        # å„²å­˜å ±å‘Š
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"stability_test_report_{timestamp}.json"
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        print(f"\nğŸ’¾ è©³ç´°å ±å‘Šå·²å„²å­˜è‡³: {filename}")

# ä½¿ç”¨ç¯„ä¾‹
if __name__ == "__main__":
    # åŸ·è¡Œ 2 å°æ™‚ç©©å®šæ€§æ¸¬è©¦ï¼Œæ¯ 10 åˆ†é˜æª¢æŸ¥ä¸€æ¬¡
    stability_test = LongTermStabilityTest(
        test_duration_hours=2,
        check_interval_minutes=10
    )
    
    stability_test.run_stability_test()
```

## ğŸ“Š æ•ˆèƒ½ç›£æ§å„€è¡¨æ¿

### å³æ™‚ç›£æ§è…³æœ¬
```python
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
DeepSeek AI å³æ™‚æ•ˆèƒ½ç›£æ§
"""
import paramiko
import time
import threading
import json
from datetime import datetime
from collections import deque

class PerformanceMonitor:
    """æ•ˆèƒ½ç›£æ§å™¨"""
    
    def __init__(self, update_interval=30):
        self.update_interval = update_interval
        self.metrics_history = deque(maxlen=100)  # ä¿ç•™æœ€è¿‘100æ¬¡è¨˜éŒ„
        self.is_running = False
        self.monitor_thread = None
        
    def start_monitoring(self):
        """é–‹å§‹ç›£æ§"""
        if self.is_running:
            print("âš ï¸ ç›£æ§å·²åœ¨é‹è¡Œä¸­")
            return
        
        self.is_running = True
        self.monitor_thread = threading.Thread(target=self._monitor_loop)
        self.monitor_thread.daemon = True
        self.monitor_thread.start()
        
        print("ğŸ” æ•ˆèƒ½ç›£æ§å·²å•Ÿå‹•")
        print(f"æ›´æ–°é–“éš”: {self.update_interval} ç§’")
        print("æŒ‰ Ctrl+C åœæ­¢ç›£æ§")
        
    def stop_monitoring(self):
        """åœæ­¢ç›£æ§"""
        self.is_running = False
        if self.monitor_thread:
            self.monitor_thread.join()
        print("â¹ï¸ æ•ˆèƒ½ç›£æ§å·²åœæ­¢")
        
    def _monitor_loop(self):
        """ç›£æ§å¾ªç’°"""
        while self.is_running:
            try:
                metrics = self._collect_metrics()
                self.metrics_history.append(metrics)
                self._display_dashboard(metrics)
                time.sleep(self.update_interval)
            except KeyboardInterrupt:
                break
            except Exception as e:
                print(f"âŒ ç›£æ§éŒ¯èª¤: {e}")
                time.sleep(self.update_interval)
    
    def _collect_metrics(self):
        """æ”¶é›†æ•ˆèƒ½æŒ‡æ¨™"""
        metrics = {
            "timestamp": datetime.now().isoformat(),
            "connection_status": False,
            "connection_time": 0,
            "response_time": 0,
            "service_status": "unknown",
            "error": None
        }
        
        ssh = None
        try:
            # æ¸¬è©¦é€£æ¥
            connect_start = time.time()
            ssh = paramiko.SSHClient()
            ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())
            ssh.connect("10.10.172.5", username="svd", password="1234", timeout=10)
            metrics["connection_time"] = time.time() - connect_start
            metrics["connection_status"] = True
            
            # æ¸¬è©¦å›æ‡‰
            test_start = time.time()
            stdin, stdout, stderr = ssh.exec_command('echo "test" | ollama run deepseek-r1:14b --', timeout=30)
            response = stdout.read().decode('utf-8')
            metrics["response_time"] = time.time() - test_start
            
            if response.strip():
                metrics["service_status"] = "healthy"
            else:
                metrics["service_status"] = "degraded"
                
        except Exception as e:
            metrics["error"] = str(e)
            metrics["service_status"] = "error"
        
        finally:
            if ssh:
                ssh.close()
        
        return metrics
    
    def _display_dashboard(self, current_metrics):
        """é¡¯ç¤ºå„€è¡¨æ¿"""
        # æ¸…é™¤è¢å¹• (å¯é¸)
        # import os
        # os.system('clear' if os.name == 'posix' else 'cls')
        
        print("\n" + "=" * 60)
        print("ğŸ“Š DeepSeek AI æ•ˆèƒ½ç›£æ§å„€è¡¨æ¿")
        print("=" * 60)
        print(f"ğŸ•’ æ›´æ–°æ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        
        # ç•¶å‰ç‹€æ…‹
        status_icon = "ğŸŸ¢" if current_metrics["service_status"] == "healthy" else "ğŸ”´"
        print(f"{status_icon} æœå‹™ç‹€æ…‹: {current_metrics['service_status']}")
        
        if current_metrics["connection_status"]:
            print(f"ğŸ”— é€£æ¥æ™‚é–“: {current_metrics['connection_time']:.2f}s")
            print(f"â±ï¸ å›æ‡‰æ™‚é–“: {current_metrics['response_time']:.2f}s")
        else:
            print("âŒ é€£æ¥å¤±æ•—")
        
        if current_metrics["error"]:
            print(f"ğŸš¨ éŒ¯èª¤: {current_metrics['error'][:50]}...")
        
        # æ­·å²çµ±è¨ˆ (å¦‚æœæœ‰è¶³å¤ è³‡æ–™)
        if len(self.metrics_history) >= 5:
            self._display_historical_stats()
    
    def _display_historical_stats(self):
        """é¡¯ç¤ºæ­·å²çµ±è¨ˆ"""
        recent_metrics = list(self.metrics_history)[-10:]  # æœ€è¿‘10æ¬¡
        
        # è¨ˆç®—æˆåŠŸç‡
        successful_connections = sum(1 for m in recent_metrics if m["connection_status"])
        healthy_services = sum(1 for m in recent_metrics if m["service_status"] == "healthy")
        
        connection_rate = (successful_connections / len(recent_metrics)) * 100
        health_rate = (healthy_services / len(recent_metrics)) * 100
        
        print(f"\nğŸ“ˆ æœ€è¿‘çµ±è¨ˆ (åŸºæ–¼æœ€è¿‘ {len(recent_metrics)} æ¬¡æª¢æŸ¥):")
        print(f"  é€£æ¥æˆåŠŸç‡: {connection_rate:.0f}%")
        print(f"  æœå‹™å¥åº·ç‡: {health_rate:.0f}%")
        
        # å¹³å‡å›æ‡‰æ™‚é–“
        response_times = [m["response_time"] for m in recent_metrics if m["connection_status"]]
        if response_times:
            avg_response_time = sum(response_times) / len(response_times)
            print(f"  å¹³å‡å›æ‡‰æ™‚é–“: {avg_response_time:.2f}s")

# ä½¿ç”¨ç¯„ä¾‹
if __name__ == "__main__":
    monitor = PerformanceMonitor(update_interval=30)
    
    try:
        monitor.start_monitoring()
        
        # ä¿æŒä¸»ç·šç¨‹é‹è¡Œ
        while monitor.is_running:
            time.sleep(1)
            
    except KeyboardInterrupt:
        print("\næ”¶åˆ°ä¸­æ–·ä¿¡è™Ÿ...")
        monitor.stop_monitoring()
```

## ğŸ¯ æ•ˆèƒ½å„ªåŒ–å»ºè­°

### æœ€ä½³å¯¦è¸
1. **é€£æ¥æ± ç®¡ç†**: é‡ç”¨ SSH é€£æ¥æ¸›å°‘å»ºç«‹æ™‚é–“
2. **æ‰¹é‡æ¸¬è©¦**: ä¸€æ¬¡é€£æ¥åŸ·è¡Œå¤šå€‹æ¸¬è©¦
3. **è¶…æ™‚è¨­å®š**: åˆç†è¨­å®šè¶…æ™‚é¿å…é•·æ™‚é–“ç­‰å¾…
4. **è² è¼‰æ§åˆ¶**: é¿å…éåº¦è«‹æ±‚é€ æˆæœå‹™éè¼‰
5. **ç›£æ§å‘Šè­¦**: è¨­å®šæ•ˆèƒ½é–¾å€¼å’Œå‘Šè­¦æ©Ÿåˆ¶

### æ•ˆèƒ½èª¿å„ª
- æ ¹æ“šå•é¡Œè¤‡é›œåº¦èª¿æ•´è¶…æ™‚æ™‚é–“
- ä½¿ç”¨æ›´ç°¡å–®çš„å•é¡Œé€²è¡Œå¥åº·æª¢æŸ¥
- å¯¦æ–½è«‹æ±‚é™æµé¿å…ç³»çµ±éè¼‰
- ç›£æ§æœå‹™å™¨è³‡æºä½¿ç”¨æƒ…æ³

---

**å»ºç«‹æ™‚é–“**: 2025-09-09  
**æ¸¬è©¦é¡å‹**: æ•ˆèƒ½æ¸¬è©¦ã€å£“åŠ›æ¸¬è©¦ã€ç©©å®šæ€§æ¸¬è©¦  
**ä¾è³´å¥—ä»¶**: paramiko, threading, statistics