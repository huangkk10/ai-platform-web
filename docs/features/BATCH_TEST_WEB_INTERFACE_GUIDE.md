# 批量測試 Web 介面使用指南

## 📋 功能概述

批量測試系統現在提供完整的 Web 介面，讓您可以在瀏覽器中：
1. ✅ **執行批量測試** - 選擇多個版本和測試案例進行批量測試
2. ✅ **查看測試結果** - 即時查看測試進度和結果
3. ✅ **查找歷史記錄** - 瀏覽所有歷史批量測試記錄
4. ✅ **對比分析** - 查看版本對比分析和排名

---

## 🚀 快速開始

### 1️⃣ **執行新的批量測試**

**路徑**：`Benchmark → Batch Test`

**步驟**：
1. 訪問 http://10.10.172.127/benchmark/batch-test
2. **選擇版本**：勾選要測試的搜尋演算法版本（可多選）
3. **選擇測試案例**：勾選要執行的測試案例（可多選）
4. **填寫資訊**（可選）：
   - 批次名稱：例如「週末性能測試」
   - 備註：測試目的或特殊說明
5. **開始測試**：點擊「開始批量測試」按鈕
6. **等待完成**：實時查看測試進度和結果
7. **查看對比**：測試完成後，點擊「查看對比結果」

**功能特點**：
- ✅ 支援全選/取消全選版本和測試案例
- ✅ 顯示即時測試進度（當前版本、總進度）
- ✅ 動態更新測試結果（分數、耗時等）
- ✅ 一鍵跳轉到對比頁面

---

### 2️⃣ **查看批量測試歷史記錄**

**路徑**：`Benchmark → Batch History`

**功能**：
- 📜 **列表顯示**：所有歷史批量測試記錄
- 🔍 **快速搜尋**：按 Batch ID 搜尋
- 📊 **統計資訊**：
  - 測試時間
  - 測試版本數
  - 平均分數
  - 最佳版本及分數
- 🎯 **快速操作**：點擊「查看對比」直接跳轉到對比頁面

**使用方式**：
1. 訪問 http://10.10.172.127/benchmark/batch-history
2. 瀏覽所有歷史測試記錄
3. 使用搜尋框快速找到特定 batch_id 的測試
4. 點擊「查看對比」按鈕查看詳細對比分析

**表格欄位說明**：
- **批次 ID**：格式為 `YYYYMMDD_HHMMSS`（可複製）
- **測試時間**：測試執行的日期時間
- **測試版本數**：參與測試的版本數量
- **平均分數**：所有版本的平均得分（顏色標示：綠色≥0.8，黃色≥0.6，紅色<0.6）
- **最佳版本**：得分最高的版本名稱和分數
- **操作**：查看對比結果按鈕

---

### 3️⃣ **查看版本對比分析**

**路徑**：`/benchmark/comparison/:batchId`

**訪問方式**：
- 方法 1：批量測試完成後，點擊「查看對比結果」
- 方法 2：從「Batch History」頁面點擊「查看對比」
- 方法 3：直接訪問 URL（需要知道 batch_id）

**對比內容**：

#### 📊 **總體排名**
- 按總體分數排序的版本排名
- 顯示每個版本的：
  - 版本名稱
  - Overall Score（總體分數）
  - Precision（精準度）
  - Recall（召回率）
  - F1 Score（F1 分數）
  - NDCG（排序質量）
  - 響應時間
  - 通過率

#### 🎯 **專項排名**
- **最佳精準度**：Precision 最高的版本
- **最佳召回率**：Recall 最高的版本
- **最佳 F1 分數**：F1 Score 最高的版本
- **最快響應時間**：平均響應時間最短的版本

#### 🔍 **權衡分析**
自動分析並標示：
- 🎯 **高精準度版本**（Precision > 80%）
  - 適合：準確性優先、容錯率低的場景
- 📚 **高召回率版本**（Recall > 90%）
  - 適合：完整性優先、不能遺漏的場景
- ⚖️ **平衡版本**（F1 Score > 85%）
  - 適合：需要精準度和召回率平衡的場景
- ⚡ **快速響應版本**（響應時間 < 100ms）
  - 適合：實時性要求高的場景

---

## 🎯 使用場景

### 場景 1：週期性性能評估
**目標**：定期測試所有版本，追蹤性能變化

**步驟**：
1. 每週執行一次批量測試（選擇所有版本 + 所有測試案例）
2. 從「Batch History」查看歷史趨勢
3. 對比不同週期的結果，分析性能變化

---

### 場景 2：新版本驗證
**目標**：測試新版本是否優於現有版本

**步驟**：
1. 選擇：新版本 + Baseline Version
2. 執行批量測試
3. 查看對比結果，確認新版本的改進點

---

### 場景 3：特定場景優化
**目標**：為特定應用場景選擇最佳版本

**步驟**：
1. 選擇相關的測試案例（例如：只選擇 CUP 相關測試）
2. 選擇所有版本進行測試
3. 根據「權衡分析」選擇最適合的版本

---

## 📡 API 端點

### 執行批量測試
```http
POST /api/benchmark/versions/batch_test/
Content-Type: application/json

{
  "version_ids": [3, 4, 5],
  "test_case_ids": [1, 2],
  "batch_name": "週末性能測試",
  "notes": "測試新的搜尋策略",
  "force_retest": false
}
```

**回應範例**：
```json
{
  "success": true,
  "batch_id": "20251123_083342",
  "batch_name": "週末性能測試",
  "test_run_ids": [42, 43, 44],
  "comparison": {
    "versions": [...],
    "ranking": {...},
    "best_version": {...}
  },
  "summary": {
    "total_versions_tested": 3,
    "total_test_cases": 2,
    "total_tests_executed": 6,
    "execution_time": 45.23
  }
}
```

### 查詢批量測試記錄
```http
GET /api/benchmark/test-runs/?run_type=batch_comparison
```

**回應範例**：
```json
{
  "count": 15,
  "next": null,
  "previous": null,
  "results": [
    {
      "id": 42,
      "version": {
        "id": 3,
        "version_name": "Baseline Version"
      },
      "overall_score": 0.85,
      "precision": 0.82,
      "recall": 0.88,
      "f1_score": 0.85,
      "notes": "批次 ID: 20251123_083342",
      "created_at": "2025-11-23T08:33:42Z"
    }
  ]
}
```

---

## 🔧 技術細節

### 前端組件
- **BatchTestExecutionPage** - 批量測試執行頁面
- **BatchTestHistoryPage** - 歷史記錄查詢頁面（新增）
- **BatchComparisonPage** - 版本對比分析頁面

### 後端 API
- **SearchAlgorithmVersionViewSet.batch_test** - 執行批量測試
- **BenchmarkTestRunViewSet** - 查詢測試執行記錄
  - 支援篩選：`run_type=batch_comparison`

### 資料流程
```
用戶選擇版本 → 前端發送 API 請求 → BatchVersionTester 執行測試
→ 儲存測試結果（含 batch_id） → 前端跳轉到對比頁面
→ 查詢測試記錄（按 batch_id 篩選） → 生成對比分析 → 展示結果
```

---

## ✅ 驗證清單

執行批量測試前的檢查：
- [ ] 至少選擇 1 個版本
- [ ] 至少選擇 1 個測試案例
- [ ] 確認測試環境正常（Django + PostgreSQL + Celery）
- [ ] 確認有足夠的資源執行測試（CPU + 記憶體）

查看結果時的檢查：
- [ ] Batch ID 格式正確（YYYYMMDD_HHMMSS）
- [ ] 測試執行記錄數量 = 版本數 × 測試案例數
- [ ] 所有版本都有完整的評分資料
- [ ] 對比分析正常顯示

---

## 🐛 常見問題

### Q1: 找不到對應的批量測試記錄
**問題**：對比頁面顯示「找不到對應的批量測試記錄」

**可能原因**：
1. Batch ID 不正確
2. 測試剛完成，資料還未寫入資料庫（需等待 1-2 秒）
3. 測試執行失敗，沒有產生記錄

**解決方法**：
1. 檢查瀏覽器控制台（F12）查看調試資訊
2. 從「Batch History」頁面確認 batch_id 是否存在
3. 重新執行批量測試

---

### Q2: 版本列表或測試案例列表為空
**問題**：批量測試頁面載入後，列表為空

**可能原因**：
1. 沒有建立任何版本或測試案例
2. API 權限問題

**解決方法**：
1. 確認資料庫中有版本和測試案例資料
2. 檢查瀏覽器控制台的 API 回應

---

### Q3: 測試執行時間過長
**問題**：批量測試執行超過預期時間

**可能原因**：
1. 選擇了過多版本和測試案例（測試數 = 版本數 × 案例數）
2. 搜尋演算法本身較慢
3. 資料庫或 Celery 性能問題

**建議**：
1. 分批測試（先測試少量版本）
2. 使用「force_retest: false」避免重複測試
3. 監控系統資源使用情況

---

## 📊 性能參考

| 版本數 | 測試案例數 | 預估時間 |
|--------|-----------|----------|
| 2      | 2         | ~30 秒   |
| 5      | 5         | ~2 分鐘  |
| 7      | 10        | ~5 分鐘  |
| 10     | 20        | ~15 分鐘 |

**注意**：實際時間取決於搜尋演算法複雜度和系統性能。

---

## 🎓 最佳實踐

1. **定期測試**：建立固定的測試週期（例如每週測試一次）
2. **版本命名**：使用有意義的版本名稱（例如「Baseline v1.0」）
3. **測試記錄**：在 batch_name 和 notes 中記錄測試目的
4. **對比分析**：測試完成後立即查看對比結果，做出決策
5. **歷史追蹤**：定期檢視「Batch History」，追蹤性能趨勢

---

## 📝 更新日誌

### 2025-11-23
- ✅ 新增「Batch History」頁面
- ✅ 對比頁面改為使用真實資料（不再使用 mock 資料）
- ✅ 新增調試日誌（控制台輸出）
- ✅ 完善批量測試查詢功能
- ✅ 支援按 batch_id 快速跳轉

---

**文檔版本**：v1.0  
**更新日期**：2025-11-23  
**適用版本**：AI Platform v2.0+
