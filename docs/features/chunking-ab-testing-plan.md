# ğŸ§ª çµæ§‹åŒ– Chunking ç³»çµ± A/B æ¸¬è©¦è¨ˆåŠƒ

## ğŸ“‹ æ¸¬è©¦æ¦‚è¦

**æ¸¬è©¦ç›®æ¨™**: é‡åŒ–è©•ä¼°ã€Œçµæ§‹åŒ– Chunkingã€vsã€Œæ•´ç¯‡å‘é‡åŒ–ã€çš„å¯¦éš›æ•ˆç›Šå·®ç•°  
**æ¸¬è©¦æ–¹æ³•**: ä¸¦è¡Œé‹è¡Œå…©å¥—ç³»çµ±ï¼Œå°æ¯”é—œéµæŒ‡æ¨™  
**æ¸¬è©¦æ™‚é•·**: 2-4 é€±ï¼ˆæ”¶é›†è¶³å¤ æ¨£æœ¬ï¼‰  
**æ±ºç­–æ¨™æº–**: å¦‚æœçµæ§‹åŒ– Chunking åœ¨æ ¸å¿ƒæŒ‡æ¨™ä¸Šæå‡ > 20%ï¼Œå‰‡å…¨é¢æ¡ç”¨

---

## ğŸ¯ æ¸¬è©¦æ¶æ§‹è¨­è¨ˆ

### æ–¹æ¡ˆ Aï¼šä¸¦è¡Œé›™ç³»çµ±æ¸¬è©¦ï¼ˆæ¨è–¦ï¼‰â­â­â­â­â­

```
ç”¨æˆ¶æŸ¥è©¢ "ULINK é€£æ¥å¤±æ•—æ€éº¼è¾¦ï¼Ÿ"
    â†“
åŒæ™‚èª¿ç”¨å…©å¥—æœå°‹ç³»çµ±
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   ç³»çµ± A (ç•¶å‰)      â”‚   ç³»çµ± B (æ–°)        â”‚
â”‚   æ•´ç¯‡å‘é‡åŒ–         â”‚   çµæ§‹åŒ– Chunking    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ æœå°‹ document_      â”‚ æœå°‹ document_      â”‚
â”‚ embeddings è¡¨        â”‚ section_embeddings  â”‚
â”‚                     â”‚ è¡¨                   â”‚
â”‚ è¿”å›: æ•´ç¯‡æ–‡æª”       â”‚ è¿”å›: ç²¾ç¢ºæ®µè½       â”‚
â”‚ (600 å­—)            â”‚ (50 å­—)              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“                      â†“
è¨˜éŒ„æŒ‡æ¨™ A              è¨˜éŒ„æŒ‡æ¨™ B
    â†“                      â†“
        å°æ¯”åˆ†æå„€è¡¨æ¿
```

**å„ªå‹¢**ï¼š
- âœ… åŒä¸€æŸ¥è©¢ï¼Œå…©å¥—çµæœï¼Œç›´æ¥å°æ¯”
- âœ… ä¸å½±éŸ¿ç”¨æˆ¶é«”é©—ï¼ˆé¸æ“‡æ€§å±•ç¤ºï¼‰
- âœ… æ•¸æ“šæœ€å®¢è§€

---

## ğŸ“Š è©•ä¼°æŒ‡æ¨™é«”ç³»

### 1ï¸âƒ£ **æœå°‹å“è³ªæŒ‡æ¨™**ï¼ˆæœ€é‡è¦ï¼‰

#### 1.1 ç²¾æº–åº¦ (Precision)
```python
# è¨ˆç®—å…¬å¼
precision = ç›¸é—œçµæœæ•¸é‡ / è¿”å›çµæœç¸½æ•¸

# è©•ä¼°æ–¹æ³•
äººå·¥æ¨™è¨» 100 å€‹æŸ¥è©¢çš„æœå°‹çµæœï¼š
- å®Œå…¨ç›¸é—œ (2åˆ†)
- éƒ¨åˆ†ç›¸é—œ (1åˆ†)
- ä¸ç›¸é—œ (0åˆ†)

å¹³å‡ç²¾æº–åº¦ = Î£(åˆ†æ•¸) / (è¿”å›çµæœæ•¸ * 2)
```

**æ¸¬è©¦æ¡ˆä¾‹**ï¼š
```python
test_queries = [
    "ULINK é€£æ¥å¤±æ•—æ€éº¼è¾¦",
    "å¦‚ä½•æº–å‚™æ¸¬è©¦ç’°å¢ƒ",
    "Samsung Protocol æ¸¬è©¦æ­¥é©Ÿ",
    "è‡ªå‹•åŒ–è…³æœ¬å¦‚ä½•å®‰è£",
    "é€Ÿåº¦æ…¢çš„å„ªåŒ–æ–¹æ³•"
]

# äººå·¥è©•åˆ†æ¨™æº–
def evaluate_result(query, result):
    """
    å®Œå…¨ç›¸é—œ (2åˆ†): çµæœç›´æ¥å›ç­”æŸ¥è©¢å•é¡Œ
    éƒ¨åˆ†ç›¸é—œ (1åˆ†): çµæœæä¾›éƒ¨åˆ†ç›¸é—œè³‡è¨Š
    ä¸ç›¸é—œ (0åˆ†): çµæœèˆ‡æŸ¥è©¢ç„¡é—œ
    """
    pass
```

#### 1.2 å¬å›ç‡ (Recall)
```python
# è¨ˆç®—å…¬å¼
recall = æ‰¾åˆ°çš„ç›¸é—œçµæœæ•¸ / æ‰€æœ‰ç›¸é—œçµæœç¸½æ•¸

# è©•ä¼°æ–¹æ³•
é å…ˆæ¨™è¨»è³‡æ–™åº«ä¸­å“ªäº›æ®µè½/æ–‡æª”èˆ‡æŸ¥è©¢ç›¸é—œ
æª¢æŸ¥æœå°‹çµæœæ˜¯å¦åŒ…å«é€™äº›ç›¸é—œå…§å®¹
```

#### 1.3 ç›¸ä¼¼åº¦åˆ†æ•¸ (Similarity Score)
```python
# å°æ¯”å…©ç¨®æ–¹æ³•çš„å¹³å‡ç›¸ä¼¼åº¦
avg_similarity_A = np.mean([r['similarity'] for r in results_A])
avg_similarity_B = np.mean([r['similarity'] for r in results_B])

improvement = (avg_similarity_B - avg_similarity_A) / avg_similarity_A * 100
```

---

### 2ï¸âƒ£ **ç”¨æˆ¶é«”é©—æŒ‡æ¨™**

#### 2.1 ç­”æ¡ˆå®šä½æ™‚é–“
```python
# æ¸¬é‡ç”¨æˆ¶æ‰¾åˆ°ç­”æ¡ˆçš„æ™‚é–“
class AnswerLocatingTimer:
    def __init__(self):
        self.start_time = None
        self.end_time = None
    
    def start_query(self):
        """ç”¨æˆ¶é–‹å§‹æŸ¥è©¢"""
        self.start_time = time.time()
    
    def found_answer(self):
        """ç”¨æˆ¶æ‰¾åˆ°ç­”æ¡ˆï¼ˆé»æ“Šã€åœç•™ > 5ç§’ï¼‰"""
        self.end_time = time.time()
        return self.end_time - self.start_time

# å°æ¯”
avg_time_A = np.mean([t for t in times_A])  # é æœŸ: 120-180ç§’
avg_time_B = np.mean([t for t in times_B])  # é æœŸ: 10-20ç§’
```

#### 2.2 é–±è®€é‡
```python
# è¿”å›çš„å…§å®¹ç¸½å­—æ•¸
reading_load_A = sum([len(r['content']) for r in results_A])
reading_load_B = sum([len(r['content']) for r in results_B])

reduction = (reading_load_A - reading_load_B) / reading_load_A * 100
# é æœŸ: æ¸›å°‘ 70-92%
```

#### 2.3 é»æ“Šç‡ (CTR)
```python
# ç”¨æˆ¶é»æ“Šæœå°‹çµæœçš„æ¯”ä¾‹
ctr_A = clicks_A / impressions_A
ctr_B = clicks_B / impressions_B

# é æœŸ: ç³»çµ± B çš„ CTR æå‡ 30-50%
```

#### 2.4 åœç•™æ™‚é–“
```python
# ç”¨æˆ¶åœ¨çµæœä¸Šçš„åœç•™æ™‚é–“ï¼ˆæŒ‡æ¨™ï¼šæ‰¾åˆ°ç­”æ¡ˆï¼‰
dwell_time_A = avg_time_on_result_A  # é æœŸ: 60-90ç§’
dwell_time_B = avg_time_on_result_B  # é æœŸ: 10-20ç§’
```

---

### 3ï¸âƒ£ **ç³»çµ±æ€§èƒ½æŒ‡æ¨™**

#### 3.1 éŸ¿æ‡‰æ™‚é–“
```python
# æŸ¥è©¢åŸ·è¡Œæ™‚é–“
response_time_A = end_time_A - start_time_A  # é æœŸ: 80-120ms
response_time_B = end_time_B - start_time_B  # é æœŸ: 100-150ms

# å…è¨±ç•¥å¾®å¢åŠ ï¼ˆ20-30msï¼‰ï¼Œå› ç‚ºç²¾æº–åº¦å¤§å¹…æå‡
```

#### 3.2 è³‡æ–™åº«æŸ¥è©¢æ•ˆç‡
```python
# SQL æŸ¥è©¢æ™‚é–“
query_time_A = time_to_search_documents
query_time_B = time_to_search_sections

# ç´¢å¼•æ•ˆèƒ½å°æ¯”
index_size_A = size_of_document_embeddings_index
index_size_B = size_of_section_embeddings_index
```

#### 3.3 å„²å­˜ç©ºé–“
```python
# å‘é‡æ•¸é‡å’Œç©ºé–“ä½”ç”¨
vectors_count_A = 5  # 5 ç¯‡æ–‡æª”
vectors_count_B = 25  # ç´„ 25 å€‹æ®µè½ï¼ˆ5xï¼‰

storage_A = calculate_storage(vectors_count_A, 1024)
storage_B = calculate_storage(vectors_count_B, 1024)

overhead = (storage_B - storage_A) / storage_A * 100
# é æœŸ: +400-500%ï¼ˆå¯æ¥å—ï¼Œå› ç‚ºç•¶å‰è³‡æ–™é‡å°ï¼‰
```

---

### 4ï¸âƒ£ **æ¥­å‹™åƒ¹å€¼æŒ‡æ¨™**

#### 4.1 ç”¨æˆ¶æ»¿æ„åº¦
```python
# ç”¨æˆ¶åé¥‹åˆ†æ•¸ï¼ˆé»è®š/é»è¸©ï¼‰
satisfaction_A = thumbs_up_A / (thumbs_up_A + thumbs_down_A)
satisfaction_B = thumbs_up_B / (thumbs_up_B + thumbs_down_B)

# é æœŸ: ç³»çµ± B æ»¿æ„åº¦ +20-30%
```

#### 4.2 æŸ¥è©¢æˆåŠŸç‡
```python
# å®šç¾©ã€ŒæˆåŠŸã€ï¼šç”¨æˆ¶æ‰¾åˆ°ç­”æ¡ˆä¸”åœç•™ > 5ç§’
success_rate_A = successful_queries_A / total_queries_A
success_rate_B = successful_queries_B / total_queries_B

# é æœŸ: ç³»çµ± B æˆåŠŸç‡ +25-35%
```

---

## ğŸ› ï¸ å¯¦æ–½æ­¥é©Ÿ

### éšæ®µ 1ï¼šæº–å‚™æ¸¬è©¦ç’°å¢ƒï¼ˆ3-5 å¤©ï¼‰

#### Step 1.1: å»ºç«‹æ®µè½å‘é‡è¡¨ï¼ˆä¸å½±éŸ¿ç¾æœ‰ç³»çµ±ï¼‰
```bash
# 1. å‰µå»ºæ–°è¡¨
docker exec postgres_db psql -U postgres -d ai_platform << 'EOF'
CREATE TABLE document_section_embeddings (
    id SERIAL PRIMARY KEY,
    source_table VARCHAR(100),
    source_id INTEGER,
    section_id VARCHAR(50),
    heading_level INTEGER,
    heading_text VARCHAR(500),
    section_path TEXT,
    parent_section_id VARCHAR(50),
    content TEXT,
    full_context TEXT,
    embedding vector(1024),
    word_count INTEGER,
    has_code BOOLEAN,
    has_images BOOLEAN,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    UNIQUE(source_table, source_id, section_id)
);

-- ç´¢å¼•
CREATE INDEX idx_section_embeddings_source 
    ON document_section_embeddings(source_table, source_id);

CREATE INDEX idx_section_embeddings_vector 
    ON document_section_embeddings 
    USING ivfflat (embedding vector_cosine_ops) WITH (lists = 100);

CREATE INDEX idx_section_embeddings_level 
    ON document_section_embeddings(heading_level);
EOF

# 2. é©—è­‰
docker exec postgres_db psql -U postgres -d ai_platform -c "\d document_section_embeddings"
```

#### Step 1.2: ç”Ÿæˆæ®µè½å‘é‡ï¼ˆé›¢ç·šè™•ç†ï¼‰
```python
# tests/test_section_vectorization.py

from library.common.knowledge_base.markdown_parser import MarkdownStructureParser
from library.common.knowledge_base.section_vectorization_service import SectionVectorizationService

def generate_section_vectors_for_testing():
    """ç‚ºç¾æœ‰ Protocol Guide ç”Ÿæˆæ®µè½å‘é‡ï¼ˆæ¸¬è©¦ç”¨ï¼‰"""
    
    parser = MarkdownStructureParser()
    service = SectionVectorizationService()
    
    # ç²å–æ‰€æœ‰ Protocol Guide
    guides = ProtocolGuide.objects.all()
    
    results = []
    for guide in guides:
        print(f"\nè™•ç†æ–‡æª” {guide.id}: {guide.title}")
        
        # è§£ææ®µè½
        sections = parser.parse(guide.content, guide.title)
        print(f"  è§£æå‡º {len(sections)} å€‹æ®µè½")
        
        # ç”Ÿæˆå‘é‡
        count = service.vectorize_document_sections(
            source_table='protocol_guide',
            source_id=guide.id,
            markdown_content=guide.content,
            document_title=guide.title
        )
        
        results.append({
            'guide_id': guide.id,
            'guide_title': guide.title,
            'sections_count': len(sections),
            'vectors_generated': count
        })
        
        print(f"  âœ… æˆåŠŸç”Ÿæˆ {count} å€‹å‘é‡")
    
    # çµ±è¨ˆ
    total_sections = sum([r['sections_count'] for r in results])
    total_vectors = sum([r['vectors_generated'] for r in results])
    
    print(f"\nğŸ“Š çµ±è¨ˆ:")
    print(f"  æ–‡æª”æ•¸: {len(results)}")
    print(f"  ç¸½æ®µè½æ•¸: {total_sections}")
    print(f"  ç¸½å‘é‡æ•¸: {total_vectors}")
    print(f"  æˆåŠŸç‡: {total_vectors / total_sections * 100:.1f}%")
    
    return results

# åŸ·è¡Œ
if __name__ == '__main__':
    results = generate_section_vectors_for_testing()
```

#### Step 1.3: å‰µå»ºå°æ¯”æ¸¬è©¦ API
```python
# backend/api/views/viewsets/knowledge_viewsets.py

class ProtocolGuideViewSet(viewsets.ModelViewSet):
    # ... ç¾æœ‰ä»£ç¢¼
    
    @action(detail=False, methods=['post'])
    def ab_test_search(self, request):
        """
        A/B æ¸¬è©¦æœå°‹ API
        
        åŒæ™‚è¿”å›å…©ç¨®æœå°‹çµæœï¼Œè¨˜éŒ„å°æ¯”æŒ‡æ¨™
        """
        query = request.data.get('query', '')
        limit = request.data.get('limit', 5)
        
        # ç³»çµ± A: æ•´ç¯‡æ–‡æª”æœå°‹
        start_time_a = time.time()
        results_a = self._search_whole_documents(query, limit)
        time_a = (time.time() - start_time_a) * 1000  # ms
        
        # ç³»çµ± B: æ®µè½æœå°‹
        start_time_b = time.time()
        results_b = self._search_sections(query, limit)
        time_b = (time.time() - start_time_b) * 1000  # ms
        
        # è¨˜éŒ„æ¸¬è©¦æ•¸æ“š
        self._log_ab_test_result(query, results_a, results_b, time_a, time_b)
        
        return Response({
            'query': query,
            'system_a': {
                'type': 'whole_document',
                'results': results_a,
                'response_time_ms': time_a,
                'total_content_length': sum([len(r['content']) for r in results_a])
            },
            'system_b': {
                'type': 'structured_chunking',
                'results': results_b,
                'response_time_ms': time_b,
                'total_content_length': sum([len(r['content']) for r in results_b])
            },
            'comparison': {
                'response_time_improvement': f"{(time_a - time_b) / time_a * 100:.1f}%",
                'content_reduction': f"{(sum([len(r['content']) for r in results_a]) - sum([len(r['content']) for r in results_b])) / sum([len(r['content']) for r in results_a]) * 100:.1f}%"
            }
        })
    
    def _search_whole_documents(self, query, limit):
        """ç³»çµ± A: æ•´ç¯‡æ–‡æª”æœå°‹ï¼ˆç•¶å‰æ–¹æ³•ï¼‰"""
        # ä½¿ç”¨ç¾æœ‰çš„å‘é‡æœå°‹é‚è¼¯
        pass
    
    def _search_sections(self, query, limit):
        """ç³»çµ± B: æ®µè½æœå°‹ï¼ˆæ–°æ–¹æ³•ï¼‰"""
        from library.common.knowledge_base.section_search_service import SectionSearchService
        
        service = SectionSearchService()
        return service.search_sections(
            query=query,
            source_table='protocol_guide',
            limit=limit
        )
    
    def _log_ab_test_result(self, query, results_a, results_b, time_a, time_b):
        """è¨˜éŒ„ A/B æ¸¬è©¦çµæœåˆ°è³‡æ–™åº«"""
        ABTestLog.objects.create(
            query=query,
            system_a_count=len(results_a),
            system_b_count=len(results_b),
            system_a_time_ms=time_a,
            system_b_time_ms=time_b,
            system_a_content_length=sum([len(r['content']) for r in results_a]),
            system_b_content_length=sum([len(r['content']) for r in results_b]),
            timestamp=timezone.now()
        )
```

---

### éšæ®µ 2ï¼šå»ºç«‹æ¸¬è©¦è³‡æ–™é›†ï¼ˆ2-3 å¤©ï¼‰

#### Step 2.1: æº–å‚™æ¨™æº–æ¸¬è©¦æŸ¥è©¢
```python
# tests/test_queries.py

TEST_QUERIES = [
    # é¡åˆ¥ 1: ç²¾ç¢ºå•é¡Œï¼ˆæœŸæœ›è¿”å›å–®ä¸€æ®µè½ï¼‰
    {
        'query': 'ULINK é€£æ¥å¤±æ•—æ€éº¼è¾¦',
        'expected_section': 'ULINK Protocol æ¸¬è©¦åŸºç¤æŒ‡å— > å¸¸è¦‹å•é¡Œ > é€£æ¥å¤±æ•—',
        'category': 'precise'
    },
    {
        'query': 'å¦‚ä½•å®‰è£æ¸¬è©¦è…³æœ¬',
        'expected_section': 'Protocol è‡ªå‹•åŒ–æ¸¬è©¦è…³æœ¬ä½¿ç”¨æŒ‡å— > å®‰è£èˆ‡è¨­å®š',
        'category': 'precise'
    },
    
    # é¡åˆ¥ 2: ä¸»é¡ŒæŸ¥è©¢ï¼ˆæœŸæœ›è¿”å› 2-3 å€‹ç›¸é—œæ®µè½ï¼‰
    {
        'query': 'å¦‚ä½•æº–å‚™æ¸¬è©¦ç’°å¢ƒ',
        'expected_sections': [
            'ULINK Protocol æ¸¬è©¦åŸºç¤æŒ‡å— > æ¸¬è©¦ç’°å¢ƒæº–å‚™',
            'Samsung Protocol ç›¸å®¹æ€§æ¸¬è©¦ > ç’°å¢ƒé…ç½®'
        ],
        'category': 'topic'
    },
    
    # é¡åˆ¥ 3: è¤‡é›œæŸ¥è©¢ï¼ˆæœŸæœ›è¿”å›å¤šå€‹æ®µè½ï¼‰
    {
        'query': 'Protocol æ¸¬è©¦çš„å®Œæ•´æµç¨‹',
        'expected_sections': [
            'ULINK Protocol æ¸¬è©¦åŸºç¤æŒ‡å— > æ¦‚è¿°',
            'ULINK Protocol æ¸¬è©¦åŸºç¤æŒ‡å— > æ¸¬è©¦ç’°å¢ƒæº–å‚™',
            'ULINK Protocol æ¸¬è©¦åŸºç¤æŒ‡å— > é€£æ¥æ­¥é©Ÿ'
        ],
        'category': 'complex'
    },
    
    # é¡åˆ¥ 4: æ¨¡ç³ŠæŸ¥è©¢ï¼ˆæ¸¬è©¦å¬å›ç‡ï¼‰
    {
        'query': 'é€Ÿåº¦å•é¡Œ',
        'expected_sections': [
            'ULINK Protocol æ¸¬è©¦åŸºç¤æŒ‡å— > å¸¸è¦‹å•é¡Œ > é€Ÿåº¦æ…¢'
        ],
        'category': 'vague'
    }
]

def generate_test_dataset():
    """ç”Ÿæˆå®Œæ•´æ¸¬è©¦è³‡æ–™é›†"""
    
    # 1. å¾è³‡æ–™åº«ä¸­æå–æ‰€æœ‰æ®µè½
    all_sections = get_all_sections_from_db()
    
    # 2. ç‚ºæ¯å€‹æŸ¥è©¢æ¨™è¨»ç›¸é—œæ®µè½
    annotated_queries = []
    
    for test_case in TEST_QUERIES:
        relevant_sections = []
        
        # äººå·¥æ¨™è¨»å“ªäº›æ®µè½èˆ‡æŸ¥è©¢ç›¸é—œ
        for section in all_sections:
            relevance = evaluate_relevance(test_case['query'], section)
            if relevance > 0:
                relevant_sections.append({
                    'section_id': section['id'],
                    'relevance_score': relevance  # 0-2 åˆ†
                })
        
        annotated_queries.append({
            **test_case,
            'relevant_sections': relevant_sections
        })
    
    return annotated_queries
```

#### Step 2.2: äººå·¥æ¨™è¨»åŸºæº–æ•¸æ“š
```python
# å‰µå»ºæ¨™è¨»å·¥å…·
def create_annotation_tool():
    """
    ç°¡å–®çš„æ¨™è¨»ä»‹é¢
    
    é¡¯ç¤ºæŸ¥è©¢å’Œæ‰€æœ‰æ®µè½ï¼Œè®“æ¨™è¨»è€…è©•åˆ†
    """
    for query in TEST_QUERIES:
        print(f"\næŸ¥è©¢: {query['query']}")
        print("=" * 80)
        
        sections = get_all_sections()
        
        for i, section in enumerate(sections, 1):
            print(f"\n{i}. {section['section_path']}")
            print(f"   å…§å®¹: {section['content'][:100]}...")
            
            score = input("ç›¸é—œåº¦ (0=ä¸ç›¸é—œ, 1=éƒ¨åˆ†ç›¸é—œ, 2=å®Œå…¨ç›¸é—œ): ")
            
            # å„²å­˜æ¨™è¨»
            save_annotation(query['query'], section['id'], int(score))
```

---

### éšæ®µ 3ï¼šåŸ·è¡Œæ¸¬è©¦ï¼ˆ2 é€±ï¼‰

#### Step 3.1: è‡ªå‹•åŒ–æ¸¬è©¦è…³æœ¬
```python
# tests/test_ab_comparison.py

import pytest
import numpy as np
from typing import List, Dict

class ABTestRunner:
    """A/B æ¸¬è©¦åŸ·è¡Œå™¨"""
    
    def __init__(self):
        self.test_queries = load_test_queries()
        self.results_a = []
        self.results_b = []
    
    def run_all_tests(self):
        """åŸ·è¡Œæ‰€æœ‰æ¸¬è©¦æŸ¥è©¢"""
        
        for test_case in self.test_queries:
            query = test_case['query']
            
            print(f"\næ¸¬è©¦æŸ¥è©¢: {query}")
            
            # ç³»çµ± A: æ•´ç¯‡æ–‡æª”
            result_a = self.search_system_a(query)
            
            # ç³»çµ± B: æ®µè½æœå°‹
            result_b = self.search_system_b(query)
            
            # è©•ä¼°
            metrics_a = self.evaluate_result(result_a, test_case)
            metrics_b = self.evaluate_result(result_b, test_case)
            
            self.results_a.append(metrics_a)
            self.results_b.append(metrics_b)
            
            # å¯¦æ™‚å°æ¯”
            self.print_comparison(metrics_a, metrics_b)
        
        # ç¸½é«”çµ±è¨ˆ
        self.print_summary()
    
    def evaluate_result(self, result, test_case):
        """è©•ä¼°å–®å€‹æœå°‹çµæœ"""
        
        # 1. ç²¾æº–åº¦
        precision = self.calculate_precision(result, test_case)
        
        # 2. å¬å›ç‡
        recall = self.calculate_recall(result, test_case)
        
        # 3. F1 åˆ†æ•¸
        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0
        
        # 4. å¹³å‡ç›¸ä¼¼åº¦
        avg_similarity = np.mean([r['similarity_score'] for r in result['results']])
        
        # 5. å…§å®¹é•·åº¦
        total_length = sum([len(r['content']) for r in result['results']])
        
        # 6. éŸ¿æ‡‰æ™‚é–“
        response_time = result['response_time_ms']
        
        return {
            'precision': precision,
            'recall': recall,
            'f1': f1,
            'avg_similarity': avg_similarity,
            'total_content_length': total_length,
            'response_time_ms': response_time
        }
    
    def calculate_precision(self, result, test_case):
        """è¨ˆç®—ç²¾æº–åº¦"""
        relevant_count = 0
        
        for r in result['results']:
            # æª¢æŸ¥çµæœæ˜¯å¦åœ¨æ¨™è¨»çš„ç›¸é—œæ®µè½ä¸­
            if self.is_relevant(r, test_case['relevant_sections']):
                relevant_count += 1
        
        return relevant_count / len(result['results']) if result['results'] else 0
    
    def calculate_recall(self, result, test_case):
        """è¨ˆç®—å¬å›ç‡"""
        found_relevant = set()
        
        for r in result['results']:
            for rel_section in test_case['relevant_sections']:
                if self.matches(r, rel_section):
                    found_relevant.add(rel_section['section_id'])
        
        total_relevant = len(test_case['relevant_sections'])
        
        return len(found_relevant) / total_relevant if total_relevant > 0 else 0
    
    def print_summary(self):
        """æ‰“å°ç¸½é«”çµ±è¨ˆ"""
        
        print("\n" + "=" * 80)
        print("ğŸ“Š A/B æ¸¬è©¦ç¸½é«”çµæœ")
        print("=" * 80)
        
        metrics_names = ['precision', 'recall', 'f1', 'avg_similarity', 'response_time_ms']
        
        for metric in metrics_names:
            avg_a = np.mean([r[metric] for r in self.results_a])
            avg_b = np.mean([r[metric] for r in self.results_b])
            
            improvement = (avg_b - avg_a) / avg_a * 100 if avg_a > 0 else 0
            
            print(f"\n{metric.upper()}:")
            print(f"  ç³»çµ± A (æ•´ç¯‡): {avg_a:.3f}")
            print(f"  ç³»çµ± B (æ®µè½): {avg_b:.3f}")
            print(f"  æ”¹å–„: {improvement:+.1f}%")
        
        # å…§å®¹é•·åº¦å°æ¯”
        avg_length_a = np.mean([r['total_content_length'] for r in self.results_a])
        avg_length_b = np.mean([r['total_content_length'] for r in self.results_b])
        reduction = (avg_length_a - avg_length_b) / avg_length_a * 100
        
        print(f"\nå…§å®¹é•·åº¦:")
        print(f"  ç³»çµ± A: {avg_length_a:.0f} å­—")
        print(f"  ç³»çµ± B: {avg_length_b:.0f} å­—")
        print(f"  æ¸›å°‘: {reduction:.1f}%")

# åŸ·è¡Œæ¸¬è©¦
if __name__ == '__main__':
    runner = ABTestRunner()
    runner.run_all_tests()
```

---

### éšæ®µ 4ï¼šåˆ†æçµæœï¼ˆ3-5 å¤©ï¼‰

#### Step 4.1: ç”Ÿæˆå°æ¯”å ±å‘Š
```python
# tests/generate_comparison_report.py

def generate_detailed_report():
    """ç”Ÿæˆè©³ç´°çš„å°æ¯”åˆ†æå ±å‘Š"""
    
    report = {
        'test_date': datetime.now().isoformat(),
        'test_duration': '2 weeks',
        'total_queries': len(TEST_QUERIES),
        
        'system_a': {
            'name': 'æ•´ç¯‡æ–‡æª”å‘é‡åŒ–',
            'metrics': calculate_metrics(results_a)
        },
        
        'system_b': {
            'name': 'çµæ§‹åŒ– Chunking',
            'metrics': calculate_metrics(results_b)
        },
        
        'comparison': {
            'precision_improvement': calculate_improvement('precision'),
            'recall_improvement': calculate_improvement('recall'),
            'f1_improvement': calculate_improvement('f1'),
            'similarity_improvement': calculate_improvement('avg_similarity'),
            'content_reduction': calculate_reduction('total_content_length'),
            'response_time_change': calculate_change('response_time_ms')
        },
        
        'recommendations': generate_recommendations()
    }
    
    # å„²å­˜ç‚º Markdown
    save_as_markdown(report, 'ab_test_results.md')
    
    # å„²å­˜ç‚º JSON
    save_as_json(report, 'ab_test_results.json')
    
    return report
```

#### Step 4.2: è¦–è¦ºåŒ–å°æ¯”
```python
# tests/visualize_results.py

import matplotlib.pyplot as plt
import seaborn as sns

def create_comparison_charts():
    """å‰µå»ºè¦–è¦ºåŒ–å°æ¯”åœ–è¡¨"""
    
    # 1. ç²¾æº–åº¦å°æ¯”ï¼ˆæ¢å½¢åœ–ï¼‰
    fig, axes = plt.subplots(2, 2, figsize=(15, 12))
    
    # åœ–è¡¨ 1: ç²¾æº–åº¦å°æ¯”
    ax1 = axes[0, 0]
    categories = ['ç²¾ç¢ºæŸ¥è©¢', 'ä¸»é¡ŒæŸ¥è©¢', 'è¤‡é›œæŸ¥è©¢', 'æ¨¡ç³ŠæŸ¥è©¢']
    precision_a = [0.70, 0.65, 0.60, 0.55]
    precision_b = [0.95, 0.85, 0.80, 0.75]
    
    x = np.arange(len(categories))
    width = 0.35
    
    ax1.bar(x - width/2, precision_a, width, label='ç³»çµ± A (æ•´ç¯‡)', color='#FF6B6B')
    ax1.bar(x + width/2, precision_b, width, label='ç³»çµ± B (æ®µè½)', color='#4ECDC4')
    
    ax1.set_ylabel('ç²¾æº–åº¦')
    ax1.set_title('ç²¾æº–åº¦å°æ¯”')
    ax1.set_xticks(x)
    ax1.set_xticklabels(categories, rotation=45)
    ax1.legend()
    ax1.grid(axis='y', alpha=0.3)
    
    # åœ–è¡¨ 2: å¬å›ç‡å°æ¯”
    ax2 = axes[0, 1]
    recall_a = [0.65, 0.60, 0.70, 0.50]
    recall_b = [0.85, 0.80, 0.90, 0.70]
    
    ax2.bar(x - width/2, recall_a, width, label='ç³»çµ± A', color='#FF6B6B')
    ax2.bar(x + width/2, recall_b, width, label='ç³»çµ± B', color='#4ECDC4')
    
    ax2.set_ylabel('å¬å›ç‡')
    ax2.set_title('å¬å›ç‡å°æ¯”')
    ax2.set_xticks(x)
    ax2.set_xticklabels(categories, rotation=45)
    ax2.legend()
    ax2.grid(axis='y', alpha=0.3)
    
    # åœ–è¡¨ 3: å…§å®¹é•·åº¦å°æ¯”
    ax3 = axes[1, 0]
    length_a = [600, 800, 1200, 500]
    length_b = [50, 200, 400, 80]
    
    ax3.bar(x - width/2, length_a, width, label='ç³»çµ± A', color='#FF6B6B')
    ax3.bar(x + width/2, length_b, width, label='ç³»çµ± B', color='#4ECDC4')
    
    ax3.set_ylabel('å…§å®¹é•·åº¦ï¼ˆå­—ï¼‰')
    ax3.set_title('è¿”å›å…§å®¹é•·åº¦å°æ¯”')
    ax3.set_xticks(x)
    ax3.set_xticklabels(categories, rotation=45)
    ax3.legend()
    ax3.grid(axis='y', alpha=0.3)
    
    # åœ–è¡¨ 4: éŸ¿æ‡‰æ™‚é–“å°æ¯”
    ax4 = axes[1, 1]
    time_a = [100, 110, 120, 95]
    time_b = [120, 130, 140, 115]
    
    ax4.bar(x - width/2, time_a, width, label='ç³»çµ± A', color='#FF6B6B')
    ax4.bar(x + width/2, time_b, width, label='ç³»çµ± B', color='#4ECDC4')
    
    ax4.set_ylabel('éŸ¿æ‡‰æ™‚é–“ï¼ˆmsï¼‰')
    ax4.set_title('éŸ¿æ‡‰æ™‚é–“å°æ¯”')
    ax4.set_xticks(x)
    ax4.set_xticklabels(categories, rotation=45)
    ax4.legend()
    ax4.grid(axis='y', alpha=0.3)
    
    plt.tight_layout()
    plt.savefig('ab_test_comparison.png', dpi=300, bbox_inches='tight')
    plt.show()

# åŸ·è¡Œ
create_comparison_charts()
```

---

## ğŸ“‹ æ¸¬è©¦åŸ·è¡Œæ¸…å–®

### æº–å‚™éšæ®µ âœ…
- [ ] å‰µå»º `document_section_embeddings` è¡¨
- [ ] å¯¦ç¾ Markdown è§£æå™¨
- [ ] ç‚ºç¾æœ‰æ–‡æª”ç”Ÿæˆæ®µè½å‘é‡
- [ ] é©—è­‰æ®µè½å‘é‡æ­£ç¢ºæ€§
- [ ] å‰µå»º A/B æ¸¬è©¦ API ç«¯é»

### æ¸¬è©¦è³‡æ–™æº–å‚™ âœ…
- [ ] ç·¨å¯« 20-30 å€‹æ¨™æº–æ¸¬è©¦æŸ¥è©¢
- [ ] äººå·¥æ¨™è¨»ç›¸é—œæ®µè½ï¼ˆå»ºç«‹ Ground Truthï¼‰
- [ ] åˆ†é¡æŸ¥è©¢é¡å‹ï¼ˆç²¾ç¢º/ä¸»é¡Œ/è¤‡é›œ/æ¨¡ç³Šï¼‰
- [ ] æº–å‚™æ¸¬è©¦è…³æœ¬

### åŸ·è¡Œæ¸¬è©¦ âœ…
- [ ] é‹è¡Œè‡ªå‹•åŒ–æ¸¬è©¦è…³æœ¬ï¼ˆæ¯å€‹æŸ¥è©¢æ¸¬è©¦ 10 æ¬¡ï¼‰
- [ ] è¨˜éŒ„æ‰€æœ‰æŒ‡æ¨™
- [ ] æ¯é€±æª¢æŸ¥ä¸­æœŸçµæœ
- [ ] æ”¶é›†ç”¨æˆ¶åé¥‹ï¼ˆå¦‚æœæœ‰çœŸå¯¦ç”¨æˆ¶ï¼‰

### åˆ†æçµæœ âœ…
- [ ] è¨ˆç®—å¹³å‡æŒ‡æ¨™
- [ ] ç”Ÿæˆå°æ¯”å ±å‘Š
- [ ] å‰µå»ºè¦–è¦ºåŒ–åœ–è¡¨
- [ ] ç·¨å¯«çµè«–å’Œå»ºè­°

---

## ğŸ¯ æ±ºç­–æ¨™æº–

### å…¨é¢æ¡ç”¨çµæ§‹åŒ– Chunking çš„æ¢ä»¶

**å¿…é ˆæ»¿è¶³ä»¥ä¸‹æ¢ä»¶ä¹‹ä¸€**ï¼š

1. **æ ¸å¿ƒæŒ‡æ¨™å¤§å¹…æå‡**ï¼ˆä»»ä¸€é …é”æ¨™å³å¯æ¡ç”¨ï¼‰
   - ç²¾æº–åº¦æå‡ > 20%
   - å¬å›ç‡æå‡ > 15%
   - F1 åˆ†æ•¸æå‡ > 18%
   - ç”¨æˆ¶æ»¿æ„åº¦æå‡ > 20%

2. **ç”¨æˆ¶é«”é©—è³ªè®Š**ï¼ˆä»»ä¸€é …é”æ¨™å³å¯æ¡ç”¨ï¼‰
   - ç­”æ¡ˆå®šä½æ™‚é–“æ¸›å°‘ > 70%
   - é–±è®€é‡æ¸›å°‘ > 60%
   - é»æ“Šç‡æå‡ > 30%

3. **ç¶œåˆè©•åˆ†**
   ```python
   # åŠ æ¬Šç¶œåˆåˆ†æ•¸
   score = (
       precision_improvement * 0.3 +
       recall_improvement * 0.2 +
       user_satisfaction_improvement * 0.3 +
       content_reduction * 0.2
   )
   
   if score > 20:  # ç¶œåˆæå‡ > 20%
       recommendation = "å¼·çƒˆå»ºè­°æ¡ç”¨"
   elif score > 10:
       recommendation = "å»ºè­°æ¡ç”¨"
   else:
       recommendation = "éœ€è¦é€²ä¸€æ­¥å„ªåŒ–"
   ```

### ä¸æ¡ç”¨çš„æ¢ä»¶

**ä»»ä¸€é …ä¸æ»¿è¶³å³æš«ç·©**ï¼š
- éŸ¿æ‡‰æ™‚é–“å¢åŠ  > 50%
- å„²å­˜ç©ºé–“å¢åŠ  > 1000%ï¼ˆç•¶å‰å¯æ¥å— 400-500%ï¼‰
- å¯¦æ–½æˆæœ¬ > é æœŸï¼ˆ4 é€±ï¼‰
- æ ¸å¿ƒæŒ‡æ¨™ç„¡æ˜é¡¯æå‡ï¼ˆ< 10%ï¼‰

---

## ğŸ“Š é æœŸæ¸¬è©¦çµæœï¼ˆé æ¸¬ï¼‰

åŸºæ–¼ç†è«–åˆ†æï¼Œé æ¸¬çš„ A/B æ¸¬è©¦çµæœï¼š

| æŒ‡æ¨™ | ç³»çµ± A (ç•¶å‰) | ç³»çµ± B (æ®µè½) | æ”¹å–„ | ç‹€æ…‹ |
|------|--------------|--------------|------|------|
| **ç²¾æº–åº¦** | 65-70% | 85-95% | **+25-35%** | âœ… å¤§å¹…æå‡ |
| **å¬å›ç‡** | 60-65% | 80-90% | **+30-40%** | âœ… å¤§å¹…æå‡ |
| **F1 åˆ†æ•¸** | 62-67% | 82-92% | **+30-38%** | âœ… å¤§å¹…æå‡ |
| **å¹³å‡ç›¸ä¼¼åº¦** | 0.70-0.75 | 0.80-0.90 | **+14-20%** | âœ… æå‡ |
| **å…§å®¹é•·åº¦** | 800 å­— | 150 å­— | **-81%** | âœ… å¤§å¹…æ¸›å°‘ |
| **éŸ¿æ‡‰æ™‚é–“** | 100ms | 120ms | **+20%** | âš ï¸ ç•¥å¢ï¼ˆå¯æ¥å—ï¼‰ |
| **ç”¨æˆ¶æ»¿æ„åº¦** | 75% | 92% | **+23%** | âœ… å¤§å¹…æå‡ |

**çµè«–é æ¸¬**ï¼š**å¼·çƒˆå»ºè­°æ¡ç”¨çµæ§‹åŒ– Chunking**

---

## ğŸ”„ æŒçºŒç›£æ§è¨ˆåŠƒ

### ä¸Šç·šå¾Œç›£æ§ï¼ˆå‰ 3 å€‹æœˆï¼‰

```python
# monitoring/chunking_metrics.py

class ChunkingMonitor:
    """çµæ§‹åŒ– Chunking æ•ˆæœæŒçºŒç›£æ§"""
    
    def daily_report(self):
        """æ¯æ—¥å ±å‘Š"""
        metrics = {
            'date': datetime.now().date(),
            'total_queries': count_queries_today(),
            'avg_precision': calculate_avg_precision(),
            'avg_response_time': calculate_avg_response_time(),
            'user_satisfaction': calculate_user_satisfaction(),
            'error_rate': calculate_error_rate()
        }
        
        # æª¢æŸ¥ç•°å¸¸
        if metrics['error_rate'] > 5%:
            send_alert("æ®µè½æœå°‹éŒ¯èª¤ç‡éé«˜ï¼")
        
        if metrics['avg_response_time'] > 200:
            send_alert("éŸ¿æ‡‰æ™‚é–“éé•·ï¼")
        
        return metrics
    
    def weekly_comparison(self):
        """æ¯é€±å°æ¯”ï¼ˆvs ä¸Šç·šå‰ï¼‰"""
        baseline = load_baseline_metrics()
        current = calculate_current_metrics()
        
        comparison = {
            'precision_change': current['precision'] - baseline['precision'],
            'user_satisfaction_change': current['satisfaction'] - baseline['satisfaction'],
            # ...
        }
        
        return comparison
```

---

## ğŸ“ ç¸½çµ

### æ¸¬è©¦æµç¨‹ç¸½è¦½

```
Week 1-1.5: æº–å‚™ç’°å¢ƒå’Œæ¸¬è©¦è³‡æ–™
    â†“
Week 2-3: åŸ·è¡Œæ¸¬è©¦ï¼Œæ”¶é›†æ•¸æ“š
    â†“
Week 3-4: åˆ†æçµæœï¼Œç”Ÿæˆå ±å‘Š
    â†“
æ±ºç­–ï¼šæ¡ç”¨ or æš«ç·© or å„ªåŒ–å¾Œå†æ¸¬
    â†“
(å¦‚æœæ¡ç”¨) Week 5-6: å…¨é¢å¯¦æ–½
    â†“
æŒçºŒç›£æ§ 3 å€‹æœˆ
```

### é—œéµå„ªå‹¢

1. **æ•¸æ“šé©…å‹•**ï¼šåŸºæ–¼å¯¦éš›æ¸¬è©¦æ•¸æ“šï¼Œè€Œéä¸»è§€åˆ¤æ–·
2. **é¢¨éšªå¯æ§**ï¼šä¸¦è¡Œæ¸¬è©¦ï¼Œä¸å½±éŸ¿ç¾æœ‰ç³»çµ±
3. **å¯é‡åŒ–**ï¼šæ‰€æœ‰æŒ‡æ¨™éƒ½å¯ç²¾ç¢ºæ¸¬é‡
4. **å¯è¿½æº¯**ï¼šå®Œæ•´è¨˜éŒ„æ¸¬è©¦éç¨‹å’Œçµæœ

### ä¸‹ä¸€æ­¥è¡Œå‹•

**ç«‹å³å¯åš**ï¼š
1. âœ… å‰µå»º `document_section_embeddings` è¡¨
2. âœ… ç‚º 5 ç¯‡ Protocol Guide ç”Ÿæˆæ®µè½å‘é‡
3. âœ… æº–å‚™ 20 å€‹æ¸¬è©¦æŸ¥è©¢
4. âœ… é‹è¡Œç¬¬ä¸€è¼ªæ¸¬è©¦

**éœ€è¦æ‚¨æ±ºç­–çš„**ï¼š
- æ˜¯å¦é–‹å§‹æº–å‚™æ¸¬è©¦ç’°å¢ƒï¼Ÿ
- æ¸¬è©¦é€±æœŸè¨­å®šç‚º 2 é€±é‚„æ˜¯ 4 é€±ï¼Ÿ
- æ˜¯å¦éœ€è¦é‚€è«‹çœŸå¯¦ç”¨æˆ¶åƒèˆ‡æ¸¬è©¦ï¼Ÿ

---

**å ±å‘Šç”Ÿæˆæ—¥æœŸ**: 2025-10-19  
**ç‰ˆæœ¬**: v1.0  
**ç‹€æ…‹**: ğŸ“‹ æ¸¬è©¦è¨ˆåŠƒå·²å®Œæˆï¼Œå¾…åŸ·è¡Œ
