# ğŸš€ å‘é‡æœå°‹ç³»çµ±å¢å¼·åŠŸèƒ½åˆ†æå ±å‘Š

## ğŸ“‹ åŸ·è¡Œæ¦‚è¦

**åˆ†ææ—¥æœŸ**: 2025-10-19  
**ç•¶å‰ç³»çµ±ç‰ˆæœ¬**: v1.0 (1024ç¶­å‘é‡)  
**åˆ†æç¯„åœ**: å‘é‡æœå°‹æ©Ÿåˆ¶çš„åŠŸèƒ½å¢å¼·æ–¹å‘  
**ç›®æ¨™**: åœ¨ä¸ä¿®æ”¹ç¾æœ‰ä»£ç¢¼çš„å‰æä¸‹ï¼Œæä¾›ç³»çµ±å„ªåŒ–å’ŒåŠŸèƒ½æ“´å±•å»ºè­°

---

## ğŸ¯ ç¾æ³åˆ†æ

### å·²å¯¦ç¾åŠŸèƒ½

#### 1. **æ ¸å¿ƒå‘é‡ç³»çµ±** âœ…
- **Embedding æ¨¡å‹**: `intfloat/multilingual-e5-large` (1024ç¶­)
- **å‘é‡è¡¨**: `document_embeddings` (çµ±ä¸€è¡¨ï¼Œæ”¯æ´å¤šçŸ¥è­˜æº)
- **ç´¢å¼•**: IVFFlat é¤˜å¼¦ç›¸ä¼¼åº¦ç´¢å¼•
- **è‡ªå‹•ç”Ÿæˆ**: é€é `VectorManagementMixin` è‡ªå‹•ç”Ÿæˆ/æ›´æ–°/åˆªé™¤å‘é‡

#### 2. **æœå°‹åŠŸèƒ½** âœ…
- **åŸºç¤èªç¾©æœå°‹**: `search_similar_documents()`
- **ç›¸ä¼¼åº¦è¨ˆç®—**: é¤˜å¼¦ç›¸ä¼¼åº¦ (Cosine Similarity)
- **é–¾å€¼éæ¿¾**: æ”¯æ´ `threshold` åƒæ•¸
- **æ‰¹é‡æŸ¥è©¢**: é¿å… N+1 æŸ¥è©¢å•é¡Œ

#### 3. **çŸ¥è­˜åº«æ•´åˆ** âœ…
- **Protocol Assistant**: âœ… å®Œæ•´å‘é‡æ”¯æ´
- **RVT Assistant**: âœ… å®Œæ•´å‘é‡æ”¯æ´
- **Know Issue**: âœ… å®Œæ•´å‘é‡æ”¯æ´

#### 4. **æ¶æ§‹è¨­è¨ˆ** âœ…
- **çµ±ä¸€æ¥å£**: `search_with_vectors_generic()` é€šç”¨æœå°‹å‡½æ•¸
- **Library åˆ†é›¢**: å„ Assistant æœ‰ç¨ç«‹çš„ VectorService
- **å…§å®¹æ ¼å¼åŒ–**: æ”¯æ´è‡ªå®šç¾© `content_formatter`

---

## ğŸ” åŠŸèƒ½å¢å¼·æ–¹å‘åˆ†æ

### æ–¹å‘ 1: æ··åˆæœå°‹ (Hybrid Search) ğŸŒŸğŸŒŸğŸŒŸğŸŒŸğŸŒŸ

**å„ªå…ˆç´š**: â­â­â­â­â­ (æœ€é«˜)

#### æ¦‚å¿µ
çµåˆ**å‘é‡èªç¾©æœå°‹**å’Œ**é—œéµå­—å…¨æ–‡æœå°‹**ï¼Œæå‡æœå°‹ç²¾æº–åº¦å’Œå¬å›ç‡ã€‚

#### ç‚ºä»€éº¼é‡è¦ï¼Ÿ
1. **å‘é‡æœå°‹**æ“…é•·ç†è§£èªç¾©ï¼Œä½†å°ç²¾ç¢ºé—œéµå­—ä¸æ•æ„Ÿ
2. **é—œéµå­—æœå°‹**æ“…é•·ç²¾ç¢ºåŒ¹é…ï¼Œä½†ä¸ç†è§£èªç¾©
3. **å…©è€…çµåˆ**å¯ä»¥äº’è£œå„ªå‹¢ï¼Œå¤§å¹…æå‡æœå°‹å“è³ª

#### å¯¦ç¾æ¶æ§‹
```python
# library/common/knowledge_base/hybrid_search_service.py

class HybridSearchService:
    """æ··åˆæœå°‹æœå‹™"""
    
    def hybrid_search(
        self,
        query: str,
        model_class: Type[models.Model],
        source_table: str,
        vector_weight: float = 0.7,      # å‘é‡æœå°‹æ¬Šé‡
        keyword_weight: float = 0.3,     # é—œéµå­—æœå°‹æ¬Šé‡
        limit: int = 10
    ) -> List[Dict]:
        """
        æ··åˆæœå°‹ç­–ç•¥
        
        æ­¥é©Ÿï¼š
        1. å‘é‡èªç¾©æœå°‹ â†’ ç²å¾— top_k çµæœåŠåˆ†æ•¸
        2. é—œéµå­—å…¨æ–‡æœå°‹ â†’ ç²å¾— top_k çµæœåŠåˆ†æ•¸
        3. åˆä½µçµæœä¸¦é‡æ–°æ’åº (RRF æˆ–åŠ æ¬Šå¹³å‡)
        4. è¿”å›æœ€çµ‚ top_k
        """
        
        # 1. å‘é‡æœå°‹
        vector_results = self._vector_search(query, source_table, limit=limit*2)
        
        # 2. é—œéµå­—æœå°‹ (PostgreSQL å…¨æ–‡æœå°‹)
        keyword_results = self._keyword_search(query, model_class, limit=limit*2)
        
        # 3. åˆä½µçµæœ (Reciprocal Rank Fusion)
        merged_results = self._merge_results(
            vector_results, 
            keyword_results,
            vector_weight,
            keyword_weight
        )
        
        return merged_results[:limit]
    
    def _keyword_search(self, query, model_class, limit):
        """PostgreSQL å…¨æ–‡æœå°‹"""
        from django.contrib.postgres.search import SearchVector, SearchQuery
        
        search_vector = SearchVector('title', weight='A') + \
                       SearchVector('content', weight='B')
        search_query = SearchQuery(query, config='english')
        
        return model_class.objects.annotate(
            search=search_vector,
            rank=SearchRank(search_vector, search_query)
        ).filter(search=search_query).order_by('-rank')[:limit]
```

#### é æœŸæ•ˆæœ
- **ç²¾æº–åº¦æå‡**: 30-50%
- **å¬å›ç‡æå‡**: 20-40%
- **ç”¨æˆ¶æ»¿æ„åº¦**: é¡¯è‘—æå‡

#### å¯¦ç¾é›£åº¦
- **æŠ€è¡“é›£åº¦**: â­â­â­ (ä¸­ç­‰)
- **é–‹ç™¼æ™‚é–“**: 2-3 å¤©
- **æ¸¬è©¦æ™‚é–“**: 1 å¤©

---

### æ–¹å‘ 2: å¤šæ¨¡æ…‹æœå°‹ (Multi-Modal Search) ğŸŒŸğŸŒŸğŸŒŸğŸŒŸ

**å„ªå…ˆç´š**: â­â­â­â­ (é«˜)

#### æ¦‚å¿µ
æ”¯æ´**åœ–ç‰‡ã€æ–‡å­—ã€ä»£ç¢¼**ç­‰å¤šç¨®æ¨¡æ…‹çš„è¯åˆæœå°‹ã€‚

#### æ‡‰ç”¨å ´æ™¯
1. **Protocol Guide ä¸­çš„æˆªåœ–**ï¼šã€Œæ‰¾å‡ºæ‰€æœ‰åŒ…å«éŒ¯èª¤å½ˆçª—çš„æˆªåœ–ã€
2. **Know Issue ä¸­çš„éŒ¯èª¤ç¢¼**ï¼šã€Œæ‰¾å‡ºé¡ä¼¼çš„éŒ¯èª¤ä»£ç¢¼ã€
3. **RVT Guide ä¸­çš„æµç¨‹åœ–**ï¼šã€Œæ‰¾å‡ºç›¸ä¼¼çš„æ¸¬è©¦æµç¨‹åœ–ã€

#### å¯¦ç¾æ¶æ§‹
```python
# library/common/knowledge_base/multimodal_service.py

class MultiModalSearchService:
    """å¤šæ¨¡æ…‹æœå°‹æœå‹™"""
    
    def __init__(self):
        # æ–‡å­— Embedding
        self.text_model = SentenceTransformer('intfloat/multilingual-e5-large')
        
        # åœ–ç‰‡ Embedding (CLIP æ¨¡å‹)
        self.image_model = SentenceTransformer('clip-ViT-B-32')
        
        # ä»£ç¢¼ Embedding
        self.code_model = SentenceTransformer('microsoft/codebert-base')
    
    def search_with_image(self, image_path: str, limit: int = 5):
        """ä½¿ç”¨åœ–ç‰‡æœå°‹ç›¸ä¼¼å…§å®¹"""
        # 1. å°‡åœ–ç‰‡è½‰æ›ç‚ºå‘é‡
        image_embedding = self.image_model.encode(Image.open(image_path))
        
        # 2. åœ¨å‘é‡è³‡æ–™åº«ä¸­æœå°‹
        # (éœ€è¦é¡å¤–çš„åœ–ç‰‡å‘é‡è¡¨)
        pass
    
    def search_with_code(self, code_snippet: str, limit: int = 5):
        """ä½¿ç”¨ä»£ç¢¼ç‰‡æ®µæœå°‹ç›¸ä¼¼æ¸¬è©¦è…³æœ¬"""
        # 1. å°‡ä»£ç¢¼è½‰æ›ç‚ºå‘é‡
        code_embedding = self.code_model.encode(code_snippet)
        
        # 2. æœå°‹ç›¸ä¼¼çš„æ¸¬è©¦è…³æœ¬
        pass
```

#### è³‡æ–™åº«æ“´å±•éœ€æ±‚
```sql
-- åœ–ç‰‡å‘é‡è¡¨
CREATE TABLE image_embeddings (
    id SERIAL PRIMARY KEY,
    source_table VARCHAR(100),  -- 'protocol_guide', 'rvt_guide'
    source_id INTEGER,
    image_id INTEGER,           -- content_images.id
    image_description TEXT,     -- åœ–ç‰‡æè¿°
    embedding vector(512),      -- CLIP æ¨¡å‹ 512 ç¶­
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- ä»£ç¢¼å‘é‡è¡¨
CREATE TABLE code_embeddings (
    id SERIAL PRIMARY KEY,
    source_table VARCHAR(100),  -- 'know_issue'
    source_id INTEGER,
    code_type VARCHAR(50),      -- 'python', 'javascript', 'shell'
    code_content TEXT,          -- åŸå§‹ä»£ç¢¼
    embedding vector(768),      -- CodeBERT 768 ç¶­
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

#### é æœŸæ•ˆæœ
- **æœå°‹èƒ½åŠ›æ“´å±•**: æ¶µè“‹å¤šç¨®å…§å®¹é¡å‹
- **ç”¨æˆ¶é«”é©—**: ã€Œä»¥åœ–æœåœ–ã€ã€ã€Œä»¥ç¢¼æœç¢¼ã€
- **çŸ¥è­˜ç™¼ç¾**: ç™¼ç¾éš±è—çš„é—œè¯æ€§

#### å¯¦ç¾é›£åº¦
- **æŠ€è¡“é›£åº¦**: â­â­â­â­ (é«˜)
- **é–‹ç™¼æ™‚é–“**: 1-2 é€±
- **æ¸¬è©¦æ™‚é–“**: 1 é€±

---

### æ–¹å‘ 3: å‘é‡ç´¢å¼•å„ªåŒ– ğŸŒŸğŸŒŸğŸŒŸğŸŒŸ

**å„ªå…ˆç´š**: â­â­â­â­ (é«˜)

#### æ¦‚å¿µ
å„ªåŒ–å‘é‡ç´¢å¼•ç®—æ³•ï¼Œæå‡å¤§è¦æ¨¡è³‡æ–™çš„æœå°‹æ•ˆèƒ½ã€‚

#### ç•¶å‰ç‹€æ³
- **ç´¢å¼•é¡å‹**: IVFFlat (lists=100)
- **é©ç”¨è¦æ¨¡**: < 10,000 ç­†è³‡æ–™
- **æŸ¥è©¢é€Ÿåº¦**: è‰¯å¥½ (~50-100ms)

#### å„ªåŒ–æ–¹å‘

##### 3.1 å‹•æ…‹ç´¢å¼•åƒæ•¸èª¿æ•´
```python
# library/common/knowledge_base/vector_index_optimizer.py

class VectorIndexOptimizer:
    """å‘é‡ç´¢å¼•å„ªåŒ–å™¨"""
    
    def optimize_index(self, source_table: str):
        """æ ¹æ“šè³‡æ–™é‡è‡ªå‹•èª¿æ•´ç´¢å¼•åƒæ•¸"""
        
        # 1. ç²å–è³‡æ–™é‡
        count = self._get_vector_count(source_table)
        
        # 2. è¨ˆç®—æœ€ä½³ lists åƒæ•¸
        if count < 1000:
            lists = 100
        elif count < 10000:
            lists = int(np.sqrt(count))
        else:
            lists = int(count / 100)
        
        # 3. é‡å»ºç´¢å¼•
        self._rebuild_index(lists)
        
        logger.info(f"ç´¢å¼•å„ªåŒ–å®Œæˆ: {source_table}, lists={lists}")
```

##### 3.2 å‡ç´šåˆ° HNSW ç´¢å¼•
```sql
-- HNSW (Hierarchical Navigable Small World) 
-- æ¯” IVFFlat æ›´å¿«ï¼Œä½†éœ€è¦æ›´å¤šè¨˜æ†¶é«”

-- åˆªé™¤èˆŠç´¢å¼•
DROP INDEX idx_document_embeddings_vector;

-- å‰µå»º HNSW ç´¢å¼•
CREATE INDEX idx_document_embeddings_vector_hnsw 
    ON document_embeddings 
    USING hnsw (embedding vector_cosine_ops) 
    WITH (m = 16, ef_construction = 64);
```

**å°æ¯”åˆ†æ**ï¼š

| æŒ‡æ¨™ | IVFFlat | HNSW |
|------|---------|------|
| æŸ¥è©¢é€Ÿåº¦ | å¿« | **æ›´å¿«** (2-5x) |
| è¨˜æ†¶é«”ä½¿ç”¨ | ä½ | **é«˜** (2-3x) |
| å»ºç«‹æ™‚é–“ | å¿« | æ…¢ |
| æº–ç¢ºç‡ | 90-95% | **95-99%** |
| é©ç”¨è¦æ¨¡ | < 100è¬ | **< 1000è¬** |

**å»ºè­°**ï¼š
- è³‡æ–™é‡ < 10,000ï¼šä½¿ç”¨ IVFFlatï¼ˆç•¶å‰ï¼‰
- è³‡æ–™é‡ 10,000-100,000ï¼šè€ƒæ…® HNSW
- è³‡æ–™é‡ > 100,000ï¼šå¿…é ˆä½¿ç”¨ HNSW

#### å¯¦ç¾é›£åº¦
- **æŠ€è¡“é›£åº¦**: â­â­ (ä½-ä¸­)
- **é–‹ç™¼æ™‚é–“**: 1-2 å¤©
- **æ¸¬è©¦æ™‚é–“**: 1 å¤©

---

### æ–¹å‘ 4: æ™ºèƒ½é‡æ’åº (Re-Ranking) ğŸŒŸğŸŒŸğŸŒŸğŸŒŸ

**å„ªå…ˆç´š**: â­â­â­â­ (é«˜)

#### æ¦‚å¿µ
åœ¨å‘é‡æœå°‹çµæœçš„åŸºç¤ä¸Šï¼Œä½¿ç”¨æ›´ç²¾ç¢ºçš„æ¨¡å‹é€²è¡ŒäºŒæ¬¡æ’åºã€‚

#### ç‚ºä»€éº¼éœ€è¦ï¼Ÿ
1. **å‘é‡æœå°‹**å¿«ä½†ç²—ç³™ï¼ˆèªç¾©ç›¸ä¼¼åº¦ï¼‰
2. **Re-Ranking æ¨¡å‹**æ…¢ä½†ç²¾ç¢ºï¼ˆçœŸå¯¦ç›¸é—œæ€§ï¼‰
3. **å…©éšæ®µ**ç­–ç•¥å¹³è¡¡é€Ÿåº¦å’Œç²¾æº–åº¦

#### å¯¦ç¾æ¶æ§‹
```python
# library/common/knowledge_base/reranking_service.py

from sentence_transformers import CrossEncoder

class ReRankingService:
    """æ™ºèƒ½é‡æ’åºæœå‹™"""
    
    def __init__(self):
        # Cross-Encoder æ¨¡å‹ï¼ˆæ¯” Bi-Encoder æ›´æº–ç¢ºï¼‰
        self.reranker = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-12-v2')
    
    def rerank_results(
        self,
        query: str,
        candidates: List[Dict],
        top_k: int = 5
    ) -> List[Dict]:
        """
        é‡æ–°æ’åºæœå°‹çµæœ
        
        æ­¥é©Ÿï¼š
        1. å‘é‡æœå°‹ç²å¾— top_50 å€™é¸çµæœ
        2. Re-Ranking æ¨¡å‹å°å€™é¸çµæœæ‰“åˆ†
        3. è¿”å› top_k æœ€ç›¸é—œçµæœ
        """
        
        # æº–å‚™ query-document å°
        pairs = [(query, candidate['content']) for candidate in candidates]
        
        # ä½¿ç”¨ Cross-Encoder è¨ˆç®—ç›¸é—œæ€§åˆ†æ•¸
        scores = self.reranker.predict(pairs)
        
        # é‡æ–°æ’åº
        for i, candidate in enumerate(candidates):
            candidate['rerank_score'] = float(scores[i])
        
        # æŒ‰é‡æ’åºåˆ†æ•¸æ’åº
        candidates.sort(key=lambda x: x['rerank_score'], reverse=True)
        
        return candidates[:top_k]
```

#### ä½¿ç”¨ç¯„ä¾‹
```python
# ä½¿ç”¨æ··åˆç­–ç•¥
def smart_search(query: str):
    # æ­¥é©Ÿ 1: å‘é‡æœå°‹ï¼ˆå¿«é€Ÿï¼Œç²å¾— 50 å€‹å€™é¸ï¼‰
    candidates = vector_search(query, limit=50, threshold=0.3)
    
    # æ­¥é©Ÿ 2: é‡æ’åºï¼ˆç²¾ç¢ºï¼Œé¸å‡ºæœ€ç›¸é—œçš„ 5 å€‹ï¼‰
    final_results = reranking_service.rerank_results(query, candidates, top_k=5)
    
    return final_results
```

#### é æœŸæ•ˆæœ
- **ç²¾æº–åº¦æå‡**: 15-25%
- **NDCG@5 æå‡**: 10-20%
- **æŸ¥è©¢æ™‚é–“å¢åŠ **: +50-100msï¼ˆå¯æ¥å—ï¼‰

#### å¯¦ç¾é›£åº¦
- **æŠ€è¡“é›£åº¦**: â­â­â­ (ä¸­)
- **é–‹ç™¼æ™‚é–“**: 2-3 å¤©
- **æ¸¬è©¦æ™‚é–“**: 1 å¤©

---

### æ–¹å‘ 5: æŸ¥è©¢æ“´å±• (Query Expansion) ğŸŒŸğŸŒŸğŸŒŸ

**å„ªå…ˆç´š**: â­â­â­ (ä¸­)

#### æ¦‚å¿µ
è‡ªå‹•æ“´å±•ç”¨æˆ¶æŸ¥è©¢ï¼ŒåŒ…å«åŒç¾©è©ã€ç›¸é—œè©ï¼Œæå‡å¬å›ç‡ã€‚

#### å¯¦ç¾æ–¹æ³•

##### 5.1 åŸºæ–¼ LLM çš„æŸ¥è©¢æ“´å±•
```python
# library/common/knowledge_base/query_expansion_service.py

class QueryExpansionService:
    """æŸ¥è©¢æ“´å±•æœå‹™"""
    
    def expand_query_with_llm(self, query: str) -> List[str]:
        """ä½¿ç”¨ LLM ç”ŸæˆæŸ¥è©¢è®Šé«”"""
        
        prompt = f"""
        åŸå§‹æŸ¥è©¢: {query}
        
        è«‹ç”Ÿæˆ 3-5 å€‹èªç¾©ç›¸ä¼¼ä½†è¡¨é”ä¸åŒçš„æŸ¥è©¢è®Šé«”ã€‚
        è¦æ±‚ï¼š
        1. ä¿æŒåŸæ„
        2. ä½¿ç”¨ä¸åŒæªè¾­
        3. åŒ…å«åŒç¾©è©
        
        è®Šé«”ï¼š
        """
        
        # èª¿ç”¨ Dify æˆ–æœ¬åœ° LLM
        variants = llm_client.generate(prompt)
        
        return [query] + variants  # åŸæŸ¥è©¢ + è®Šé«”
    
    def expand_query_with_wordnet(self, query: str) -> List[str]:
        """ä½¿ç”¨ WordNet æ·»åŠ åŒç¾©è©"""
        from nltk.corpus import wordnet
        
        expanded_terms = []
        for word in query.split():
            synonyms = wordnet.synsets(word)
            for syn in synonyms[:2]:  # æ¯å€‹è©å– 2 å€‹åŒç¾©è©
                expanded_terms.append(syn.lemmas()[0].name())
        
        return [query] + expanded_terms
```

##### 5.2 åŸºæ–¼æ­·å²æŸ¥è©¢çš„æ“´å±•
```python
def expand_query_from_history(query: str) -> List[str]:
    """åŸºæ–¼ç”¨æˆ¶æ­·å²æŸ¥è©¢æ“´å±•"""
    
    # 1. æŸ¥æ‰¾ç›¸ä¼¼çš„æ­·å²æŸ¥è©¢
    similar_queries = find_similar_historical_queries(query, limit=5)
    
    # 2. åˆä½µç‚ºæŸ¥è©¢è®Šé«”
    return [query] + similar_queries
```

#### æœå°‹æµç¨‹
```python
def search_with_expansion(query: str):
    # 1. æ“´å±•æŸ¥è©¢
    expanded_queries = query_expansion_service.expand_query(query)
    
    # 2. å°æ¯å€‹æŸ¥è©¢è®Šé«”é€²è¡Œæœå°‹
    all_results = []
    for q in expanded_queries:
        results = vector_search(q, limit=10)
        all_results.extend(results)
    
    # 3. å»é‡ä¸¦é‡æ–°æ’åº
    unique_results = deduplicate_and_rerank(all_results)
    
    return unique_results[:5]
```

#### é æœŸæ•ˆæœ
- **å¬å›ç‡æå‡**: 20-30%
- **é•·å°¾æŸ¥è©¢æ”¹å–„**: é¡¯è‘—
- **æŸ¥è©¢æ™‚é–“å¢åŠ **: +100-200ms

#### å¯¦ç¾é›£åº¦
- **æŠ€è¡“é›£åº¦**: â­â­â­ (ä¸­)
- **é–‹ç™¼æ™‚é–“**: 3-5 å¤©
- **æ¸¬è©¦æ™‚é–“**: 2 å¤©

---

### æ–¹å‘ 6: å€‹æ€§åŒ–æœå°‹ (Personalized Search) ğŸŒŸğŸŒŸğŸŒŸ

**å„ªå…ˆç´š**: â­â­â­ (ä¸­)

#### æ¦‚å¿µ
æ ¹æ“šç”¨æˆ¶æ­·å²è¡Œç‚ºã€åå¥½ï¼Œå€‹æ€§åŒ–èª¿æ•´æœå°‹çµæœã€‚

#### å¯¦ç¾æ¶æ§‹
```python
# library/common/knowledge_base/personalized_search_service.py

class PersonalizedSearchService:
    """å€‹æ€§åŒ–æœå°‹æœå‹™"""
    
    def personalized_search(
        self,
        query: str,
        user_id: int,
        limit: int = 5
    ) -> List[Dict]:
        """å€‹æ€§åŒ–æœå°‹"""
        
        # 1. ç²å–ç”¨æˆ¶ç•«åƒ
        user_profile = self._get_user_profile(user_id)
        
        # 2. åŸºç¤å‘é‡æœå°‹
        base_results = vector_search(query, limit=20)
        
        # 3. æ ¹æ“šç”¨æˆ¶åå¥½é‡æ–°æ’åº
        personalized_results = self._rerank_by_user_preference(
            base_results,
            user_profile
        )
        
        return personalized_results[:limit]
    
    def _get_user_profile(self, user_id: int) -> Dict:
        """ç²å–ç”¨æˆ¶ç•«åƒ"""
        
        # å¾ç”¨æˆ¶æ­·å²è¡Œç‚ºä¸­æå–åå¥½
        history = ChatMessage.objects.filter(user_id=user_id).order_by('-created_at')[:100]
        
        profile = {
            'frequently_searched_topics': self._extract_topics(history),
            'preferred_sources': self._extract_sources(history),
            'click_patterns': self._analyze_clicks(user_id),
            'feedback_scores': self._get_feedback_stats(user_id)
        }
        
        return profile
    
    def _rerank_by_user_preference(self, results, profile):
        """æ ¹æ“šç”¨æˆ¶åå¥½é‡æ–°æ’åº"""
        
        for result in results:
            # åŸºç¤åˆ†æ•¸
            score = result['score']
            
            # åå¥½ä¸»é¡ŒåŠ æ¬Š
            if result['topic'] in profile['frequently_searched_topics']:
                score *= 1.2
            
            # åå¥½ä¾†æºåŠ æ¬Š
            if result['source_table'] in profile['preferred_sources']:
                score *= 1.15
            
            result['personalized_score'] = score
        
        # é‡æ–°æ’åº
        results.sort(key=lambda x: x['personalized_score'], reverse=True)
        return results
```

#### ç”¨æˆ¶ç•«åƒè³‡æ–™è¡¨
```sql
CREATE TABLE user_search_profiles (
    user_id INTEGER PRIMARY KEY,
    frequently_searched_topics JSONB,  -- ['protocol', 'rvt', 'qa']
    preferred_sources JSONB,           -- ['protocol_guide', 'rvt_guide']
    search_patterns JSONB,             -- æœå°‹æ¨¡å¼åˆ†æ
    feedback_stats JSONB,              -- åé¥‹çµ±è¨ˆ
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

#### é æœŸæ•ˆæœ
- **ç”¨æˆ¶æ»¿æ„åº¦**: +25-35%
- **é»æ“Šç‡**: +15-25%
- **æŸ¥è©¢æˆåŠŸç‡**: +20-30%

#### å¯¦ç¾é›£åº¦
- **æŠ€è¡“é›£åº¦**: â­â­â­â­ (é«˜)
- **é–‹ç™¼æ™‚é–“**: 1-2 é€±
- **æ¸¬è©¦æ™‚é–“**: 1 é€±

---

### æ–¹å‘ 7: å¿«å–æ©Ÿåˆ¶å„ªåŒ– ğŸŒŸğŸŒŸğŸŒŸ

**å„ªå…ˆç´š**: â­â­â­ (ä¸­)

#### æ¦‚å¿µ
å°å¸¸è¦‹æŸ¥è©¢çµæœé€²è¡Œå¿«å–ï¼Œå¤§å¹…æå‡éŸ¿æ‡‰é€Ÿåº¦ã€‚

#### å¯¦ç¾æ¶æ§‹
```python
# library/common/knowledge_base/search_cache_service.py

import redis
from functools import wraps

class SearchCacheService:
    """æœå°‹å¿«å–æœå‹™"""
    
    def __init__(self):
        self.redis_client = redis.Redis(
            host='localhost',
            port=6379,
            db=0,
            decode_responses=True
        )
        self.cache_ttl = 3600  # 1 å°æ™‚
    
    def cache_search_results(self, func):
        """æœå°‹çµæœå¿«å–è£é£¾å™¨"""
        
        @wraps(func)
        def wrapper(query: str, *args, **kwargs):
            # ç”Ÿæˆå¿«å–éµ
            cache_key = self._generate_cache_key(query, args, kwargs)
            
            # å˜—è©¦å¾å¿«å–ç²å–
            cached_result = self.redis_client.get(cache_key)
            if cached_result:
                logger.info(f"å¿«å–å‘½ä¸­: {query}")
                return json.loads(cached_result)
            
            # åŸ·è¡Œå¯¦éš›æœå°‹
            result = func(query, *args, **kwargs)
            
            # å­˜å…¥å¿«å–
            self.redis_client.setex(
                cache_key,
                self.cache_ttl,
                json.dumps(result)
            )
            
            return result
        
        return wrapper
    
    def invalidate_cache(self, source_table: str, source_id: int):
        """ç•¶è³‡æ–™æ›´æ–°æ™‚ï¼Œæ¸…é™¤ç›¸é—œå¿«å–"""
        
        # æ¸…é™¤æ‰€æœ‰åŒ…å«è©²è³‡æ–™çš„å¿«å–
        pattern = f"search:*:{source_table}:{source_id}:*"
        keys = self.redis_client.keys(pattern)
        
        if keys:
            self.redis_client.delete(*keys)
            logger.info(f"æ¸…é™¤å¿«å–: {len(keys)} å€‹éµ")
```

#### å¿«å–ç­–ç•¥

##### 7.1 æŸ¥è©¢çµæœå¿«å–
```python
@cache_service.cache_search_results
def vector_search(query: str, limit: int = 5):
    # å¯¦éš›æœå°‹é‚è¼¯
    pass
```

##### 7.2 Embedding å¿«å–
```python
class EmbeddingCacheService:
    """Embedding å¿«å–æœå‹™"""
    
    def get_or_generate_embedding(self, text: str) -> List[float]:
        """ç²å–æˆ–ç”Ÿæˆ Embedding"""
        
        # è¨ˆç®—æ–‡æœ¬å“ˆå¸Œ
        text_hash = hashlib.md5(text.encode()).hexdigest()
        cache_key = f"embedding:{text_hash}"
        
        # å˜—è©¦å¾å¿«å–ç²å–
        cached = self.redis_client.get(cache_key)
        if cached:
            return json.loads(cached)
        
        # ç”Ÿæˆæ–°çš„ embedding
        embedding = self.embedding_model.encode(text)
        
        # å­˜å…¥å¿«å–ï¼ˆé•·æœŸï¼‰
        self.redis_client.setex(cache_key, 86400*7, json.dumps(embedding))
        
        return embedding
```

#### å¿«å–å¤±æ•ˆç­–ç•¥
```python
def on_guide_updated(sender, instance, **kwargs):
    """ç•¶ Guide æ›´æ–°æ™‚è§¸ç™¼"""
    
    # æ¸…é™¤è©² Guide ç›¸é—œçš„æ‰€æœ‰å¿«å–
    cache_service.invalidate_cache(
        source_table=instance._meta.db_table,
        source_id=instance.id
    )
```

#### é æœŸæ•ˆæœ
- **æŸ¥è©¢é€Ÿåº¦**: å¿«å–å‘½ä¸­æ™‚ **10-50x æå‡** (å¾ 100ms â†’ 2-10ms)
- **è³‡æ–™åº«è² è¼‰**: -60-80%
- **å¿«å–å‘½ä¸­ç‡**: 40-60% (ç†±é–€æŸ¥è©¢)

#### å¯¦ç¾é›£åº¦
- **æŠ€è¡“é›£åº¦**: â­â­ (ä½-ä¸­)
- **é–‹ç™¼æ™‚é–“**: 2-3 å¤©
- **æ¸¬è©¦æ™‚é–“**: 1 å¤©

---

### æ–¹å‘ 8: å‘é‡å£“ç¸®èˆ‡é‡åŒ– ğŸŒŸğŸŒŸ

**å„ªå…ˆç´š**: â­â­ (ä½)

#### æ¦‚å¿µ
å£“ç¸®å‘é‡ç¶­åº¦ï¼Œæ¸›å°‘å„²å­˜ç©ºé–“å’Œè¨ˆç®—æˆæœ¬ï¼Œé©åˆå¤§è¦æ¨¡éƒ¨ç½²ã€‚

#### å¯¦ç¾æ–¹æ³•

##### 8.1 é™ç¶­æŠ€è¡“ (PCA/t-SNE)
```python
from sklearn.decomposition import PCA

class VectorCompressionService:
    """å‘é‡å£“ç¸®æœå‹™"""
    
    def __init__(self, target_dim: int = 512):
        self.target_dim = target_dim
        self.pca = PCA(n_components=target_dim)
    
    def train_compression(self, embeddings: List[List[float]]):
        """è¨“ç·´å£“ç¸®æ¨¡å‹"""
        self.pca.fit(embeddings)
    
    def compress_vector(self, embedding: List[float]) -> List[float]:
        """å£“ç¸®å–®å€‹å‘é‡ (1024 â†’ 512)"""
        return self.pca.transform([embedding])[0].tolist()
```

##### 8.2 é‡åŒ–æŠ€è¡“ (Quantization)
```python
def quantize_vector(embedding: List[float], bits: int = 8) -> bytes:
    """
    å°‡ float32 å‘é‡é‡åŒ–ç‚º int8
    
    å„²å­˜ç©ºé–“: 4096 bytes â†’ 1024 bytes (75% æ¸›å°‘)
    ç²¾æº–åº¦æå¤±: < 2%
    """
    
    # æ­£è¦åŒ–åˆ° [0, 255]
    min_val = min(embedding)
    max_val = max(embedding)
    
    quantized = [
        int((val - min_val) / (max_val - min_val) * 255)
        for val in embedding
    ]
    
    return bytes(quantized)
```

#### é æœŸæ•ˆæœ
- **å„²å­˜ç©ºé–“**: -50-75%
- **æŸ¥è©¢é€Ÿåº¦**: +10-30%
- **ç²¾æº–åº¦æå¤±**: 2-5%

#### å¯¦ç¾é›£åº¦
- **æŠ€è¡“é›£åº¦**: â­â­â­â­ (é«˜)
- **é–‹ç™¼æ™‚é–“**: 1 é€±
- **æ¸¬è©¦æ™‚é–“**: 1 é€±

---

## ğŸ“Š åŠŸèƒ½å„ªå…ˆç´šç¸½çµ

### çŸ­æœŸå„ªåŒ–ï¼ˆ1-2 é€±ï¼‰âš¡

| åŠŸèƒ½ | å„ªå…ˆç´š | é–‹ç™¼æ™‚é–“ | é æœŸæ•ˆæœ | ROI |
|------|--------|----------|----------|-----|
| **æ··åˆæœå°‹** | â­â­â­â­â­ | 2-3 å¤© | ç²¾æº–åº¦ +30-50% | ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ |
| **æ™ºèƒ½é‡æ’åº** | â­â­â­â­ | 2-3 å¤© | ç²¾æº–åº¦ +15-25% | ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ |
| **å¿«å–æ©Ÿåˆ¶** | â­â­â­ | 2-3 å¤© | é€Ÿåº¦ +10-50x | ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ |
| **ç´¢å¼•å„ªåŒ–** | â­â­â­â­ | 1-2 å¤© | å¤§è¦æ¨¡æ•ˆèƒ½æå‡ | ğŸ”¥ğŸ”¥ğŸ”¥ |

**å»ºè­°é †åº**: æ··åˆæœå°‹ â†’ å¿«å–æ©Ÿåˆ¶ â†’ æ™ºèƒ½é‡æ’åº â†’ ç´¢å¼•å„ªåŒ–

### ä¸­æœŸè¦åŠƒï¼ˆ1-2 å€‹æœˆï¼‰ğŸ“ˆ

| åŠŸèƒ½ | å„ªå…ˆç´š | é–‹ç™¼æ™‚é–“ | é æœŸæ•ˆæœ | ROI |
|------|--------|----------|----------|-----|
| **å¤šæ¨¡æ…‹æœå°‹** | â­â­â­â­ | 1-2 é€± | åŠŸèƒ½æ“´å±• | ğŸ”¥ğŸ”¥ğŸ”¥ |
| **æŸ¥è©¢æ“´å±•** | â­â­â­ | 3-5 å¤© | å¬å›ç‡ +20-30% | ğŸ”¥ğŸ”¥ğŸ”¥ |
| **å€‹æ€§åŒ–æœå°‹** | â­â­â­ | 1-2 é€± | ç”¨æˆ¶é«”é©— +25-35% | ğŸ”¥ğŸ”¥ğŸ”¥ |

**å»ºè­°é †åº**: å¤šæ¨¡æ…‹æœå°‹ â†’ å€‹æ€§åŒ–æœå°‹ â†’ æŸ¥è©¢æ“´å±•

### é•·æœŸå„ªåŒ–ï¼ˆ3-6 å€‹æœˆï¼‰ğŸš€

| åŠŸèƒ½ | å„ªå…ˆç´š | é–‹ç™¼æ™‚é–“ | é æœŸæ•ˆæœ | ROI |
|------|--------|----------|----------|-----|
| **å‘é‡å£“ç¸®** | â­â­ | 1 é€± | å„²å­˜ -50-75% | ğŸ”¥ğŸ”¥ |

---

## ğŸ¯ æ¨è–¦å¯¦æ–½è·¯ç·šåœ–

### ç¬¬ä¸€éšæ®µï¼šåŸºç¤å¢å¼·ï¼ˆ1-2 é€±ï¼‰
```
Week 1:
  Day 1-3: å¯¦ç¾æ··åˆæœå°‹
  Day 4-5: å¯¦ç¾å¿«å–æ©Ÿåˆ¶
  
Week 2:
  Day 1-3: å¯¦ç¾æ™ºèƒ½é‡æ’åº
  Day 4-5: ç´¢å¼•å„ªåŒ–å’Œæ•ˆèƒ½æ¸¬è©¦
```

**ç›®æ¨™**ï¼š
- âœ… æœå°‹ç²¾æº–åº¦æå‡ 40-60%
- âœ… æœå°‹é€Ÿåº¦æå‡ 5-10x
- âœ… ç”¨æˆ¶æ»¿æ„åº¦é¡¯è‘—æå‡

### ç¬¬äºŒéšæ®µï¼šåŠŸèƒ½æ“´å±•ï¼ˆ3-4 é€±ï¼‰
```
Week 3-4:
  å¯¦ç¾å¤šæ¨¡æ…‹æœå°‹ï¼ˆåœ–ç‰‡ã€ä»£ç¢¼ï¼‰
  
Week 5:
  å¯¦ç¾æŸ¥è©¢æ“´å±•
  
Week 6:
  å€‹æ€§åŒ–æœå°‹æ¡†æ¶æ­å»º
```

**ç›®æ¨™**ï¼š
- âœ… æ”¯æ´å¤šç¨®æœå°‹æ¨¡å¼
- âœ… å¬å›ç‡æå‡ 30-40%
- âœ… å€‹æ€§åŒ–æ¨è–¦ä¸Šç·š

### ç¬¬ä¸‰éšæ®µï¼šæ·±åº¦å„ªåŒ–ï¼ˆ5-8 é€±ï¼‰
```
Week 7-8:
  å®Œå–„å€‹æ€§åŒ–æœå°‹
  ç”¨æˆ¶ç•«åƒç³»çµ±
  
Week 9-10:
  å‘é‡å£“ç¸®å¯¦é©—
  å¤§è¦æ¨¡æ•ˆèƒ½å„ªåŒ–
```

---

## ğŸ’¡ å…·é«”å¯¦æ–½å»ºè­°

### 1. æ··åˆæœå°‹ - è©³ç´°å¯¦æ–½è¨ˆåŠƒ

#### æ­¥é©Ÿ 1: æº–å‚™ PostgreSQL å…¨æ–‡æœå°‹
```sql
-- ç‚ºæ¯å€‹çŸ¥è­˜åº«è¡¨æ·»åŠ å…¨æ–‡æœå°‹æ¬„ä½
ALTER TABLE protocol_guide 
ADD COLUMN search_vector tsvector;

-- å‰µå»ºå…¨æ–‡æœå°‹ç´¢å¼•
CREATE INDEX idx_protocol_guide_search 
ON protocol_guide 
USING GIN(search_vector);

-- å‰µå»ºæ›´æ–°è§¸ç™¼å™¨
CREATE TRIGGER protocol_guide_search_update 
BEFORE INSERT OR UPDATE ON protocol_guide
FOR EACH ROW EXECUTE FUNCTION
tsvector_update_trigger(search_vector, 'pg_catalog.english', title, content);
```

#### æ­¥é©Ÿ 2: å¯¦ç¾æ··åˆæœå°‹æœå‹™
```python
# library/common/knowledge_base/hybrid_search_service.py
# (å®Œæ•´ä»£ç¢¼è¦‹ä¸Šæ–¹)
```

#### æ­¥é©Ÿ 3: API æ•´åˆ
```python
# backend/api/views/viewsets/knowledge_viewsets.py

@action(detail=False, methods=['post'])
def hybrid_search(self, request):
    """æ··åˆæœå°‹ API"""
    query = request.data.get('query', '')
    
    # ä½¿ç”¨æ··åˆæœå°‹
    results = hybrid_search_service.hybrid_search(
        query=query,
        model_class=ProtocolGuide,
        source_table='protocol_guide',
        limit=10
    )
    
    return Response({
        'results': results,
        'search_type': 'hybrid'
    })
```

#### æ­¥é©Ÿ 4: å‰ç«¯æ•´åˆ
```javascript
// frontend/src/hooks/useHybridSearch.js

export const useHybridSearch = () => {
  const search = async (query) => {
    const response = await api.post('/api/protocol-guides/hybrid_search/', {
      query: query
    });
    
    return response.data.results;
  };
  
  return { search };
};
```

### 2. å¿«å–æ©Ÿåˆ¶ - è©³ç´°å¯¦æ–½è¨ˆåŠƒ

#### æ­¥é©Ÿ 1: å®‰è£ Redis
```bash
# docker-compose.yml
services:
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
```

#### æ­¥é©Ÿ 2: å¯¦ç¾å¿«å–æœå‹™
```python
# (å®Œæ•´ä»£ç¢¼è¦‹ä¸Šæ–¹)
```

#### æ­¥é©Ÿ 3: æ•´åˆåˆ°ç¾æœ‰æœå°‹
```python
# ä¿®æ”¹ç¾æœ‰çš„æœå°‹å‡½æ•¸
@cache_service.cache_search_results
def search_with_vectors_generic(query, model_class, source_table, ...):
    # åŸæœ‰é‚è¼¯
    pass
```

---

## ğŸ“ˆ é æœŸæ•ˆæœå°æ¯”

### ç•¶å‰ç³»çµ± vs å®Œæ•´å„ªåŒ–å¾Œ

| æŒ‡æ¨™ | ç•¶å‰ | æ··åˆæœå°‹ | å®Œæ•´å„ªåŒ– | æå‡å¹…åº¦ |
|------|------|----------|----------|----------|
| **ç²¾æº–åº¦** | 70% | 85-90% | 90-95% | +25-35% |
| **å¬å›ç‡** | 65% | 75-80% | 85-90% | +30-40% |
| **æŸ¥è©¢é€Ÿåº¦** | 100ms | 150ms | 10-20ms* | å¿«å–ä¸‹ 10x |
| **ç”¨æˆ¶æ»¿æ„åº¦** | 75% | 85% | 92% | +17% |
| **é»æ“Šç‡** | 60% | 70% | 80% | +33% |

*å¿«å–å‘½ä¸­æƒ…æ³ä¸‹

---

## ğŸ”¬ A/B æ¸¬è©¦å»ºè­°

### æ¸¬è©¦æ–¹æ¡ˆ
1. **å°ç…§çµ„**: ç•¶å‰å‘é‡æœå°‹ï¼ˆ30% ç”¨æˆ¶ï¼‰
2. **å¯¦é©—çµ„ A**: æ··åˆæœå°‹ï¼ˆ30% ç”¨æˆ¶ï¼‰
3. **å¯¦é©—çµ„ B**: æ··åˆæœå°‹ + é‡æ’åºï¼ˆ40% ç”¨æˆ¶ï¼‰

### è©•ä¼°æŒ‡æ¨™
- **CTR** (é»æ“Šç‡): ç”¨æˆ¶é»æ“Šæœå°‹çµæœçš„æ¯”ä¾‹
- **Session Success Rate**: ç”¨æˆ¶æ‰¾åˆ°ç­”æ¡ˆçš„æ¯”ä¾‹
- **Average Response Time**: å¹³å‡éŸ¿æ‡‰æ™‚é–“
- **User Feedback Score**: ç”¨æˆ¶åé¥‹åˆ†æ•¸ï¼ˆé»è®š/é»è¸©ï¼‰

### æ¸¬è©¦æ™‚é•·
- **æœ€çŸ­**: 2 é€±ï¼ˆæ”¶é›†è¶³å¤ æ•¸æ“šï¼‰
- **å»ºè­°**: 4 é€±ï¼ˆè§€å¯Ÿé•·æœŸæ•ˆæœï¼‰

---

## ğŸ› ï¸ é–‹ç™¼è³‡æºéœ€æ±‚

### äººåŠ›éœ€æ±‚
- **å¾Œç«¯é–‹ç™¼**: 1-2 äºº
- **è³‡æ–™åº«å·¥ç¨‹å¸«**: 0.5 äººï¼ˆç´¢å¼•å„ªåŒ–ï¼‰
- **æ¸¬è©¦å·¥ç¨‹å¸«**: 0.5 äºº
- **ç¸½è¨ˆ**: 2-3 äººé€±

### åŸºç¤è¨­æ–½éœ€æ±‚
- **Redis**: 2-4 GB RAM
- **PostgreSQL**: ç¾æœ‰è³‡æºè¶³å¤ 
- **æ¨¡å‹æª”æ¡ˆ**: +500 MB (Re-Ranking æ¨¡å‹)

---

## ğŸ“š åƒè€ƒè³‡æº

### å­¸è¡“è«–æ–‡
1. **Hybrid Search**: "Combining Sparse and Dense Retrieval" (2021)
2. **Re-Ranking**: "Cross-Encoder for Text Matching" (2020)
3. **Query Expansion**: "Neural Query Expansion" (2022)

### é–‹æºå°ˆæ¡ˆ
- **Haystack**: æ··åˆæœå°‹æ¡†æ¶
- **Milvus**: å‘é‡è³‡æ–™åº«
- **Weaviate**: å¤šæ¨¡æ…‹æœå°‹å¼•æ“

### æŠ€è¡“æ–‡æª”
- **pgvector å®˜æ–¹æ–‡æª”**: https://github.com/pgvector/pgvector
- **Sentence Transformers**: https://www.sbert.net/
- **PostgreSQL å…¨æ–‡æœå°‹**: https://www.postgresql.org/docs/current/textsearch.html

---

## ğŸ¬ çµè«–

### æ ¸å¿ƒå»ºè­°
1. **ç«‹å³å¯¦æ–½**: æ··åˆæœå°‹ï¼ˆæœ€é«˜ ROIï¼‰
2. **çŸ­æœŸå„ªåŒ–**: å¿«å–æ©Ÿåˆ¶ï¼ˆæ€§èƒ½å€å¢ï¼‰
3. **ä¸­æœŸè¦åŠƒ**: å¤šæ¨¡æ…‹æœå°‹ï¼ˆåŠŸèƒ½æ“´å±•ï¼‰
4. **é•·æœŸç›®æ¨™**: å€‹æ€§åŒ–æœå°‹ï¼ˆç”¨æˆ¶é«”é©—ï¼‰

### æŠ•å…¥ç”¢å‡ºæ¯”
- **æ··åˆæœå°‹**: æŠ•å…¥ 2-3 å¤©ï¼Œç²¾æº–åº¦ +30-50% ğŸ†
- **å¿«å–æ©Ÿåˆ¶**: æŠ•å…¥ 2-3 å¤©ï¼Œé€Ÿåº¦ +10-50x ğŸ†
- **æ™ºèƒ½é‡æ’åº**: æŠ•å…¥ 2-3 å¤©ï¼Œç²¾æº–åº¦ +15-25% â­
- **å¤šæ¨¡æ…‹æœå°‹**: æŠ•å…¥ 1-2 é€±ï¼ŒåŠŸèƒ½è³ªè®Š â­

### æœ€çµ‚ç›®æ¨™
**å»ºç«‹æ¥­ç•Œé ˜å…ˆçš„ AI çŸ¥è­˜åº«æœå°‹ç³»çµ±**ï¼Œç‚ºç”¨æˆ¶æä¾›ï¼š
- ğŸ¯ ç²¾æº–çš„æœå°‹çµæœ
- âš¡ æ¥µå¿«çš„éŸ¿æ‡‰é€Ÿåº¦
- ğŸ¤– æ™ºèƒ½çš„å…§å®¹æ¨è–¦
- ğŸ¨ è±å¯Œçš„æœå°‹æ¨¡å¼

---

**å ±å‘Šç”Ÿæˆæ—¥æœŸ**: 2025-10-19  
**åˆ†æè€…**: AI Platform Team  
**ç‰ˆæœ¬**: v1.0  
**ç‹€æ…‹**: ğŸ“Š å®Œæ•´åˆ†æï¼Œå¾…æ±ºç­–
