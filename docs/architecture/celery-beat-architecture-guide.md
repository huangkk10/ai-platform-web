# ğŸ”„ Celery Beat å®šæ™‚ä»»å‹™æ¶æ§‹æŒ‡å—

## ğŸ“‹ **æ¦‚è¿°**
æœ¬æ–‡æª”è©³ç´°èªªæ˜ AI Platform ä¸­ Celery Beat å®šæ™‚ä»»å‹™ç³»çµ±çš„å®Œæ•´æ¶æ§‹ã€åŸ·è¡ŒåŸç†å’Œç›£æ§æ–¹å¼ã€‚

**æœ€å¾Œæ›´æ–°**: 2025-10-09  
**é©ç”¨ç‰ˆæœ¬**: AI Platform v2.1+  
**ç¶­è­·åœ˜éšŠ**: AI Platform Development Team

---

## ğŸ—ï¸ **ç³»çµ±æ¶æ§‹æ¦‚è¦½**

### ğŸ“Š **å®¹å™¨åŒ–åˆ†é›¢æ¶æ§‹**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    AI Platform Celery æ¶æ§‹                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  ğŸ“… ai-celery-beat      ğŸ“® ai-redis        ğŸƒ ai-celery-worker  â”‚
â”‚     (æ’ç¨‹å™¨)              (æ¶ˆæ¯ä½‡åˆ—)           (åŸ·è¡Œå™¨)          â”‚
â”‚                                                                 â”‚
â”‚  â° ç›£æ§æ™‚é–“è¡¨           ğŸ“‹ ä»»å‹™ä½‡åˆ—          âš¡ åŸ·è¡Œå¯¦éš›å·¥ä½œ     â”‚
â”‚  ğŸ“¤ ç”¢ç”Ÿå®šæ™‚ä»»å‹™         ğŸ’¾ çµæœå­˜å„²          ğŸ“Š è™•ç†æ¥­å‹™é‚è¼¯     â”‚
â”‚  ğŸ¯ crontab è§£æ        ğŸ”„ æ¶ˆæ¯å‚³é          ğŸ¤– AI/ML ä»»å‹™      â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   ğŸ“Š postgres_db     â”‚
                    â”‚   (é…ç½®å­˜å„²)         â”‚
                    â”‚                     â”‚
                    â”‚  ğŸ“‹ æ’ç¨‹é…ç½®         â”‚
                    â”‚  ğŸ“ˆ åŸ·è¡Œè¨˜éŒ„         â”‚
                    â”‚  ğŸ“Š çµ±è¨ˆè³‡æ–™         â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## âš™ï¸ **Celery Beat åŸ·è¡ŒåŸç†**

### ğŸ”„ **å·¥ä½œæµç¨‹è©³è§£**

```mermaid
sequenceDiagram
    participant CB as Celery Beat
    participant PG as PostgreSQL
    participant RD as Redis
    participant CW as Celery Worker
    participant LIB as Library Tasks

    CB->>PG: 1. è®€å–æ’ç¨‹é…ç½®
    CB->>CB: 2. æª¢æŸ¥ä»»å‹™æ˜¯å¦åˆ°æœŸ
    CB->>RD: 3. æ¨é€åˆ°æœŸä»»å‹™è‡³ä½‡åˆ—
    CW->>RD: 4. å¾ä½‡åˆ—å–å‡ºä»»å‹™
    CW->>LIB: 5. åŸ·è¡Œä»»å‹™å‡½æ•¸
    LIB->>PG: 6. è™•ç†æ¥­å‹™é‚è¼¯
    LIB->>CW: 7. å›å‚³åŸ·è¡Œçµæœ
    CW->>RD: 8. å­˜å„²åŸ·è¡Œçµæœ
```

### ğŸ“‹ **æ ¸å¿ƒçµ„ä»¶èªªæ˜**

#### **1. Celery Beat (ai-celery-beat)**
```yaml
container_name: ai-celery-beat
command: celery -A ai_platform beat --loglevel=info --scheduler django_celery_beat.schedulers:DatabaseScheduler
```

**è·è²¬**:
- ğŸ• æ¯ç§’æª¢æŸ¥æ’ç¨‹é…ç½®
- ğŸ“… è§£æ crontab è¡¨é”å¼
- ğŸ¯ è­˜åˆ¥åˆ°æœŸä»»å‹™
- ğŸ“¤ æ¨é€ä»»å‹™åˆ° Redis ä½‡åˆ—
- ğŸ“Š è¨˜éŒ„åŸ·è¡Œç‹€æ…‹

**é…ç½®ç‰¹é»**:
- ä½¿ç”¨ **DatabaseScheduler** (è€Œéæ–‡ä»¶æ’ç¨‹å™¨)
- æ”¯æ´å‹•æ…‹é…ç½®æ›´æ–°
- æ™‚å€æ„ŸçŸ¥ (Asia/Taipei)
- æŒä¹…åŒ–æ’ç¨‹ç‹€æ…‹

#### **2. Celery Worker (ai-celery-worker)**
```yaml
container_name: ai-celery-worker  
command: celery -A ai_platform worker --loglevel=info --concurrency=2
```

**è·è²¬**:
- ğŸ”„ ç›£è½ Redis ä»»å‹™ä½‡åˆ—
- âš¡ ä¸¦ç™¼åŸ·è¡Œä»»å‹™ (concurrency=2)
- ğŸ“Š èª¿ç”¨å¯¦éš›æ¥­å‹™é‚è¼¯
- ğŸ’¾ å›å ±åŸ·è¡Œçµæœ
- ğŸš¨ è™•ç†ä»»å‹™ç•°å¸¸

#### **3. Redis æ¶ˆæ¯ä½‡åˆ— (ai-redis)**
```yaml
container_name: ai-redis
command: redis-server --appendonly yes
```

**è·è²¬**:
- ğŸ“® ä»»å‹™æ¶ˆæ¯ä½‡åˆ— (`redis://redis:6379/1`)
- ğŸ’¾ çµæœå­˜å„²å¾Œç«¯ (`redis://redis:6379/2`)
- ğŸ”„ ä»»å‹™ç‹€æ…‹è¿½è¹¤
- âš¡ é«˜æ€§èƒ½æ¶ˆæ¯å‚³é

## ğŸ“… **ç•¶å‰æ’ç¨‹é…ç½®**

### ğŸ• **å®šæ™‚ä»»å‹™æ™‚é–“è¡¨**

| ä»»å‹™åç¨± | åŸ·è¡Œæ™‚é–“ | é »ç‡ | ç›®æ¨™ |
|---------|----------|------|------|
| `process-new-chat-vectors-hourly` | æ¯å°æ™‚ 0 åˆ† | æ¯å°æ™‚ | ğŸ¯ ç”¨æˆ¶å•é¡Œå‘é‡åŒ– |
| `process-assistant-vectors-periodic` | æ¯6å°æ™‚ 30 åˆ† | æ¯6å°æ™‚ | ğŸ¤– åŠ©æ‰‹å›è¦†å‘é‡åŒ– |
| `update-question-analytics-daily` | æ¯å¤© 3:30 | æ¯æ—¥ | **ğŸ“Š èšé¡åˆ†æ** |
| `preload-vector-services-daily` | æ¯å¤© 3:00 | æ¯æ—¥ | ğŸš€ æœå‹™é è¼‰å…¥ |
| `cleanup-cache-daily` | æ¯å¤© 2:00 | æ¯æ—¥ | ğŸ§¹ å¿«å–æ¸…ç† |

### ğŸ¯ **é—œéµä»»å‹™è©³è§£**

#### **èšé¡åˆ†æä»»å‹™ (3:30 AM)**
```python
'update-question-analytics-daily': {
    'task': 'library.rvt_analytics.tasks.precompute_question_classifications',
    'schedule': crontab(hour=3, minute=30),
    'options': {'expires': 3600}
}
```

**åŸ·è¡Œå…§å®¹**:
1. **å‘é‡èšé¡** - K-means/DBSCAN æ¼”ç®—æ³•
2. **å•é¡Œåˆ†çµ„** - ç›¸ä¼¼å•é¡Œæ­¸é¡  
3. **çµ±è¨ˆæ›´æ–°** - ç†±é–€å•é¡Œæ’å
4. **å¿«å–åˆ·æ–°** - å‰ç«¯é¡¯ç¤ºè³‡æ–™

#### **å‘é‡è™•ç†ä»»å‹™ (æ¯å°æ™‚)**
```python
'process-new-chat-vectors-hourly': {
    'task': 'library.rvt_analytics.tasks.rebuild_chat_vectors',
    'schedule': crontab(minute=0),
    'kwargs': {
        'force_rebuild': False,
        'user_role': 'user',
        'min_length': 5
    }
}
```

**åŸ·è¡Œé‚è¼¯**:
- ğŸ” æƒææœªå‘é‡åŒ–çš„èŠå¤©æ¶ˆæ¯
- ğŸ¯ ç¯©é¸ç”¨æˆ¶å•é¡Œ (æ’é™¤åŠ©æ‰‹å›è¦†)
- ğŸ¤– ç”Ÿæˆ 1024 ç¶­å‘é‡
- ğŸ’¾ å­˜å„²åˆ° `chat_message_embeddings_1024` è¡¨

## ğŸ“Š **ç›£æ§å’Œç®¡ç†**

### ğŸŒ¸ **Celery Flower ç›£æ§ä»‹é¢**

**è¨ªå•**: `http://localhost:5555`

```yaml
celery_flower:
  container_name: ai-celery-flower
  command: celery -A ai_platform flower --port=5555
```

**ç›£æ§å…§å®¹**:
- ğŸ“ˆ ä»»å‹™åŸ·è¡Œçµ±è¨ˆ
- â±ï¸ åŸ·è¡Œæ™‚é–“åˆ†æ
- ğŸ”„ ä½‡åˆ—é•·åº¦ç›£æ§
- ğŸ’» Worker ç‹€æ…‹æª¢æŸ¥
- ğŸš¨ å¤±æ•—ä»»å‹™è¿½è¹¤

### ğŸ“‹ **æ—¥èªŒç›£æ§**

#### **Celery Beat æ—¥èªŒ**
```bash
# æª¢æŸ¥æ’ç¨‹å™¨ç‹€æ…‹
docker logs ai-celery-beat --follow

# æŸ¥çœ‹ç‰¹å®šæ™‚é–“çš„æ—¥èªŒ  
docker logs ai-celery-beat --since="2025-10-09T03:00:00"
```

#### **Celery Worker æ—¥èªŒ**
```bash
# æª¢æŸ¥ä»»å‹™åŸ·è¡Œ
docker logs ai-celery-worker --follow

# éæ¿¾èšé¡ç›¸é—œä»»å‹™
docker logs ai-celery-worker | grep "precompute_question"
```

### ğŸ” **Redis ä½‡åˆ—æª¢æŸ¥**

```bash
# æª¢æŸ¥ä»»å‹™ä½‡åˆ—é•·åº¦
docker exec ai-redis redis-cli LLEN celery

# æŸ¥çœ‹ä½‡åˆ—ä¸­çš„ä»»å‹™
docker exec ai-redis redis-cli LRANGE celery 0 -1

# æª¢æŸ¥çµæœå­˜å„²
docker exec ai-redis redis-cli KEYS "celery-task-meta-*"

# æª¢æŸ¥ä»»å‹™ç‹€æ…‹
docker exec ai-redis redis-cli GET "celery-task-meta-<task-id>"
```

## ğŸ› ï¸ **æ•…éšœæ’é™¤æŒ‡å—**

### ğŸš¨ **å¸¸è¦‹å•é¡Œèˆ‡è§£æ±ºæ–¹æ¡ˆ**

#### **å•é¡Œ 1: å®šæ™‚ä»»å‹™æ²’æœ‰åŸ·è¡Œ**
```bash
# 1. æª¢æŸ¥ Beat å®¹å™¨ç‹€æ…‹
docker ps | grep celery-beat

# 2. æª¢æŸ¥ Beat æ—¥èªŒ
docker logs ai-celery-beat --tail=50

# 3. æª¢æŸ¥è³‡æ–™åº«é€£æ¥
docker exec ai-celery-beat python manage.py shell -c "
from django.db import connection
connection.ensure_connection()
print('DB é€£æ¥æ­£å¸¸')
"

# 4. æ‰‹å‹•è§¸ç™¼ä»»å‹™æ¸¬è©¦
docker exec ai-celery-worker python -c "
from library.rvt_analytics.tasks import precompute_question_classifications
result = precompute_question_classifications.apply()
print(f'ä»»å‹™çµæœ: {result}')
"
```

#### **å•é¡Œ 2: Worker ç„¡æ³•è™•ç†ä»»å‹™**
```bash
# 1. æª¢æŸ¥ Worker ç‹€æ…‹
docker ps | grep celery-worker

# 2. æª¢æŸ¥ Redis é€£æ¥
docker exec ai-celery-worker python -c "
import redis
r = redis.Redis(host='redis', port=6379, db=1)
print(f'Redis é€£æ¥: {r.ping()}')
"

# 3. é‡å•Ÿ Worker
docker restart ai-celery-worker
```

#### **å•é¡Œ 3: ä»»å‹™åŸ·è¡Œå¤±æ•—**
```bash
# 1. æª¢æŸ¥å…·é«”éŒ¯èª¤
docker logs ai-celery-worker | grep ERROR

# 2. æª¢æŸ¥è³‡æºä½¿ç”¨
docker stats ai-celery-worker

# 3. æª¢æŸ¥ Python ç’°å¢ƒ
docker exec ai-celery-worker python -c "
import library.rvt_analytics.tasks
print('ä»»å‹™æ¨¡çµ„è¼‰å…¥æˆåŠŸ')
"
```

### ğŸ”§ **æ•ˆèƒ½èª¿æ ¡**

#### **Worker ä¸¦ç™¼è¨­å®š**
```yaml
# æ ¹æ“š CPU æ ¸å¿ƒæ•¸èª¿æ•´
command: celery -A ai_platform worker --concurrency=4
```

#### **ä»»å‹™è¶…æ™‚è¨­å®š**
```python
# åœ¨ celery.py ä¸­
app.conf.task_soft_time_limit = 600  # 10 åˆ†é˜è»Ÿé™åˆ¶
app.conf.task_time_limit = 900       # 15 åˆ†é˜ç¡¬é™åˆ¶
```

#### **è¨˜æ†¶é«”å„ªåŒ–**
```python
# Worker è‡ªå‹•é‡å•Ÿ (é˜²æ­¢è¨˜æ†¶é«”æ´©æ¼)
app.conf.worker_max_tasks_per_child = 1000
```

## ğŸ“ˆ **æ€§èƒ½æŒ‡æ¨™**

### âœ… **æ­£å¸¸é‹è¡ŒæŒ‡æ¨™**

| æŒ‡æ¨™ | æ­£å¸¸å€¼ | èªªæ˜ |
|------|--------|------|
| ä»»å‹™åŸ·è¡ŒæˆåŠŸç‡ | > 95% | ä»»å‹™æˆåŠŸå®Œæˆæ¯”ä¾‹ |
| å¹³å‡åŸ·è¡Œæ™‚é–“ | < 30ç§’ | å¤§éƒ¨åˆ†ä»»å‹™çš„åŸ·è¡Œæ™‚é–“ |
| ä½‡åˆ—é•·åº¦ | < 10 | Redis ä¸­ç­‰å¾…çš„ä»»å‹™æ•¸ |
| Worker è¨˜æ†¶é«”ä½¿ç”¨ | < 512MB | Worker é€²ç¨‹è¨˜æ†¶é«”å ç”¨ |
| Beat éŸ¿æ‡‰æ™‚é–“ | < 5ç§’ | æ’ç¨‹å™¨çš„éŸ¿æ‡‰æ™‚é–“ |

### ğŸ“Š **ç›£æ§è…³æœ¬**

```bash
#!/bin/bash
# monitor_celery.sh

echo "ğŸ” Celery ç³»çµ±ç‹€æ…‹ç›£æ§"
echo "===================="

echo "ğŸ“Š å®¹å™¨ç‹€æ…‹:"
docker ps --format "table {{.Names}}\t{{.Status}}" | grep celery

echo -e "\nğŸ“‹ ä½‡åˆ—ç‹€æ…‹:"
QUEUE_LENGTH=$(docker exec ai-redis redis-cli LLEN celery 2>/dev/null || echo "N/A")
echo "ä»»å‹™ä½‡åˆ—é•·åº¦: $QUEUE_LENGTH"

echo -e "\nâš¡ æœ€è¿‘ä»»å‹™åŸ·è¡Œ:"
docker logs ai-celery-worker --since="1h" --tail=5 | grep -E "(INFO|ERROR)"

echo -e "\nğŸ• ä¸‹æ¬¡å®šæ™‚ä»»å‹™:"
docker exec ai-django python manage.py shell -c "
from django_celery_beat.models import PeriodicTask
for task in PeriodicTask.objects.filter(enabled=True)[:3]:
    print(f'{task.name}: {task.crontab}')
" 2>/dev/null
```

## ğŸš€ **æœ€ä½³å¯¦è¸**

### ğŸ“ **é–‹ç™¼æŒ‡å—**

#### **æ–°å¢å®šæ™‚ä»»å‹™**
```python
# 1. åœ¨ celery.py ä¸­æ·»åŠ æ’ç¨‹
'new-task-name': {
    'task': 'app.tasks.new_task',
    'schedule': crontab(hour=4, minute=0),
    'kwargs': {'param1': 'value1'}
}

# 2. åœ¨ tasks.py ä¸­å¯¦ç¾ä»»å‹™
@shared_task(bind=True)
def new_task(self, param1=None):
    try:
        # ä»»å‹™é‚è¼¯
        return {'success': True}
    except Exception as exc:
        self.retry(exc=exc, countdown=60, max_retries=3)
```

#### **ä»»å‹™è¨­è¨ˆåŸå‰‡**
1. **å†ªç­‰æ€§**: é‡è¤‡åŸ·è¡Œä¸æœƒç”¢ç”Ÿå‰¯ä½œç”¨
2. **å¯é‡è©¦**: æ”¯æ´è‡ªå‹•é‡è©¦æ©Ÿåˆ¶
3. **è¶…æ™‚æ§åˆ¶**: è¨­å®šåˆç†çš„åŸ·è¡Œæ™‚é™
4. **éŒ¯èª¤è™•ç†**: å„ªé›…è™•ç†ç•°å¸¸æƒ…æ³
5. **æ—¥èªŒè¨˜éŒ„**: è©³ç´°è¨˜éŒ„åŸ·è¡Œéç¨‹

### ğŸ”’ **å®‰å…¨è€ƒé‡**

#### **è³‡æºé™åˆ¶**
```yaml
# Docker Compose ä¸­è¨­å®šè³‡æºé™åˆ¶
deploy:
  resources:
    limits:
      memory: 512M
      cpus: '0.5'
```

#### **ç¶²è·¯éš”é›¢**
```yaml
# ä½¿ç”¨å…§éƒ¨ç¶²è·¯
networks:
  - custom_network
```

## ğŸ“š **ç›¸é—œæ–‡æª”**

- ğŸ“– [Vector Database Architecture](./vector-database-scheduled-update-architecture.md)
- ğŸ” [Vector Search Guide](./vector-search-guide.md)
- ğŸ¤– [AI Guidance](./ai-guidance-vector-architecture.md)
- ğŸ“Š [RVT Guide Refactoring](./rvt-guide-refactoring-report.md)

---

**ç¶­è­·èªªæ˜**: æœ¬æ–‡æª”æ‡‰éš¨è‘—ç³»çµ±æ›´æ–°è€ŒåŒæ­¥æ›´æ–°ï¼Œç‰¹åˆ¥æ˜¯æ–°å¢å®šæ™‚ä»»å‹™æˆ–ä¿®æ”¹æ’ç¨‹é…ç½®æ™‚ã€‚

**ç·Šæ€¥è¯çµ¡**: å¦‚é‡åˆ° Celery Beat ç›¸é—œçš„åš´é‡å•é¡Œï¼Œè«‹ç«‹å³æª¢æŸ¥å®¹å™¨æ—¥èªŒä¸¦é‡å•Ÿç›¸é—œæœå‹™ã€‚