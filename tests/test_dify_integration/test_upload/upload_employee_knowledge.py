#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å°‡å®Œæ•´çš„å“¡å·¥è³‡æ–™ä¸Šå‚³åˆ°æŒ‡å®šçš„çŸ¥è­˜åº«
æ”¯æ´å¤šç¨®ä¸Šå‚³æ–¹å¼ï¼šæ–°å»ºçŸ¥è­˜åº«æˆ–æ·»åŠ åˆ°ç¾æœ‰çŸ¥è­˜åº«
"""

import requests
import json
import os
from datetime import datetime

# Dify API é…ç½®
DIFY_CONFIG = {
    'base_url': 'http://10.10.172.5',
    'dataset_api_key': 'dataset-JLa32OwILQHkgPqYStTCW4sC'
}

def read_employee_data():
    """è®€å–å“¡å·¥è³‡æ–™æª”æ¡ˆ"""
    file_path = '/home/user/codes/ai-platform-web/tests/test_dify_integration/company_employees_data.md'
    
    if os.path.exists(file_path):
        with open(file_path, 'r', encoding='utf-8') as f:
            return f.read()
    else:
        print(f"âŒ æ‰¾ä¸åˆ°å“¡å·¥è³‡æ–™æª”æ¡ˆ: {file_path}")
        return None

def create_new_dataset():
    """å‰µå»ºæ–°çš„å“¡å·¥çŸ¥è­˜åº«"""
    print("ğŸ†• å‰µå»ºæ–°çš„ã€Œå…¬å¸å“¡å·¥è³‡è¨Šç®¡ç†ã€çŸ¥è­˜åº«...")
    
    headers = {
        'Authorization': f'Bearer {DIFY_CONFIG["dataset_api_key"]}',
        'Content-Type': 'application/json'
    }
    
    dataset_data = {
        'name': 'å…¬å¸å“¡å·¥è³‡è¨Šç®¡ç†',
        'description': 'åŒ…å«å®Œæ•´å“¡å·¥è³‡æ–™çš„çŸ¥è­˜åº«ï¼Œæ”¯æ´å“¡å·¥æŸ¥è©¢ã€éƒ¨é–€çµ±è¨ˆã€è–ªè³‡åˆ†æç­‰åŠŸèƒ½',
        'indexing_technique': 'economy',  # ä½¿ç”¨ economy æ¨¡å¼é¿å…åµŒå…¥æ¨¡å‹å•é¡Œ
        'permission': 'only_me'
    }
    
    try:
        response = requests.post(
            f'{DIFY_CONFIG["base_url"]}/v1/datasets',
            headers=headers,
            json=dataset_data,
            timeout=30
        )
        
        if response.status_code == 200:
            dataset = response.json()
            dataset_id = dataset.get('id')
            print(f"âœ… çŸ¥è­˜åº«å‰µå»ºæˆåŠŸ!")
            print(f"   ğŸ“‹ åç¨±: {dataset.get('name')}")
            print(f"   ğŸ†” ID: {dataset_id}")
            return dataset_id
        else:
            print(f"âŒ å‰µå»ºçŸ¥è­˜åº«å¤±æ•—: HTTP {response.status_code}")
            print(f"å›æ‡‰: {response.text}")
            return None
            
    except Exception as e:
        print(f"âŒ å‰µå»ºçŸ¥è­˜åº«ç•°å¸¸: {e}")
        return None

def upload_employee_data(dataset_id, employee_data):
    """ä¸Šå‚³å“¡å·¥è³‡æ–™åˆ°çŸ¥è­˜åº«"""
    print(f"ğŸ“¤ ä¸Šå‚³å“¡å·¥è³‡æ–™åˆ°çŸ¥è­˜åº« {dataset_id}...")
    
    headers = {
        'Authorization': f'Bearer {DIFY_CONFIG["dataset_api_key"]}',
        'Content-Type': 'application/json'
    }
    
    upload_data = {
        'name': 'å…¬å¸å“¡å·¥å®Œæ•´è³‡æ–™.md',
        'text': employee_data,
        'indexing_technique': 'economy',
        'process_rule': {
            'mode': 'automatic',
            'rules': {
                'pre_processing_rules': [
                    {'id': 'remove_extra_spaces', 'enabled': True},
                    {'id': 'remove_urls_emails', 'enabled': False}
                ],
                'segmentation': {
                    'separator': '\\n\\n',
                    'max_tokens': 500
                }
            }
        }
    }
    
    try:
        response = requests.post(
            f'{DIFY_CONFIG["base_url"]}/v1/datasets/{dataset_id}/document/create_by_text',
            headers=headers,
            json=upload_data,
            timeout=30
        )
        
        if response.status_code == 200:
            document = response.json()
            print(f"âœ… å“¡å·¥è³‡æ–™ä¸Šå‚³æˆåŠŸ!")
            print(f"   ğŸ“„ æ–‡æª”åç¨±: {document.get('name')}")
            print(f"   ğŸ†” æ–‡æª” ID: {document.get('id')}")
            print(f"   ğŸ“Š å­—æ•¸: {document.get('word_count', 0)}")
            return document.get('id')
        else:
            print(f"âŒ ä¸Šå‚³å¤±æ•—: HTTP {response.status_code}")
            print(f"å›æ‡‰: {response.text}")
            return None
            
    except Exception as e:
        print(f"âŒ ä¸Šå‚³ç•°å¸¸: {e}")
        return None

def test_knowledge_retrieval(dataset_id):
    """æ¸¬è©¦çŸ¥è­˜åº«æª¢ç´¢åŠŸèƒ½"""
    print(f"\nğŸ” æ¸¬è©¦çŸ¥è­˜åº«æª¢ç´¢åŠŸèƒ½...")
    
    headers = {
        'Authorization': f'Bearer {DIFY_CONFIG["dataset_api_key"]}',
        'Content-Type': 'application/json'
    }
    
    # æ¸¬è©¦ä¸åŒçš„æŸ¥è©¢
    test_queries = [
        'å¼µå°æ˜çš„è–ªè³‡æ˜¯å¤šå°‘ï¼Ÿ',
        'æŠ€è¡“éƒ¨æœ‰å“ªäº›å“¡å·¥ï¼Ÿ',
        'èª°æ˜¯è–ªè³‡æœ€é«˜çš„å“¡å·¥ï¼Ÿ',
        'æ¥­å‹™éƒ¨é–€çš„å¹³å‡è–ªè³‡',
        '2023å¹´å…¥è·çš„å“¡å·¥æœ‰èª°ï¼Ÿ'
    ]
    
    for i, query in enumerate(test_queries, 1):
        print(f"\nğŸ§ª æ¸¬è©¦æŸ¥è©¢ {i}: {query}")
        
        search_data = {
            'query': query,
            'retrieval_model': {
                'search_method': 'keyword_search',  # ä½¿ç”¨é—œéµå­—æœå°‹é¿å…åµŒå…¥æ¨¡å‹å•é¡Œ
                'reranking_enable': False,
                'top_k': 3,
                'score_threshold_enabled': False
            }
        }
        
        try:
            response = requests.post(
                f'{DIFY_CONFIG["base_url"]}/v1/datasets/{dataset_id}/retrieve',
                headers=headers,
                json=search_data,
                timeout=30
            )
            
            if response.status_code == 200:
                data = response.json()
                records = data.get('query', {}).get('records', [])
                
                print(f"   ğŸ“Š æ‰¾åˆ° {len(records)} å€‹ç›¸é—œçµæœ")
                
                for j, record in enumerate(records[:2], 1):
                    segment = record.get('segment', {})
                    content = segment.get('content', '')
                    score = record.get('score', 0)
                    
                    print(f"   ğŸ“ çµæœ {j} (åˆ†æ•¸: {score:.4f}): {content[:100]}...")
            else:
                print(f"   âŒ æŸ¥è©¢å¤±æ•—: HTTP {response.status_code}")
                
        except Exception as e:
            print(f"   âŒ æŸ¥è©¢ç•°å¸¸: {e}")

def main():
    print("ğŸš€ å…¬å¸å“¡å·¥è³‡è¨ŠçŸ¥è­˜åº«ç®¡ç†å·¥å…·")
    print("=" * 60)
    
    # 1. è®€å–å“¡å·¥è³‡æ–™
    print("ğŸ“– è®€å–å“¡å·¥è³‡æ–™...")
    employee_data = read_employee_data()
    
    if not employee_data:
        print("âŒ ç„¡æ³•è®€å–å“¡å·¥è³‡æ–™ï¼Œç¨‹åºçµ‚æ­¢")
        return
    
    print(f"âœ… å“¡å·¥è³‡æ–™è®€å–æˆåŠŸï¼Œå…± {len(employee_data)} å€‹å­—å…ƒ")
    
    # 2. è©¢å•ä½¿ç”¨è€…é¸æ“‡
    print(f"\nğŸ“‹ è«‹é¸æ“‡æ“ä½œæ–¹å¼:")
    print("1. å‰µå»ºæ–°çš„ã€Œå…¬å¸å“¡å·¥è³‡è¨Šç®¡ç†ã€çŸ¥è­˜åº«")
    print("2. æ·»åŠ åˆ°ç¾æœ‰çŸ¥è­˜åº«")
    
    choice = input("\nè«‹è¼¸å…¥é¸æ“‡ (1 æˆ– 2): ").strip()
    
    dataset_id = None
    
    if choice == '1':
        # å‰µå»ºæ–°çŸ¥è­˜åº«
        dataset_id = create_new_dataset()
    elif choice == '2':
        # ä½¿ç”¨ç¾æœ‰çŸ¥è­˜åº«
        dataset_id = input("è«‹è¼¸å…¥çŸ¥è­˜åº« ID: ").strip()
        if not dataset_id:
            print("âŒ ç„¡æ•ˆçš„çŸ¥è­˜åº« ID")
            return
    else:
        print("âŒ ç„¡æ•ˆçš„é¸æ“‡")
        return
    
    if not dataset_id:
        print("âŒ ç„¡æ³•ç²å¾—æœ‰æ•ˆçš„çŸ¥è­˜åº« IDï¼Œç¨‹åºçµ‚æ­¢")
        return
    
    # 3. ä¸Šå‚³å“¡å·¥è³‡æ–™
    print(f"\nğŸ“¤ æº–å‚™ä¸Šå‚³è³‡æ–™åˆ°çŸ¥è­˜åº«: {dataset_id}")
    document_id = upload_employee_data(dataset_id, employee_data)
    
    if not document_id:
        print("âŒ è³‡æ–™ä¸Šå‚³å¤±æ•—ï¼Œç¨‹åºçµ‚æ­¢")
        return
    
    # 4. æ¸¬è©¦æª¢ç´¢åŠŸèƒ½
    test_knowledge_retrieval(dataset_id)
    
    # 5. è¼¸å‡ºç¸½çµ
    print(f"\nğŸ‰ å“¡å·¥çŸ¥è­˜åº«è¨­ç½®å®Œæˆ!")
    print("=" * 60)
    print(f"ğŸ“‹ çŸ¥è­˜åº« ID: {dataset_id}")
    print(f"ğŸ“„ æ–‡æª” ID: {document_id}")
    print(f"ğŸ”— æ‚¨å¯ä»¥åœ¨ Dify UI ä¸­æŸ¥çœ‹: http://10.10.172.5/datasets/{dataset_id}")
    print(f"ğŸ¤– æ¥ä¸‹ä¾†å¯ä»¥åœ¨ Chat æ‡‰ç”¨ä¸­é—œè¯æ­¤çŸ¥è­˜åº«é€²è¡Œå°è©±æ¸¬è©¦")

if __name__ == "__main__":
    main()